#!/usr/bin/env python3
"""
ì•ˆì „í•œ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸

ì¤‘ìš”í•œ ê²°ê³¼ë¥¼ ì•„ì¹´ì´ë¸Œí•œ í›„ ë¶ˆí•„ìš”í•œ íŒŒì¼ë“¤ì„ ì•ˆì „í•˜ê²Œ ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import shutil
from pathlib import Path
from datetime import datetime
import json

def create_final_archive():
    """ìµœì¢… ì•„ì¹´ì´ë¸Œ ìƒì„±"""
    print("ğŸ’¾ ì¤‘ìš” ê²°ê³¼ ìµœì¢… ì•„ì¹´ì´ë¸Œ")
    print("=" * 50)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    archive_dir = Path(f"results/archive/final_legacy_backup_{timestamp}")
    archive_dir.mkdir(parents=True, exist_ok=True)
    
    # ì•„ì¹´ì´ë¸Œí•  ì¤‘ìš” ê²°ê³¼ ë””ë ‰í† ë¦¬
    important_dirs = [
        "final_english_charts",
        "discriminant_validity_results", 
        "factor_correlations_results",
        "rpl_analysis_results",
        "moderation_analysis_results",
        "path_analysis_results"
    ]
    
    archived_count = 0
    for dir_name in important_dirs:
        source_dir = Path(dir_name)
        if source_dir.exists():
            try:
                dest_dir = archive_dir / dir_name
                shutil.copytree(source_dir, dest_dir)
                print(f"   âœ… {dir_name} â†’ ì•„ì¹´ì´ë¸Œ")
                archived_count += 1
            except Exception as e:
                print(f"   âŒ {dir_name}: {e}")
    
    print(f"\nğŸ“¦ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ: {archived_count}ê°œ ë””ë ‰í† ë¦¬")
    print(f"ğŸ“ ìœ„ì¹˜: {archive_dir}")
    
    return archive_dir


def cleanup_old_scripts():
    """êµ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì •ë¦¬"""
    print(f"\nğŸ§¹ êµ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì •ë¦¬")
    print("-" * 40)
    
    old_scripts = [
        "run_all_moderation_combinations.py",
        "run_analysis_original_data.py", 
        "run_correlation_visualization.py",
        "run_discriminant_validity_analysis.py",
        "run_factor_analysis.py",  # ìƒˆ ë²„ì „ì€ scripts/ì— ìˆìŒ
        "run_factor_visualization.py",
        "run_four_factor_moderation_analysis.py",
        "run_moderation_analysis.py",
        "run_path_visualization.py",
        "run_reliability_analysis.py",  # ìƒˆ ë²„ì „ì€ scripts/ì— ìˆìŒ
        "run_reverse_items_processing.py",
        "run_semopy_correlations.py",
        "run_semopy_native_visualization.py",
        "run_utility_analysis.py"
    ]
    
    removed_count = 0
    for script in old_scripts:
        script_path = Path(script)
        if script_path.exists():
            try:
                script_path.unlink()
                print(f"   âœ… ì‚­ì œ: {script}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {script} - {e}")
    
    print(f"\nğŸ“Š ìŠ¤í¬ë¦½íŠ¸ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_result_directories():
    """ê²°ê³¼ ë””ë ‰í† ë¦¬ ì •ë¦¬"""
    print(f"\nğŸ—‚ï¸ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì •ë¦¬")
    print("-" * 40)
    
    result_dirs = [
        "comparison_analysis_results",
        "comprehensive_mediation_results",
        "discriminant_validity_results",
        "factor_analysis_results", 
        "factor_correlations_results",
        "moderation_analysis_results",
        "path_analysis_effects_test_results",
        "path_analysis_results",
        "real_data_effects_test_results",
        "reliability_analysis_results",
        "rpl_analysis_results",
        "simple_effects_test_results",
        "utility_function_analysis_results",
        "utility_function_results"
    ]
    
    removed_count = 0
    for dir_name in result_dirs:
        dir_path = Path(dir_name)
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                print(f"   âœ… ì‚­ì œ: {dir_name}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {dir_name} - {e}")
    
    print(f"\nğŸ“Š ê²°ê³¼ ë””ë ‰í† ë¦¬ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_visualization_dirs():
    """ì‹œê°í™” ë””ë ‰í† ë¦¬ ì •ë¦¬"""
    print(f"\nğŸ¨ ì‹œê°í™” ë””ë ‰í† ë¦¬ ì •ë¦¬")
    print("-" * 40)
    
    viz_dirs = [
        "correlation_visualization_results",
        "factor_analysis_visualization_results", 
        "integrated_visualization_results",
        "semopy_native_visualization_results",
        "test_path_visualizations",
        "test_visualizations"
    ]
    
    removed_count = 0
    for dir_name in viz_dirs:
        dir_path = Path(dir_name)
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                print(f"   âœ… ì‚­ì œ: {dir_name}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {dir_name} - {e}")
    
    print(f"\nğŸ“Š ì‹œê°í™” ë””ë ‰í† ë¦¬ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_misc_files():
    """ê¸°íƒ€ íŒŒì¼ ì •ë¦¬"""
    print(f"\nğŸ“„ ê¸°íƒ€ íŒŒì¼ ì •ë¦¬")
    print("-" * 40)
    
    misc_files = [
        "cleanup_duplicates.py",
        "compare_5factor_vs_4factor_models.py",
        "comprehensive_mediation_analysis.py",
        "comprehensive_moderation_test.py", 
        "comprehensive_path_analysis.py",
        "create_5factor_visualization.py",
        "create_comprehensive_path_model.py",
        "discriminant_validity_comparison_20250906_182455.png",
        "example_visualization_usage.py",
        "final_test_structural_paths.py",
        "real_data_effects_test.py",
        "rpl_analysis_final.py",
        "rpl_corrected_coefficient_summary.py",
        "rpl_utility_function.py",
        "sem_effect_calculation_analysis.py",
        "test_heatmap.png",
        "utility_function_analysis.py",
        "manual_health_concern.dot"
    ]
    
    removed_count = 0
    for file_name in misc_files:
        file_path = Path(file_name)
        if file_path.exists():
            try:
                file_path.unlink()
                print(f"   âœ… ì‚­ì œ: {file_name}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {file_name} - {e}")
    
    print(f"\nğŸ“Š ê¸°íƒ€ íŒŒì¼ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_log_reports():
    """ë¡œê·¸ ë° ë³´ê³ ì„œ íŒŒì¼ ì •ë¦¬"""
    print(f"\nğŸ“‹ ë¡œê·¸/ë³´ê³ ì„œ íŒŒì¼ ì •ë¦¬")
    print("-" * 40)
    
    log_files = [
        "discriminant_validity_comparison_report.py",
        "discriminant_validity_comparison_report_20250906_182455.txt",
        "path_analysis.log",
        "reverse_items_processing_report_20250905_134025.txt",
        "reverse_items_processing_report_20250905_144509.txt",
        "reverse_items_report_20250905_134110.txt",
        "reverse_items_report_20250905_140845.txt",
        "reverse_items_report_20250905_140952.txt",
        "reverse_items_report_20250905_141052.txt",
        "reverse_items_report_20250905_141219.txt",
        "reverse_items_report_20250905_143317.txt",
        "rpl_analysis_report.py",
        "significant_mediations_report_20250908_221854.txt"
    ]
    
    removed_count = 0
    for file_name in log_files:
        file_path = Path(file_name)
        if file_path.exists():
            try:
                file_path.unlink()
                print(f"   âœ… ì‚­ì œ: {file_name}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {file_name} - {e}")
    
    print(f"\nğŸ“Š ë¡œê·¸/ë³´ê³ ì„œ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_processed_data():
    """processed_data ì •ë¦¬"""
    print(f"\nğŸ“ processed_data ì •ë¦¬")
    print("-" * 40)
    
    processed_dir = Path("processed_data")
    if not processed_dir.exists():
        print("   âš ï¸ processed_data ë””ë ‰í† ë¦¬ ì—†ìŒ")
        return 0
    
    # reverse_items_config.jsonë§Œ ìœ ì§€
    keep_file = "reverse_items_config.json"
    
    removed_count = 0
    for item in processed_dir.iterdir():
        if item.name != keep_file:
            try:
                if item.is_dir():
                    shutil.rmtree(item)
                else:
                    item.unlink()
                print(f"   âœ… ì‚­ì œ: processed_data/{item.name}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: processed_data/{item.name} - {e}")
    
    print(f"\nğŸ“Š processed_data ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_cache_files():
    """ìºì‹œ íŒŒì¼ ì •ë¦¬"""
    print(f"\nğŸ—‚ï¸ ìºì‹œ íŒŒì¼ ì •ë¦¬")
    print("-" * 40)
    
    removed_count = 0
    
    # __pycache__ ë””ë ‰í† ë¦¬ë“¤
    for pycache_dir in Path(".").rglob("__pycache__"):
        try:
            shutil.rmtree(pycache_dir)
            print(f"   âœ… ì‚­ì œ: {pycache_dir}")
            removed_count += 1
        except Exception as e:
            print(f"   âŒ ì‹¤íŒ¨: {pycache_dir} - {e}")
    
    print(f"\nğŸ“Š ìºì‹œ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def cleanup_temp_test_files():
    """ì„ì‹œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬"""
    print(f"\nğŸ§ª ì„ì‹œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬")
    print("-" * 40)
    
    temp_files = [
        "test_analysis_functions.py",
        "test_interactive_menu.py",
        "test_main_direct.py",
        "test_main_menu.py",
        "final_system_test.py",
        "simple_factor_test.py",
        "cleanup_legacy_files.py",
        "identify_cleanup_targets.py",
        "cleanup_targets.json",
        "cleanup_targets.txt"
    ]
    
    removed_count = 0
    for file_name in temp_files:
        file_path = Path(file_name)
        if file_path.exists():
            try:
                file_path.unlink()
                print(f"   âœ… ì‚­ì œ: {file_name}")
                removed_count += 1
            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {file_name} - {e}")
    
    print(f"\nğŸ“Š ì„ì‹œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬: {removed_count}ê°œ ì‚­ì œ")
    return removed_count


def generate_cleanup_summary(archive_dir, total_removed):
    """ì •ë¦¬ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    print(f"\nğŸ“‹ ì •ë¦¬ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±")
    print("-" * 40)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    summary_file = Path(f"docs/cleanup_summary_{timestamp}.md")
    
    summary_content = f"""# ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬ ì™„ë£Œ ë³´ê³ ì„œ

## ì •ë¦¬ ê°œìš”
- **ì‹¤í–‰ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ì´ ì‚­ì œ í•­ëª©**: {total_removed}ê°œ
- **ì•„ì¹´ì´ë¸Œ ìœ„ì¹˜**: {archive_dir}

## ì •ë¦¬ëœ í•­ëª©
1. **êµ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸**: 14ê°œ (run_*.py)
2. **ê²°ê³¼ ë””ë ‰í† ë¦¬**: 14ê°œ (*_results/)
3. **ì‹œê°í™” ë””ë ‰í† ë¦¬**: 6ê°œ (*_visualization_*)
4. **ë¡œê·¸/ë³´ê³ ì„œ**: 13ê°œ (*.log, *_report_*)
5. **ê¸°íƒ€ íŒŒì¼**: 18ê°œ (ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸, ì´ë¯¸ì§€ ë“±)
6. **processed_data**: 10ê°œ (ë°±ì—…, ì„ì‹œ íŒŒì¼ ë“±)
7. **ìºì‹œ íŒŒì¼**: __pycache__ ë””ë ‰í† ë¦¬ë“¤
8. **ì„ì‹œ í…ŒìŠ¤íŠ¸ íŒŒì¼**: 10ê°œ (test_*, cleanup_* ë“±)

## ë³´ì¡´ëœ êµ¬ì¡°
```
Sugar_substitue_2025_Heo/
â”œâ”€â”€ main.py                 # âœ… í†µí•© ì‹¤í–‰ ì‹œìŠ¤í…œ
â”œâ”€â”€ config.py               # âœ… ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ README.md               # âœ… í”„ë¡œì íŠ¸ ë¬¸ì„œ
â”œâ”€â”€ Raw data/               # âœ… ì›ë³¸ ë°ì´í„° (ë³´ì¡´)
â”œâ”€â”€ data/                   # âœ… ìƒˆë¡œìš´ ë°ì´í„° êµ¬ì¡°
â”œâ”€â”€ src/                    # âœ… ëª¨ë“ˆí™”ëœ ì†ŒìŠ¤ ì½”ë“œ
â”œâ”€â”€ scripts/                # âœ… í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ results/                # âœ… ê²°ê³¼ ê´€ë¦¬ ì‹œìŠ¤í…œ
â”œâ”€â”€ docs/                   # âœ… ë¬¸ì„œí™”
â”œâ”€â”€ logs/                   # âœ… ë¡œê·¸ ê´€ë¦¬
â”œâ”€â”€ tests/                  # âœ… í…ŒìŠ¤íŠ¸ ì½”ë“œ
â””â”€â”€ notebooks/              # âœ… ë¶„ì„ ë…¸íŠ¸ë¶
```

## ì¤‘ìš” ê²°ê³¼ ì•„ì¹´ì´ë¸Œ
- **ìœ„ì¹˜**: {archive_dir}
- **ë‚´ìš©**: ìµœì¢… ì˜ë¬¸ ì°¨íŠ¸, íŒë³„íƒ€ë‹¹ë„, ìš”ì¸ìƒê´€, RPL ë¶„ì„, ì¡°ì ˆíš¨ê³¼, ê²½ë¡œë¶„ì„ ê²°ê³¼

## ì‚¬ìš©ë²•
```bash
# ëŒ€í™”í˜• ë©”ë‰´
python main.py

# ê°œë³„ ë¶„ì„
python main.py --factor
python main.py --reliability  
python main.py --path

# ì „ì²´ ë¶„ì„
python main.py --all

# ê²°ê³¼ í™•ì¸
python main.py --results
```

## ë‹¤ìŒ ë‹¨ê³„
1. ìƒˆë¡œìš´ í†µí•© ì‹œìŠ¤í…œìœ¼ë¡œ ë¶„ì„ ìˆ˜í–‰
2. í•„ìš”ì‹œ ì•„ì¹´ì´ë¸Œì—ì„œ ê³¼ê±° ê²°ê³¼ ì°¸ì¡°
3. ì§€ì†ì ì¸ ê²°ê³¼ ê´€ë¦¬ ë° ë²„ì „ ì¶”ì 

---
*Sugar Substitute Research - ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬ ì™„ë£Œ*
"""
    
    summary_file.parent.mkdir(parents=True, exist_ok=True)
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(summary_content)
    
    print(f"   âœ… ìš”ì•½ ë³´ê³ ì„œ: {summary_file}")
    return summary_file


def main():
    """ë©”ì¸ ì •ë¦¬ í•¨ìˆ˜"""
    print("ğŸ¯ Sugar Substitute Research - ì•ˆì „í•œ ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬")
    print("=" * 70)
    
    # 1. ì¤‘ìš” ê²°ê³¼ ì•„ì¹´ì´ë¸Œ
    archive_dir = create_final_archive()
    
    # 2. ë‹¨ê³„ë³„ ì •ë¦¬
    total_removed = 0
    
    total_removed += cleanup_old_scripts()
    total_removed += cleanup_result_directories()
    total_removed += cleanup_visualization_dirs()
    total_removed += cleanup_misc_files()
    total_removed += cleanup_log_reports()
    total_removed += cleanup_processed_data()
    total_removed += cleanup_cache_files()
    total_removed += cleanup_temp_test_files()
    
    # 3. ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
    summary_file = generate_cleanup_summary(archive_dir, total_removed)
    
    # 4. ìµœì¢… ê²°ê³¼
    print(f"\n" + "=" * 70)
    print("ğŸ‰ ì½”ë“œë² ì´ìŠ¤ ì •ë¦¬ ì™„ë£Œ!")
    print("=" * 70)
    print(f"ğŸ—‘ï¸ ì´ ì‚­ì œ í•­ëª©: {total_removed}ê°œ")
    print(f"ğŸ“¦ ì•„ì¹´ì´ë¸Œ ìœ„ì¹˜: {archive_dir}")
    print(f"ğŸ“‹ ìš”ì•½ ë³´ê³ ì„œ: {summary_file}")
    
    print(f"\nâœ… ìƒˆë¡œìš´ ê¹”ë”í•œ êµ¬ì¡°:")
    print(f"   ğŸ“„ main.py - í†µí•© ì‹¤í–‰ ì‹œìŠ¤í…œ")
    print(f"   ğŸ“ data/ - ì²´ê³„ì ì¸ ë°ì´í„° ê´€ë¦¬")
    print(f"   ğŸ“ src/ - ëª¨ë“ˆí™”ëœ ì†ŒìŠ¤ ì½”ë“œ")
    print(f"   ğŸ“ scripts/ - í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸")
    print(f"   ğŸ“ results/ - ë²„ì „ ê´€ë¦¬ ê²°ê³¼")
    
    print(f"\nğŸš€ ì´ì œ ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”:")
    print(f"   python main.py")


if __name__ == "__main__":
    main()
