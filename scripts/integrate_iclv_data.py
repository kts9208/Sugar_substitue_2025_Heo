"""
ICLV ë°ì´í„° í†µí•© ìŠ¤í¬ë¦½íŠ¸

ëª©ì : DCE + 5ê°œ ì ì¬ë³€ìˆ˜ + ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„° í†µí•©
ì…ë ¥:
  - data/processed/dce/dce_long_format.csv (DCE ë°ì´í„°)
  - data/processed/survey/health_concern.csv (ê±´ê°•ê´€ì‹¬ë„)
  - data/processed/survey/perceived_benefit.csv (ê±´ê°•ìœ ìµì„±)
  - data/processed/survey/perceived_price.csv (ê°€ê²©ìˆ˜ì¤€)
  - data/processed/survey/purchase_intention.csv (êµ¬ë§¤ì˜ë„)
  - data/processed/survey/nutrition_knowledge.csv (ì˜ì–‘ì§€ì‹)
  - ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„° (êµ¬ì¡°ëª¨ë¸ ë³€ìˆ˜)
ì¶œë ¥:
  - data/processed/iclv/integrated_data.csv
"""

import pandas as pd
import numpy as np
import os


def load_dce_data():
    """
    DCE Long format ë°ì´í„° ë¡œë“œ
    
    Returns:
        pd.DataFrame: DCE ë°ì´í„°
    """
    print("\n[1] DCE ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    df_dce = pd.read_csv('data/processed/dce/dce_long_format.csv')
    
    print(f"   - ë¡œë“œ ì™„ë£Œ: {len(df_dce):,}í–‰")
    print(f"   - ì‘ë‹µì ìˆ˜: {df_dce['respondent_id'].nunique()}")
    print(f"   - ì»¬ëŸ¼: {df_dce.columns.tolist()}")
    
    return df_dce


def load_latent_variable_data():
    """
    5ê°œ ì ì¬ë³€ìˆ˜ ë°ì´í„° ë¡œë“œ (ì¸¡ì •ëª¨ë¸ ì§€í‘œ)

    Returns:
        dict: ì ì¬ë³€ìˆ˜ë³„ ë°ì´í„°í”„ë ˆì„ ë”•ì…”ë„ˆë¦¬
    """
    print("\n[2] ì ì¬ë³€ìˆ˜ ë°ì´í„° ë¡œë“œ ì¤‘...")

    latent_vars = {}

    # 1. ê±´ê°•ê´€ì‹¬ë„ (Q6-Q11)
    print("   [2-1] ê±´ê°•ê´€ì‹¬ë„...")
    df_health = pd.read_csv('data/processed/survey/health_concern.csv')
    df_health = df_health.rename(columns={'no': 'respondent_id'})
    df_health = df_health.drop_duplicates(subset='respondent_id', keep='first')
    latent_vars['health_concern'] = df_health
    print(f"      - {len(df_health)}ëª…, ì§€í‘œ: {[c for c in df_health.columns if c.startswith('q')]}")

    # 2. ê±´ê°•ìœ ìµì„± (Q12-Q17)
    print("   [2-2] ê±´ê°•ìœ ìµì„±...")
    df_benefit = pd.read_csv('data/processed/survey/perceived_benefit.csv')
    df_benefit = df_benefit.rename(columns={'no': 'respondent_id'})
    df_benefit = df_benefit.drop_duplicates(subset='respondent_id', keep='first')
    latent_vars['perceived_benefit'] = df_benefit
    print(f"      - {len(df_benefit)}ëª…, ì§€í‘œ: {[c for c in df_benefit.columns if c.startswith('q')]}")

    # 3. ê°€ê²©ìˆ˜ì¤€ (Q27-Q29)
    print("   [2-3] ê°€ê²©ìˆ˜ì¤€...")
    df_price = pd.read_csv('data/processed/survey/perceived_price.csv')
    df_price = df_price.rename(columns={'no': 'respondent_id'})
    df_price = df_price.drop_duplicates(subset='respondent_id', keep='first')
    latent_vars['perceived_price'] = df_price
    print(f"      - {len(df_price)}ëª…, ì§€í‘œ: {[c for c in df_price.columns if c.startswith('q')]}")

    # 4. êµ¬ë§¤ì˜ë„ (Q18-Q20)
    print("   [2-4] êµ¬ë§¤ì˜ë„...")
    df_purchase = pd.read_csv('data/processed/survey/purchase_intention.csv')
    df_purchase = df_purchase.rename(columns={'no': 'respondent_id'})
    df_purchase = df_purchase.drop_duplicates(subset='respondent_id', keep='first')
    latent_vars['purchase_intention'] = df_purchase
    print(f"      - {len(df_purchase)}ëª…, ì§€í‘œ: {[c for c in df_purchase.columns if c.startswith('q')]}")

    # 5. ì˜ì–‘ì§€ì‹ (Q30-Q49)
    print("   [2-5] ì˜ì–‘ì§€ì‹...")
    df_nutrition = pd.read_csv('data/processed/survey/nutrition_knowledge.csv')
    df_nutrition = df_nutrition.rename(columns={'no': 'respondent_id'})
    df_nutrition = df_nutrition.drop_duplicates(subset='respondent_id', keep='first')
    latent_vars['nutrition_knowledge'] = df_nutrition
    print(f"      - {len(df_nutrition)}ëª…, ì§€í‘œ: {[c for c in df_nutrition.columns if c.startswith('q')]}")

    print(f"\n   - ì´ {len(latent_vars)}ê°œ ì ì¬ë³€ìˆ˜ ë¡œë“œ ì™„ë£Œ")

    return latent_vars


def load_sociodem_data():
    """
    ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„° ë¡œë“œ (êµ¬ì¡°ëª¨ë¸ ë³€ìˆ˜)

    Returns:
        pd.DataFrame: ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„°
    """
    print("\n[3] ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„° ë¡œë“œ ì¤‘...")

    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    df = pd.read_excel('data/raw/Sugar_substitue_Raw data_251108.xlsx', sheet_name='DATA')

    # ì‚¬íšŒì¸êµ¬í•™ì  ë³€ìˆ˜ ì„ íƒ
    # ğŸ”´ ìˆ˜ì •: q50 (income), q52 (education) ì˜¬ë°”ë¥¸ ë§¤í•‘
    sociodem_cols = ['no', 'q1', 'q3', 'q50', 'q52', 'q54', 'q55', 'q56']
    df_sociodem = df[sociodem_cols].copy()

    # ì»¬ëŸ¼ëª… ë³€ê²½
    # ğŸ”´ ìˆ˜ì •: ì˜¬ë°”ë¥¸ ë§¤í•‘ ì ìš©
    df_sociodem = df_sociodem.rename(columns={
        'no': 'respondent_id',
        'q1': 'gender',           # 0: ë‚¨ì„±, 1: ì—¬ì„±
        'q3': 'age',              # 1: 20~29ì„¸, 2: 30~39ì„¸, 3: 40~49ì„¸, 4: 50~59ì„¸, 5: 60~69ì„¸
        'q50': 'income',          # 1: 200ë§Œì› ë¯¸ë§Œ, 2: 200~300ë§Œ, 3: 300~400ë§Œ, 4: 400~500ë§Œ, 5: 500~600ë§Œ, 6: 600ë§Œì› ì´ìƒ
        'q52': 'education',       # 1: ê³ ì¡¸ë¯¸ë§Œ, 2: ê³ ì¡¸, 3: ëŒ€í•™ì¬í•™, 4: ëŒ€í•™ì¡¸ì—…, 5: ëŒ€í•™ì›ì¬í•™, 6: ëŒ€í•™ì›ì¡¸ì—…
        'q54': 'diabetes',
        'q55': 'family_diabetes',
        'q56': 'sugar_substitute_usage'
    })

    # ì—°ë ¹ëŒ€ë¥¼ ì—°ì†í˜•ìœ¼ë¡œ ë³€í™˜ (ì¤‘ê°„ê°’ ì‚¬ìš©)
    # ğŸ”´ ìˆ˜ì •: q3 (ì—°ë ¹ëŒ€)ë¥¼ ì—°ì†í˜• ë‚˜ì´ë¡œ ë³€í™˜
    age_mapping = {
        1: 25,  # 20~29ì„¸ â†’ 25ì„¸
        2: 35,  # 30~39ì„¸ â†’ 35ì„¸
        3: 45,  # 40~49ì„¸ â†’ 45ì„¸
        4: 55,  # 50~59ì„¸ â†’ 55ì„¸
        5: 65   # 60~69ì„¸ â†’ 65ì„¸
    }
    df_sociodem['age_continuous'] = df_sociodem['age'].map(age_mapping)
    df_sociodem['age_std'] = (df_sociodem['age_continuous'] - df_sociodem['age_continuous'].mean()) / df_sociodem['age_continuous'].std()

    # ì†Œë“ ì—°ì†í˜• ë³€í™˜ (ì¤‘ê°„ê°’ ì‚¬ìš©, ë‹¨ìœ„: ë§Œì›)
    # ğŸ”´ ìˆ˜ì •: income=6 ì¶”ê°€ (600ë§Œì› ì´ìƒ â†’ 700ë§Œì›ìœ¼ë¡œ ê°€ì •)
    income_mapping = {
        1: 150,   # 200ë§Œì› ë¯¸ë§Œ â†’ 150ë§Œì›
        2: 250,   # 200~300ë§Œì› â†’ 250ë§Œì›
        3: 350,   # 300~400ë§Œì› â†’ 350ë§Œì›
        4: 450,   # 400~500ë§Œì› â†’ 450ë§Œì›
        5: 550,   # 500~600ë§Œì› â†’ 550ë§Œì›
        6: 700    # 600ë§Œì› ì´ìƒ â†’ 700ë§Œì›
    }
    df_sociodem['income_continuous'] = df_sociodem['income'].map(income_mapping)
    df_sociodem['income_std'] = (df_sociodem['income_continuous'] - df_sociodem['income_continuous'].mean()) / df_sociodem['income_continuous'].std()

    # êµìœ¡ ìˆ˜ì¤€ (ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    df_sociodem['education_level'] = df_sociodem['education']

    # ì¤‘ë³µ ì œê±° (ì²« ë²ˆì§¸ ê²ƒë§Œ ìœ ì§€)
    df_sociodem = df_sociodem.drop_duplicates(subset='respondent_id', keep='first')

    print(f"   - ë¡œë“œ ì™„ë£Œ: {len(df_sociodem)}ëª…")
    print(f"   - ë³€ìˆ˜: {df_sociodem.columns.tolist()}")
    print(f"   - income ë²”ìœ„: {df_sociodem['income'].min()}~{df_sociodem['income'].max()} (1~6)")
    print(f"   - education ë²”ìœ„: {df_sociodem['education'].min()}~{df_sociodem['education'].max()} (1~6)")
    print(f"   - income_std NaN ê°œìˆ˜: {df_sociodem['income_std'].isna().sum()}")

    return df_sociodem


def integrate_data(df_dce, latent_vars, df_sociodem):
    """
    DCE + 5ê°œ ì ì¬ë³€ìˆ˜ + ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„° í†µí•©

    Args:
        df_dce: DCE ë°ì´í„°
        latent_vars: ì ì¬ë³€ìˆ˜ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        df_sociodem: ì‚¬íšŒì¸êµ¬í•™ì  ë°ì´í„°

    Returns:
        pd.DataFrame: í†µí•© ë°ì´í„°
    """
    print("\n[4] ë°ì´í„° í†µí•© ì¤‘...")

    df_merged = df_dce.copy()

    # Step 1-5: 5ê°œ ì ì¬ë³€ìˆ˜ ìˆœì°¨ ë³‘í•©
    for i, (lv_name, df_lv) in enumerate(latent_vars.items(), 1):
        print(f"   - Step {i}: + {lv_name} ë³‘í•©...")
        df_merged = df_merged.merge(
            df_lv,
            on='respondent_id',
            how='left'
        )
        print(f"     ë³‘í•© í›„: {len(df_merged):,}í–‰ Ã— {len(df_merged.columns)}ì»¬ëŸ¼")

    # Step 6: + ì‚¬íšŒì¸êµ¬í•™ì 
    print(f"   - Step 6: + ì‚¬íšŒì¸êµ¬í•™ì  ë³‘í•©...")
    df_integrated = df_merged.merge(
        df_sociodem,
        on='respondent_id',
        how='left'
    )
    print(f"     ë³‘í•© í›„: {len(df_integrated):,}í–‰ Ã— {len(df_integrated.columns)}ì»¬ëŸ¼")

    print(f"\n   - ìµœì¢… ë°ì´í„°: {len(df_integrated):,}í–‰ Ã— {len(df_integrated.columns)}ì»¬ëŸ¼")

    return df_integrated


def validate_integration(df_integrated, df_dce):
    """
    í†µí•© ë°ì´í„° ê²€ì¦

    Args:
        df_integrated: í†µí•© ë°ì´í„°
        df_dce: ì›ë³¸ DCE ë°ì´í„°
    """
    print("\n[5] í†µí•© ë°ì´í„° ê²€ì¦ ì¤‘...")

    # ê²€ì¦ 1: í–‰ ìˆ˜
    assert len(df_integrated) == len(df_dce), "í–‰ ìˆ˜ê°€ ë³€ê²½ë¨"
    print(f"   âœ“ í–‰ ìˆ˜ ê²€ì¦: {len(df_integrated):,}í–‰ ìœ ì§€")

    # ê²€ì¦ 2: ì‘ë‹µì ìˆ˜
    n_respondents_original = df_dce['respondent_id'].nunique()
    n_respondents_integrated = df_integrated['respondent_id'].nunique()
    print(f"   âœ“ ì‘ë‹µì ìˆ˜: {n_respondents_integrated}ëª… (ì›ë³¸: {n_respondents_original}ëª…)")

    # ê²€ì¦ 3: DCE ì»¬ëŸ¼ ìœ ì§€
    dce_cols = ['choice_set', 'alternative', 'price', 'health_label', 'choice']
    for col in dce_cols:
        assert col in df_integrated.columns, f"{col} ì»¬ëŸ¼ ëˆ„ë½"
    print(f"   âœ“ DCE ì»¬ëŸ¼ ìœ ì§€: {dce_cols}")

    # ê²€ì¦ 4: 5ê°œ ì ì¬ë³€ìˆ˜ ì§€í‘œ ì¶”ê°€
    print("\n   [ì ì¬ë³€ìˆ˜ ì§€í‘œ ê²€ì¦]")

    # 4-1. ê±´ê°•ê´€ì‹¬ë„ (Q6-Q11)
    health_cols = ['q6', 'q7', 'q8', 'q9', 'q10', 'q11']
    for col in health_cols:
        assert col in df_integrated.columns, f"{col} ì»¬ëŸ¼ ëˆ„ë½"
    print(f"   âœ“ ê±´ê°•ê´€ì‹¬ë„ (6ê°œ): {health_cols}")

    # 4-2. ê±´ê°•ìœ ìµì„± (Q12-Q17)
    benefit_cols = ['q12', 'q13', 'q14', 'q15', 'q16', 'q17']
    for col in benefit_cols:
        assert col in df_integrated.columns, f"{col} ì»¬ëŸ¼ ëˆ„ë½"
    print(f"   âœ“ ê±´ê°•ìœ ìµì„± (6ê°œ): {benefit_cols}")

    # 4-3. êµ¬ë§¤ì˜ë„ (Q18-Q20)
    purchase_cols = ['q18', 'q19', 'q20']
    for col in purchase_cols:
        assert col in df_integrated.columns, f"{col} ì»¬ëŸ¼ ëˆ„ë½"
    print(f"   âœ“ êµ¬ë§¤ì˜ë„ (3ê°œ): {purchase_cols}")

    # 4-4. ê°€ê²©ìˆ˜ì¤€ (Q27-Q29)
    price_cols = ['q27', 'q28', 'q29']
    for col in price_cols:
        assert col in df_integrated.columns, f"{col} ì»¬ëŸ¼ ëˆ„ë½"
    print(f"   âœ“ ê°€ê²©ìˆ˜ì¤€ (3ê°œ): {price_cols}")

    # 4-5. ì˜ì–‘ì§€ì‹ (Q30-Q49)
    nutrition_cols = [f'q{i}' for i in range(30, 50)]
    for col in nutrition_cols:
        assert col in df_integrated.columns, f"{col} ì»¬ëŸ¼ ëˆ„ë½"
    print(f"   âœ“ ì˜ì–‘ì§€ì‹ (20ê°œ): q30-q49")

    print(f"   âœ“ ì´ 38ê°œ ì§€í‘œ ëª¨ë‘ ì¡´ì¬")

    # ê²€ì¦ 5: êµ¬ì¡°ëª¨ë¸ ë³€ìˆ˜ ì¶”ê°€
    print("\n   [êµ¬ì¡°ëª¨ë¸ ë³€ìˆ˜ ê²€ì¦]")
    structural_cols = ['age_std', 'gender', 'income_std', 'education_level']
    for col in structural_cols:
        if col in df_integrated.columns:
            print(f"   âœ“ {col}")

    # ê²€ì¦ 6: ê²°ì¸¡ì¹˜ í™•ì¸
    print("\n   [ê²°ì¸¡ì¹˜ í™•ì¸]")
    missing = df_integrated.isnull().sum()
    critical_cols = ['respondent_id', 'choice_set', 'alternative', 'choice']

    for col in critical_cols:
        if missing[col] > 0:
            print(f"   âœ— {col}: {missing[col]}ê°œ ê²°ì¸¡ì¹˜ (ì¹˜ëª…ì !)")
        else:
            print(f"   âœ“ {col}: ê²°ì¸¡ì¹˜ ì—†ìŒ")

    print("\n   âœ“ ëª¨ë“  ê²€ì¦ í†µê³¼!")


def create_summary(df_integrated):
    """
    í†µí•© ë°ì´í„° ìš”ì•½
    
    Args:
        df_integrated: í†µí•© ë°ì´í„°
    """
    print("\n[6] í†µí•© ë°ì´í„° ìš”ì•½:")
    print("-" * 80)
    
    # ê¸°ë³¸ ì •ë³´
    print(f"   - ì´ í–‰ ìˆ˜: {len(df_integrated):,}")
    print(f"   - ì´ ì»¬ëŸ¼ ìˆ˜: {len(df_integrated.columns)}")
    print(f"   - ì‘ë‹µì ìˆ˜: {df_integrated['respondent_id'].nunique()}")
    
    # ì»¬ëŸ¼ ê·¸ë£¹ë³„ ì •ë¦¬
    print(f"\n   [ì»¬ëŸ¼ ê·¸ë£¹]")
    
    # DCE ê´€ë ¨
    dce_cols = [c for c in df_integrated.columns if c in [
        'choice_set', 'alternative', 'alternative_name', 
        'product_type', 'sugar_content', 'health_label', 'price', 'choice'
    ]]
    print(f"   - DCE ë³€ìˆ˜ ({len(dce_cols)}ê°œ): {dce_cols}")
    
    # ì¸¡ì •ëª¨ë¸ ì§€í‘œ
    indicator_cols = [c for c in df_integrated.columns if c.startswith('q') and c[1:].isdigit()]
    print(f"   - ì¸¡ì •ëª¨ë¸ ì§€í‘œ ({len(indicator_cols)}ê°œ): {indicator_cols}")
    
    # êµ¬ì¡°ëª¨ë¸ ë³€ìˆ˜
    structural_cols = [c for c in df_integrated.columns if c in [
        'age', 'age_std', 'gender', 'income', 'income_std', 
        'income_continuous', 'education', 'education_level',
        'diabetes', 'family_diabetes', 'sugar_substitute_usage'
    ]]
    print(f"   - êµ¬ì¡°ëª¨ë¸ ë³€ìˆ˜ ({len(structural_cols)}ê°œ): {structural_cols}")
    
    # ì„ íƒ ë¶„í¬
    print(f"\n   [ì„ íƒ ë¶„í¬]")
    choice_dist = df_integrated[df_integrated['choice'] == 1]['alternative_name'].value_counts()
    total_choices = choice_dist.sum()
    for alt_name, count in choice_dist.items():
        pct = count / total_choices * 100
        print(f"   - {alt_name}: {count}íšŒ ({pct:.1f}%)")
    
    # ê²°ì¸¡ì¹˜ ìš”ì•½
    print(f"\n   [ê²°ì¸¡ì¹˜ ìš”ì•½]")
    missing = df_integrated.isnull().sum()
    missing_cols = missing[missing > 0].sort_values(ascending=False)
    
    if len(missing_cols) > 0:
        print(f"   - ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼: {len(missing_cols)}ê°œ")
        for col, count in missing_cols.head(10).items():
            pct = count / len(df_integrated) * 100
            print(f"     {col}: {count}ê°œ ({pct:.1f}%)")
    else:
        print(f"   - ê²°ì¸¡ì¹˜ ì—†ìŒ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    print("=" * 80)
    print("ICLV ë°ì´í„° í†µí•© (5ê°œ ì ì¬ë³€ìˆ˜)")
    print("=" * 80)

    # 1. ë°ì´í„° ë¡œë“œ
    df_dce = load_dce_data()
    latent_vars = load_latent_variable_data()
    df_sociodem = load_sociodem_data()

    # 2. ë°ì´í„° í†µí•©
    df_integrated = integrate_data(df_dce, latent_vars, df_sociodem)

    # 3. ê²€ì¦
    validate_integration(df_integrated, df_dce)

    # 4. ìš”ì•½
    create_summary(df_integrated)

    # 5. ì €ì¥
    print("\n[7] ì €ì¥ ì¤‘...")
    output_dir = 'data/processed/iclv'
    os.makedirs(output_dir, exist_ok=True)

    output_path = os.path.join(output_dir, 'integrated_data.csv')
    df_integrated.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"   - ì €ì¥ ì™„ë£Œ: {output_path}")

    # 6. ë¯¸ë¦¬ë³´ê¸°
    print("\n[8] ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²« 3í–‰):")
    print("-" * 80)
    print(df_integrated.head(3).to_string())

    print("\n" + "=" * 80)
    print("ICLV ë°ì´í„° í†µí•© ì™„ë£Œ! (5ê°œ ì ì¬ë³€ìˆ˜, 38ê°œ ì§€í‘œ)")
    print("=" * 80)

    return df_integrated


if __name__ == "__main__":
    df_integrated = main()

