"""
ë™ì‹œì¶”ì • (Simultaneous Estimation) - GPU ë°°ì¹˜ ì²˜ë¦¬

ì´ íŒŒì¼ í•˜ë‚˜ë¡œ ëª¨ë“  ë™ì‹œì¶”ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ìˆœì°¨ì¶”ì • 2ë‹¨ê³„ CSV íŒŒì¼ëª…ë§Œ ì§€ì •í•˜ë©´ ìë™ìœ¼ë¡œ ì„¤ì •ì´ íŒŒì‹±ë©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
1. INITIAL_PARAMS_CSVì— ìˆœì°¨ì¶”ì • 2ë‹¨ê³„ ê²°ê³¼ íŒŒì¼ëª… ì§€ì •
   ì˜ˆ: 'st2_HC-PB_PB-PI1_PI2_results.csv'
2. ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ê²½ë¡œ ë° ì„ íƒëª¨ë¸ ì„¤ì • íŒŒì‹±
3. ê²°ê³¼ íŒŒì¼ëª…: simultaneous_{ê²½ë¡œëª…}_{ì„ íƒëª¨ë¸LV}_results_{timestamp}.csv

ì£¼ìš” ê¸°ëŠ¥:
- ìë™ ì„¤ì •: CSV íŒŒì¼ëª…ì—ì„œ ê²½ë¡œ ë° ì„ íƒëª¨ë¸ ì„¤ì • ìë™ ì¶”ì¶œ
- ì´ˆê¸°ê°’: PKL íŒŒì¼ì—ì„œ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ, ë‚˜ë¨¸ì§€ëŠ” 0.1ë¡œ ì´ˆê¸°í™”
- GPU ë°°ì¹˜ ì²˜ë¦¬: ê³ ì† ë™ì‹œì¶”ì •

ì¶”ì • ëŒ€ìƒ:
- ì¸¡ì •ëª¨ë¸: ì¶”ì • O (PKL ì´ˆê¸°ê°’ ì‚¬ìš©)
- êµ¬ì¡°ëª¨ë¸: ì¶”ì • O (ì´ˆê¸°ê°’ 0.1)
- ì„ íƒëª¨ë¸: ì¶”ì • O (ì´ˆê¸°ê°’ 0.1)

Author: Sugar Substitute Research Team
Date: 2025-11-18
"""

import sys
import pandas as pd
import numpy as np
import time
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ê³µí†µ ìœ í‹¸ë¦¬í‹° import
sys.path.insert(0, str(project_root / 'examples'))
from model_config_utils import (
    build_paths_from_config,
    build_choice_config_dict,
    generate_simultaneous_filename,
    parse_csv_filename,
    parse_csv_content
)

from src.analysis.hybrid_choice_model.iclv_models.multi_latent_config import (
    create_sugar_substitute_multi_lv_config
)
from src.analysis.hybrid_choice_model.iclv_models.simultaneous_gpu_batch_estimator import SimultaneousGPUBatchEstimator
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_measurement import MultiLatentMeasurement
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_structural import MultiLatentStructural
from src.analysis.hybrid_choice_model.iclv_models.choice_equations import MultinomialLogitChoice
from src.analysis.hybrid_choice_model.iclv_models.initial_values_final import get_sigma_sq_initial_value


# ============================================================================
# ğŸ¯ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ - ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ============================================================================

# ============================================================================
# ì„¤ì • ëª¨ë“œ: ìë™ ì„¤ì • (CSV íŒŒì¼ëª…ì—ì„œ ëª¨ë“  ì„¤ì • ìë™ ì¶”ì¶œ)
# ============================================================================
#
# CSV íŒŒì¼ëª…ë§Œ ì§€ì •í•˜ë©´ ê²½ë¡œ, ì„ íƒëª¨ë¸ ì„¤ì •ì´ ìë™ìœ¼ë¡œ íŒŒì‹±ë¨
# íŒŒì¼ëª… í˜•ì‹: st2_{stage1_paths}1_{stage2_config}2_results.csv
#
# ì˜ˆì‹œ:
# 1. st2_HC-PB_PB-PI1_NK_PI2_results.csv
#    â†’ ê²½ë¡œ: HC->PB, PB->PI
#    â†’ ì„ íƒëª¨ë¸: NK, PI ì£¼íš¨ê³¼
#
# 2. st2_HC-PB_PB-PI1_PI_int_PIxhl_NKxpr2_results.csv
#    â†’ ê²½ë¡œ: HC->PB, PB->PI
#    â†’ ì„ íƒëª¨ë¸: PI ì£¼íš¨ê³¼ + PIÃ—health_label + NKÃ—price ìƒí˜¸ì‘ìš©
#
# ============================================================================

# ğŸ“Œ ìˆœì°¨ì¶”ì • 2ë‹¨ê³„ CSV íŒŒì¼ëª…ë§Œ ì§€ì •í•˜ì„¸ìš”!
INITIAL_PARAMS_CSV = 'st2_HC-PB_PB-PI1_PI2_results.csv'  # PI ì£¼íš¨ê³¼ë§Œ

# CSV íŒŒì¼ ê²½ë¡œ
csv_path = project_root / 'results' / 'sequential_stage_wise' / INITIAL_PARAMS_CSV

# CSV íŒŒì¼ëª…ê³¼ ë‚´ìš©ì—ì„œ ì„¤ì • ìë™ íŒŒì‹±
print("\n" + "=" * 70)
print("[AUTO] ìë™ ì„¤ì • ëª¨ë“œ: CSV íŒŒì¼ì—ì„œ ì„¤ì • ì¶”ì¶œ")
print("=" * 70)
print(f"CSV íŒŒì¼: {INITIAL_PARAMS_CSV}")

# 1. íŒŒì¼ëª…ì—ì„œ ê²½ë¡œ ì •ë³´ íŒŒì‹±
parsed_filename = parse_csv_filename(INITIAL_PARAMS_CSV)

# 2. íŒŒì¼ ë‚´ìš©ì—ì„œ ì„ íƒëª¨ë¸ ì„¤ì • íŒŒì‹± (ë” ì •í™•í•¨)
parsed_content = parse_csv_content(str(csv_path))

# ìë™ ì„¤ì • ì ìš©
PATHS = parsed_filename['stage1_paths']  # íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
MAIN_LVS = parsed_content['main_lvs']  # íŒŒì¼ ë‚´ìš©ì—ì„œ ì¶”ì¶œ (ë” ì •í™•)
MODERATION_LVS = []  # í˜„ì¬ ë¯¸ì§€ì›
LV_ATTRIBUTE_INTERACTIONS = parsed_content['lv_attribute_interactions']  # íŒŒì¼ ë‚´ìš©ì—ì„œ ì¶”ì¶œ

# íŒŒì‹± ê²°ê³¼ ì¶œë ¥
print(f"\n[íŒŒì‹± ê²°ê³¼]")
print(f"  1ë‹¨ê³„ ê²½ë¡œ (íŒŒì¼ëª…): {[k for k, v in PATHS.items() if v]}")
print(f"  ì£¼íš¨ê³¼ LV (íŒŒì¼ ë‚´ìš©): {MAIN_LVS}")
print(f"  ì¡°ì ˆíš¨ê³¼: {MODERATION_LVS if MODERATION_LVS else 'ì—†ìŒ'}")
print(f"  LV-Attribute ìƒí˜¸ì‘ìš© (íŒŒì¼ ë‚´ìš©): {LV_ATTRIBUTE_INTERACTIONS if LV_ATTRIBUTE_INTERACTIONS else 'ì—†ìŒ'}")
print("=" * 70 + "\n")

# âœ… CFA ê²°ê³¼ íŒŒì¼ ì‚¬ìš© (ì¸¡ì •ëª¨ë¸ë§Œ ì¶”ì •ëœ ê²°ê³¼)
# PKL íŒŒì¼ëª…ë„ ìë™ ìƒì„±
from model_config_utils import build_paths_from_config
_, path_name, _ = build_paths_from_config(PATHS)
# INITIAL_PARAMS_PKL = f'stage1_{path_name}_results.pkl'  # SEM ê²°ê³¼ (êµ¬ì¡°ëª¨ë¸ í¬í•¨)
INITIAL_PARAMS_PKL = 'cfa_results.pkl'  # âœ… CFA ê²°ê³¼ (ì¸¡ì •ëª¨ë¸ë§Œ)

# 4. GPU ë©”ëª¨ë¦¬ ì„¤ì •
CPU_MEMORY_THRESHOLD_MB = 2000  # CPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
GPU_MEMORY_THRESHOLD_MB = 5000  # GPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)

# 5. ì¶”ì • ì„¤ì •
N_DRAWS = 100  # Halton draws ìˆ˜
MAX_ITERATIONS = 1000  # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

# ============================================================================
# ğŸ¤– ìë™ ì²˜ë¦¬ ì˜ì—­ - ìˆ˜ì • ë¶ˆí•„ìš”
# ============================================================================

# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # 1. ê²½ë¡œ êµ¬ì„±
    hierarchical_paths, path_name, model_description = build_paths_from_config(PATHS)

    print("=" * 70)
    print(f"ë™ì‹œì¶”ì • (GPU ë°°ì¹˜): {model_description}")
    print("=" * 70)

    if hierarchical_paths:
        print(f"\n[1] ê²½ë¡œ êµ¬ì„± ì™„ë£Œ:")
        for i, path_dict in enumerate(hierarchical_paths, 1):
            target = path_dict['target']
            predictors = path_dict['predictors']
            pred_str = ' + '.join(predictors)
            print(f"    {i}. {pred_str} â†’ {target}")
    else:
        print(f"\n[1] Base Model (ê²½ë¡œ ì—†ìŒ)")

    # 2. ì„ íƒëª¨ë¸ ì„¤ì •
    print(f"\n[2] ì„ íƒëª¨ë¸ ì„¤ì •:")
    if MAIN_LVS:
        print(f"    ì£¼íš¨ê³¼ LV: {', '.join(MAIN_LVS)}")
    if MODERATION_LVS:
        print(f"    ì¡°ì ˆíš¨ê³¼ LV: {', '.join(MODERATION_LVS)}")
    if LV_ATTRIBUTE_INTERACTIONS:
        print(f"    LV-ì†ì„± ìƒí˜¸ì‘ìš©:")
        for lv, attr in LV_ATTRIBUTE_INTERACTIONS:
            print(f"      - {lv} Ã— {attr}")
    if not MAIN_LVS and not MODERATION_LVS and not LV_ATTRIBUTE_INTERACTIONS:
        print(f"    Base Model (ì ì¬ë³€ìˆ˜ ì—†ìŒ)")

    # 3. ë°ì´í„° ë¡œë“œ
    print("\n[3] ë°ì´í„° ë¡œë“œ:")
    data_path = project_root / 'data' / 'processed' / 'iclv' / 'integrated_data.csv'
    data = pd.read_csv(data_path)
    n_individuals = data['respondent_id'].nunique()
    print(f"    ë°ì´í„° shape: {data.shape}")
    print(f"    ì „ì²´ ê°œì¸ ìˆ˜: {n_individuals}")

    # 4. Config ìƒì„±
    print("\n[4] Config ìƒì„±:")

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: ì„ íƒëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬ ìƒì„±
    choice_config_dict = build_choice_config_dict(
        main_lvs=MAIN_LVS,
        lv_attribute_interactions=LV_ATTRIBUTE_INTERACTIONS
    )

    print(f"    ì„ íƒëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬: {choice_config_dict}")

    # Config ìƒì„± (ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ í•¨ìˆ˜ ì‚¬ìš©)
    config = create_sugar_substitute_multi_lv_config(
        custom_paths=hierarchical_paths,
        choice_config_overrides=choice_config_dict,
        n_draws=N_DRAWS,
        max_iterations=MAX_ITERATIONS,
        optimizer='L-BFGS-B',  # âœ… BHHH â†’ L-BFGS-Bë¡œ ë³€ê²½
        use_analytic_gradient=True,
        calculate_se=True,
        gradient_log_level='DETAILED',
        use_parameter_scaling=False  # âœ… ìŠ¤ì¼€ì¼ë§ ë¹„í™œì„±í™”
    )

    print(f"    Config ìƒì„± ì™„ë£Œ")
    print(f"    - ì ì¬ë³€ìˆ˜: 5ê°œ (HC, PB, PP, NK, PI)")
    print(f"    - ì¸¡ì • ë°©ë²•: ì—°ì†í˜• ì„ í˜• (Continuous Linear)")
    print(f"    - Halton draws: {N_DRAWS}")
    print(f"    - ìµœëŒ€ ë°˜ë³µ: {MAX_ITERATIONS}")
    print(f"    - ìµœì í™”: L-BFGS-B (Analytic Gradient)")
    print(f"    - íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§: ë¹„í™œì„±í™”")
    print(f"    - GPU ë°°ì¹˜ ì²˜ë¦¬: í™œì„±í™”")
    
    # 5. ëª¨ë¸ ìƒì„±
    print("\n[5] ëª¨ë¸ ìƒì„±:")
    with open("debug_choice_config.txt", "w", encoding="utf-8") as f:
        f.write(f"config.choice.main_lvs = {config.choice.main_lvs}\n")
        f.write(f"config.choice.lv_attribute_interactions = {config.choice.lv_attribute_interactions}\n")

    try:
        measurement_model = MultiLatentMeasurement(config.measurement_configs)
        structural_model = MultiLatentStructural(config.structural)
        choice_model = MultinomialLogitChoice(config.choice)
        print("    ì¸¡ì •ëª¨ë¸, êµ¬ì¡°ëª¨ë¸, ì„ íƒëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print("    - ì„ íƒëª¨ë¸: Multinomial Logit (MNL)")

        with open("debug_choice_config.txt", "a", encoding="utf-8") as f:
            f.write(f"choice_model.main_lvs = {choice_model.main_lvs}\n")
            f.write(f"choice_model.lv_attribute_interactions = {choice_model.lv_attribute_interactions}\n")
    except Exception as e:
        print(f"    [ERROR] ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # âœ… ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ë¡œë“œ (ë™ì‹œì¶”ì • ì „ìš©)
    # ì´ ë‹¨ê³„ëŠ” ì´ˆê¸°ê°’ ì„¤ì • ì „ì— ìˆ˜í–‰ë˜ì–´ì•¼ í•¨
    pkl_path = project_root / 'results' / 'sequential_stage_wise' / INITIAL_PARAMS_PKL

    if pkl_path.exists():
        print(f"\n    [INFO] ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ë¡œë“œ ì¤‘...")
        import pickle
        with open(pkl_path, 'rb') as f:
            cfa_results = pickle.load(f)

        if 'loadings' in cfa_results and 'measurement_errors' in cfa_results:
            loadings_df = cfa_results['loadings']
            errors_df = cfa_results['measurement_errors']
            intercepts_df = cfa_results.get('intercepts', None)  # âœ… ì ˆí¸ ë¡œë“œ

            # ê° ì ì¬ë³€ìˆ˜ì˜ ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ì„¤ì •
            for lv_name, model in measurement_model.models.items():
                lv_config = config.measurement_configs[lv_name]
                indicators = lv_config.indicators

                # zeta (ìš”ì¸ì ì¬ëŸ‰)
                zeta_values = []
                for indicator in indicators:
                    row = loadings_df[(loadings_df['lval'] == indicator) &
                                     (loadings_df['op'] == '~') &
                                     (loadings_df['rval'] == lv_name)]

                    if not row.empty:
                        zeta_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator} ~ {lv_name} ìš”ì¸ì ì¬ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©")
                        zeta_values.append(1.0)

                # sigma_sq (ì˜¤ì°¨ë¶„ì‚°)
                sigma_sq_values = []
                for indicator in indicators:
                    row = errors_df[(errors_df['lval'] == indicator) &
                                   (errors_df['op'] == '~~') &
                                   (errors_df['rval'] == indicator)]

                    if not row.empty:
                        sigma_sq_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator}ì˜ ì˜¤ì°¨ë¶„ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
                        sigma_sq_values.append(0.5)

                # âœ… alpha (ì ˆí¸)
                alpha_values = []
                if intercepts_df is not None:
                    for indicator in indicators:
                        row = intercepts_df[(intercepts_df['lval'] == indicator) &
                                           (intercepts_df['op'] == '~') &
                                           (intercepts_df['rval'] == '1')]

                        if not row.empty:
                            alpha_values.append(float(row['Estimate'].iloc[0]))
                        else:
                            print(f"    [WARNING] {indicator}ì˜ ì ˆí¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.0 ì‚¬ìš©")
                            alpha_values.append(0.0)
                else:
                    print(f"    [WARNING] CFA ê²°ê³¼ì— ì ˆí¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì ˆí¸ì„ 0.0ìœ¼ë¡œ ì„¤ì •")
                    alpha_values = [0.0] * len(indicators)

                # ì¸¡ì •ëª¨ë¸ configì— CFA ê²°ê³¼ ì„¤ì •
                model.config.zeta = np.array(zeta_values)
                model.config.sigma_sq = np.array(sigma_sq_values)
                model.config.alpha = np.array(alpha_values)  # âœ… ì ˆí¸ ì¶”ê°€

                print(f"    [INFO] {lv_name}: zeta={len(zeta_values)}ê°œ, sigma_sq={len(sigma_sq_values)}ê°œ, alpha={len(alpha_values)}ê°œ ë¡œë“œ ì™„ë£Œ")

            print(f"    [SUCCESS] ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ë¡œë“œ ì™„ë£Œ (ì ˆí¸ í¬í•¨)")
        else:
            print(f"    [WARNING] CFA ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # 6. Estimator ìƒì„±
    print("\n[6] Estimator ìƒì„±:")
    try:
        estimator = SimultaneousGPUBatchEstimator(
            config,
            use_gpu=True,
            memory_monitor_cpu_threshold_mb=CPU_MEMORY_THRESHOLD_MB,
            memory_monitor_gpu_threshold_mb=GPU_MEMORY_THRESHOLD_MB
        )
        print(f"    ë™ì‹œì¶”ì • GPU ë°°ì¹˜ Estimator ìƒì„± ì™„ë£Œ")
        print(f"    - ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§: CPU {CPU_MEMORY_THRESHOLD_MB}MB, GPU {GPU_MEMORY_THRESHOLD_MB}MB")
    except Exception as e:
        print(f"    [ERROR] Estimator ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 7. ì´ˆê¸°ê°’ ì„¤ì •
    print("\n[7] ì´ˆê¸°ê°’ ì„¤ì •:")
    print("    [INFO] ì¸¡ì •ëª¨ë¸ (zeta, sigma_sq): CFA ê²°ê³¼ì—ì„œ ë¡œë“œ (ì´ë¯¸ ì™„ë£Œ)")
    print("    [INFO] êµ¬ì¡°ëª¨ë¸ & ì„ íƒëª¨ë¸: 0.1ë¡œ ì´ˆê¸°í™”")

    initial_params = None

    if pkl_path.exists():
        print(f"\n    CFA ê²°ê³¼ ë¡œë“œ: {INITIAL_PARAMS_PKL}")

        # 1. CFA ê²°ê³¼ì—ì„œ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ
        import pickle
        with open(pkl_path, 'rb') as f:
            cfa_results = pickle.load(f)

        # CFA ê²°ê³¼ëŠ” ì§ì ‘ loadingsì™€ measurement_errorsë¥¼ í¬í•¨
        if 'loadings' in cfa_results and 'measurement_errors' in cfa_results:
            print(f"    [INFO] CFA ê²°ê³¼ì—ì„œ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì¶œ")

            loadings_df = cfa_results['loadings']
            errors_df = cfa_results['measurement_errors']
            intercepts_df = cfa_results.get('intercepts', None)  # âœ… ì ˆí¸ ë¡œë“œ

            # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            measurement_dict = {}
            for lv_name, lv_config in config.measurement_configs.items():
                indicators = lv_config.indicators

                # âœ… zeta (ìš”ì¸ì ì¬ëŸ‰) - CFA loadingsì—ì„œ ì¶”ì¶œ
                zeta_values = []
                for indicator in indicators:
                    row = loadings_df[(loadings_df['lval'] == indicator) &
                                     (loadings_df['op'] == '~') &
                                     (loadings_df['rval'] == lv_name)]

                    if not row.empty:
                        zeta_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator} ~ {lv_name} ìš”ì¸ì ì¬ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©")
                        zeta_values.append(1.0)

                # âœ… sigma_sq (ì˜¤ì°¨ë¶„ì‚°) - CFA measurement_errorsì—ì„œ ì¶”ì¶œ
                sigma_sq_values = []
                for indicator in indicators:
                    row = errors_df[(errors_df['lval'] == indicator) &
                                   (errors_df['op'] == '~~') &
                                   (errors_df['rval'] == indicator)]

                    if not row.empty:
                        sigma_sq_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator}ì˜ ì˜¤ì°¨ë¶„ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
                        sigma_sq_values.append(0.5)

                # âœ… alpha (ì ˆí¸) - CFA interceptsì—ì„œ ì¶”ì¶œ
                alpha_values = []
                if intercepts_df is not None:
                    for indicator in indicators:
                        row = intercepts_df[(intercepts_df['lval'] == indicator) &
                                           (intercepts_df['op'] == '~') &
                                           (intercepts_df['rval'] == '1')]

                        if not row.empty:
                            alpha_values.append(float(row['Estimate'].iloc[0]))
                        else:
                            print(f"    [WARNING] {indicator}ì˜ ì ˆí¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.0 ì‚¬ìš©")
                            alpha_values.append(0.0)
                else:
                    print(f"    [WARNING] CFA ê²°ê³¼ì— ì ˆí¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì ˆí¸ì„ 0.0ìœ¼ë¡œ ì„¤ì •")
                    alpha_values = [0.0] * len(indicators)

                measurement_dict[lv_name] = {
                    'zeta': np.array(zeta_values),
                    'sigma_sq': np.array(sigma_sq_values),
                    'alpha': np.array(alpha_values)  # âœ… ì ˆí¸ ì¶”ê°€
                }

                # âœ… ë¡œë“œëœ ê°’ ì¶œë ¥
                print(f"    [INFO] {lv_name} ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ:")
                print(f"      - zeta (ìš”ì¸ì ì¬ëŸ‰): {zeta_values}")
                print(f"      - sigma_sq (ì˜¤ì°¨ë¶„ì‚°): {sigma_sq_values}")
                print(f"      - alpha (ì ˆí¸): {alpha_values}")

            # 2. êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”
            print(f"    [INFO] êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”")
            structural_dict = {}
            for path in config.structural.hierarchical_paths:
                target_lv = path['target']
                predictors = path['predictors']

                for pred_lv in predictors:
                    param_name = f'gamma_{pred_lv}_to_{target_lv}'
                    structural_dict[param_name] = 0.1
                    print(f"      - {param_name}: 0.1")

            # 3. ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”
            print(f"    [INFO] ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”")
            choice_dict = {}

            # Multinomial Logitì˜ ëŒ€ì•ˆ ì´ë¦„ (í•˜ë“œì½”ë”©)
            # opt-outì€ ê¸°ì¤€ ëŒ€ì•ˆì´ë¯€ë¡œ ì œì™¸
            alternatives = ['sugar', 'sugar_free']  # opt-out ì œì™¸

            # ASC (Alternative-Specific Constants)
            for alt in alternatives:
                param_name = f'asc_{alt}'
                choice_dict[param_name] = 0.1
                print(f"      - {param_name}: 0.1")

            # beta (ì†ì„± ê³„ìˆ˜) - ëª¨ë“  ëŒ€ì•ˆì— ê³µí†µ ì ìš©
            for attr in config.choice.choice_attributes:
                param_name = f'beta_{attr}'
                choice_dict[param_name] = 0.1
                print(f"      - {param_name}: 0.1")

            # theta (LV ì£¼íš¨ê³¼) - ê° ëŒ€ì•ˆë³„ë¡œ
            if config.choice.main_lvs:
                for lv in config.choice.main_lvs:
                    for alt in alternatives:
                        param_name = f'theta_{alt}_{lv}'
                        choice_dict[param_name] = 0.1
                        print(f"      - {param_name}: 0.1")

            # gamma (LV-ì†ì„± ìƒí˜¸ì‘ìš©) - ê° ëŒ€ì•ˆë³„ë¡œ
            if config.choice.lv_attribute_interactions:
                for interaction in config.choice.lv_attribute_interactions:
                    lv = interaction['lv']
                    attr = interaction['attribute']
                    for alt in alternatives:
                        param_name = f'gamma_{alt}_{lv}_{attr}'
                        choice_dict[param_name] = 0.1
                        print(f"      - {param_name}: 0.1")

            # âœ… ìµœì¢… ì´ˆê¸°ê°’ ë”•ì…”ë„ˆë¦¬ êµ¬ì„± (ì¸¡ì •ëª¨ë¸ ì œì™¸)
            # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ì´ë¯¸ measurement_model ê°ì²´ì— ë¡œë“œë˜ì–´ ìˆìŒ
            initial_params = {
                'structural': structural_dict,
                'choice': choice_dict
                # âŒ 'measurement' í‚¤ ì œê±°: ë™ì‹œì¶”ì •ì—ì„œëŠ” ë¶ˆí•„ìš”
                #    ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” measurement_model.models[lv_name].configì— ì´ë¯¸ ë¡œë“œë¨
            }

            # ê²°ê³¼ ì¶œë ¥
            print(f"\n    [SUCCESS] ì´ˆê¸°ê°’ ì„¤ì • ì™„ë£Œ:")
            print(f"      - ì¸¡ì •ëª¨ë¸: {len(measurement_dict)} LVs (measurement_model ê°ì²´ì— ë¡œë“œë¨)")
            for lv_name in list(measurement_dict.keys())[:3]:
                lv_params = measurement_dict[lv_name]
                n_zeta = len(lv_params['zeta'])
                print(f"        * {lv_name}: zeta={n_zeta}ê°œ")

            print(f"      - êµ¬ì¡°ëª¨ë¸: {len(structural_dict)}ê°œ íŒŒë¼ë¯¸í„° (0.1ë¡œ ì´ˆê¸°í™”)")
            print(f"      - ì„ íƒëª¨ë¸: {len(choice_dict)}ê°œ íŒŒë¼ë¯¸í„° (0.1ë¡œ ì´ˆê¸°í™”)")

        else:
            print(f"    [ERROR] CFA ê²°ê³¼ì— loadings ë˜ëŠ” measurement_errorsê°€ ì—†ìŠµë‹ˆë‹¤.")
            raise ValueError("CFA ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. loadingsì™€ measurement_errorsê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        print(f"    [WARNING] CFA ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INITIAL_PARAMS_PKL}")
        raise FileNotFoundError(f"CFA ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")

    # 8. ì¶”ì • ì‹¤í–‰
    print("\n[8] ë™ì‹œì¶”ì • ì‹¤í–‰:")
    print("    [INFO] ì¶”ì • ëª¨ë“œ: êµ¬ì¡°ëª¨ë¸ + ì„ íƒëª¨ë¸ë§Œ ì¶”ì •")
    print("    [INFO] ì¸¡ì •ëª¨ë¸: ê³ ì •ê°’ ì‚¬ìš© (ì¶”ì • ì•ˆ í•¨)")
    print("    [INFO] GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ë™ì‹œì— ì¶”ì •í•©ë‹ˆë‹¤.")
    print("    [ì£¼ì˜] 5-10ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")

    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = project_root / 'results' / f'simultaneous_estimation_log_{timestamp}.txt'
    print(f"    ë¡œê·¸ íŒŒì¼: {log_file.name}")

    start_time = time.time()

    try:
        print(f"\n    [INFO] ì¶”ì • ì‹œì‘...")
        print(f"    [INFO] ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì •:")
        if initial_params:
            print(f"      - ì¸¡ì •ëª¨ë¸: PKLì—ì„œ ë¡œë“œ (ê³ ì •)")
            print(f"      - êµ¬ì¡°ëª¨ë¸: 0.1ë¡œ ì´ˆê¸°í™” (ì¶”ì • ëŒ€ìƒ)")
            print(f"      - ì„ íƒëª¨ë¸: 0.1ë¡œ ì´ˆê¸°í™” (ì¶”ì • ëŒ€ìƒ)")
        else:
            print(f"      - ìë™ ì´ˆê¸°í™” ì‚¬ìš©")

        result = estimator.estimate(
            data=data,
            measurement_model=measurement_model,
            structural_model=structural_model,
            choice_model=choice_model,
            log_file=str(log_file),
            initial_params=initial_params
            # âœ… ë™ì‹œì¶”ì •ì€ í•­ìƒ ì¸¡ì •ëª¨ë¸ ê³ ì • (ì„¤ì • ë¶ˆí•„ìš”)
        )

        print(f"    [SUCCESS] ì¶”ì • ì™„ë£Œ!")

        elapsed_time = time.time() - start_time

        # 9. ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 70)
        print("ì¶”ì • ê²°ê³¼")
        print("=" * 70)
        print(f"\nì¶”ì • ì‹œê°„: {elapsed_time/60:.2f}ë¶„ ({elapsed_time:.1f}ì´ˆ)")
        print(f"ìˆ˜ë ´ ì—¬ë¶€: {result['success']}")
        print(f"ë°˜ë³µ íšŸìˆ˜: {result.get('n_iterations', result.get('iterations', 'N/A'))}")
        print(f"ìµœì¢… ë¡œê·¸ìš°ë„: {result['log_likelihood']:.4f}")

        # ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½
        if hasattr(estimator, 'memory_monitor'):
            print("\n" + "=" * 70)
            print("ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½")
            print("=" * 70)
            mem_summary = estimator.memory_monitor.get_memory_summary()
            print(f"í˜„ì¬ CPU ë©”ëª¨ë¦¬: {mem_summary['current_cpu_mb']:.1f}MB")
            if mem_summary['current_gpu_mb'] is not None:
                print(f"í˜„ì¬ GPU ë©”ëª¨ë¦¬: {mem_summary['current_gpu_mb']:.1f}MB")
            if 'cpu_max_mb' in mem_summary:
                print(f"ìµœëŒ€ CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_max_mb']:.1f}MB")
                print(f"í‰ê·  CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_avg_mb']:.1f}MB")
            if 'gpu_max_mb' in mem_summary:
                print(f"ìµœëŒ€ GPU ë©”ëª¨ë¦¬: {mem_summary['gpu_max_mb']:.1f}MB")
                print(f"í‰ê·  GPU ë©”ëª¨ë¦¬: {mem_summary['gpu_avg_mb']:.1f}MB")

        # 10. ê²°ê³¼ ì €ì¥
        print("\n[10] ê²°ê³¼ ì €ì¥:")
        output_dir = project_root / 'results'
        output_dir.mkdir(exist_ok=True)

        # íŒŒì¼ëª… ìƒì„± (ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ ê·œì¹™)
        csv_filename = generate_simultaneous_filename(path_name, config, timestamp)
        csv_file = output_dir / csv_filename

        # íŒŒë¼ë¯¸í„° ì €ì¥ (npy)
        npy_filename = csv_filename.replace('.csv', '.npy')
        params_file = output_dir / npy_filename
        np.save(params_file, result['raw_params'])

        # íŒŒë¼ë¯¸í„° í†µê³„ ì¶”ì¶œ
        print(f"    íŒŒë¼ë¯¸í„° í†µê³„ ì¶”ì¶œ ì¤‘...")
        print(f"    [DEBUG] result ë”•ì…”ë„ˆë¦¬ í‚¤: {list(result.keys())}")
        print(f"    [DEBUG] 'parameters' in result: {'parameters' in result}")
        print(f"    [DEBUG] 'parameter_statistics' in result: {'parameter_statistics' in result}")
        if 'parameters' in result:
            print(f"    [DEBUG] parameters í‚¤: {list(result['parameters'].keys())}")
        if 'parameter_statistics' in result:
            print(f"    [DEBUG] parameter_statistics í‚¤: {list(result['parameter_statistics'].keys())}")

        param_list = []

        # âœ… ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ì´ë¯¸ ë¡œë“œëœ CFA ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        print(f"    ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ CFA ê²°ê³¼ì—ì„œ ì¶”ì¶œ ì¤‘...")

        if 'loadings' in cfa_results and 'measurement_errors' in cfa_results:
            loadings_df = cfa_results['loadings']
            errors_df = cfa_results['measurement_errors']

            # ìš”ì¸ì ì¬ëŸ‰ (loading)
            for _, row in loadings_df.iterrows():
                indicator = row['lval']
                lv_name = row['rval']
                param_list.append({
                    'Coefficient': f'Î¶_{lv_name}_{indicator}',
                    'Estimate': row['Estimate'],
                    'Std. Err.': row['Std. Err'] if pd.notna(row['Std. Err']) else '-',
                    'P. Value': row['p-value'] if pd.notna(row['p-value']) else '-'
                })

            # ì˜¤ì°¨ë¶„ì‚° (error_variance)
            for _, row in errors_df.iterrows():
                indicator = row['lval']
                # lval í˜•ì‹: "q10~~q10" -> "q10"ìœ¼ë¡œ ë³€í™˜
                indicator_clean = indicator.split('~~')[0]

                # í•´ë‹¹ ì§€í‘œê°€ ì–´ëŠ ì ì¬ë³€ìˆ˜ì— ì†í•˜ëŠ”ì§€ ì°¾ê¸°
                lv_name = None
                for lv, lv_config in config.measurement_configs.items():
                    if indicator_clean in lv_config.indicators:
                        lv_name = lv
                        break

                if lv_name:
                    param_list.append({
                        'Coefficient': f'ÏƒÂ²_{lv_name}_{indicator_clean}',
                        'Estimate': row['Estimate'],
                        'Std. Err.': row['Std. Err'] if pd.notna(row['Std. Err']) else '-',
                        'P. Value': row['p-value'] if pd.notna(row['p-value']) else '-'
                    })

            print(f"    âœ“ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° {len(param_list)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        else:
            print(f"    [WARNING] CFA ê²°ê³¼ì— loadings ë˜ëŠ” measurement_errorsê°€ ì—†ìŠµë‹ˆë‹¤.")
            print(f"    ë™ì‹œì¶”ì • ê²°ê³¼ì—ì„œ ì¶”ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤...")

            # ëŒ€ì²´: ë™ì‹œì¶”ì • ê²°ê³¼ì—ì„œ ì¶”ì¶œ (í‘œì¤€ì˜¤ì°¨ ì—†ìŒ)
            if 'parameter_statistics' in result and 'measurement' in result['parameter_statistics']:
                stats = result['parameter_statistics']
                for lv_name, lv_stats in stats['measurement'].items():
                    # zeta (ìš”ì¸ì ì¬ëŸ‰)
                    if 'zeta' in lv_stats:
                        zeta_stats = lv_stats['zeta']
                        for i in range(len(zeta_stats['estimate'])):
                            indicator_name = config.measurement_configs[lv_name].indicators[i]
                            param_list.append({
                                'Coefficient': f'Î¶_{lv_name}_{indicator_name}',
                                'Estimate': zeta_stats['estimate'][i],
                                'Std. Err.': zeta_stats.get('std_error', ['-'] * len(zeta_stats['estimate']))[i],
                                'P. Value': zeta_stats.get('p_value', ['-'] * len(zeta_stats['estimate']))[i]
                            })

                    # sigma_sq (ì˜¤ì°¨ë¶„ì‚°)
                    if 'sigma_sq' in lv_stats:
                        sigma_sq_stats = lv_stats['sigma_sq']
                        for i in range(len(sigma_sq_stats['estimate'])):
                            indicator_name = config.measurement_configs[lv_name].indicators[i]
                            param_list.append({
                                'Coefficient': f'ÏƒÂ²_{lv_name}_{indicator_name}',
                                'Estimate': sigma_sq_stats['estimate'][i],
                                'Std. Err.': sigma_sq_stats.get('std_error', ['-'] * len(sigma_sq_stats['estimate']))[i],
                                'P. Value': sigma_sq_stats.get('p_value', ['-'] * len(sigma_sq_stats['estimate']))[i]
                            })

        # âœ… êµ¬ì¡°ëª¨ë¸ ë° ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ë™ì‹œì¶”ì • ê²°ê³¼ì—ì„œ ì¶”ì¶œ
        # parameter_statisticsê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ parametersì—ì„œ ì§ì ‘ ì¶”ì¶œ
        if 'parameter_statistics' in result and result['parameter_statistics']:
            print(f"    parameter_statisticsì—ì„œ êµ¬ì¡°ëª¨ë¸/ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì¤‘...")
            stats = result['parameter_statistics']

            # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„° (ê³„ì¸µì  êµ¬ì¡°)
            if 'structural' in stats:
                struct = stats['structural']
                for key, value in struct.items():
                    if key.startswith('gamma_'):
                        param_list.append({
                            'Coefficient': f'Î³_{key.replace("gamma_", "")}',
                            'Estimate': value['estimate'],
                            'Std. Err.': value.get('std_error', '-'),
                            'P. Value': value.get('p_value', '-')
                        })

            # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
            if 'choice' in stats:
                choice = stats['choice']

                # âœ… í‰íƒ„í™”ëœ êµ¬ì¡°: ê° íŒŒë¼ë¯¸í„°ê°€ ì§ì ‘ í‚¤ë¡œ ìˆìŒ
                # ì˜ˆ: {'asc_sugar': {...}, 'asc_sugar_free': {...}, 'beta_health_label': {...}, ...}
                for param_name, param_stats in choice.items():
                    # íŒŒë¼ë¯¸í„° ì´ë¦„ ë³€í™˜ (ê·¸ë¦¬ìŠ¤ ë¬¸ì ì‚¬ìš©)
                    if param_name.startswith('beta_'):
                        display_name = f'Î²_{param_name.replace("beta_", "")}'
                    elif param_name.startswith('theta_'):
                        display_name = param_name  # thetaëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    else:
                        display_name = param_name  # asc, gamma ë“±ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©

                    param_list.append({
                        'Coefficient': display_name,
                        'Estimate': param_stats['estimate'],
                        'Std. Err.': param_stats.get('std_error', '-'),
                        'P. Value': param_stats.get('p_value', '-')
                    })

        # parameter_statisticsê°€ ì—†ìœ¼ë©´ parametersì—ì„œ ì§ì ‘ ì¶”ì¶œ (í‘œì¤€ì˜¤ì°¨ ì—†ìŒ)
        elif 'parameters' in result:
            print(f"    [WARNING] parameter_statisticsê°€ ì—†ìŠµë‹ˆë‹¤. parametersì—ì„œ ì§ì ‘ ì¶”ì¶œí•©ë‹ˆë‹¤ (í‘œì¤€ì˜¤ì°¨ ì—†ìŒ).")
            params = result['parameters']

            # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
            if 'structural' in params:
                struct = params['structural']
                for key, value in struct.items():
                    if key.startswith('gamma_'):
                        param_list.append({
                            'Coefficient': f'Î³_{key.replace("gamma_", "")}',
                            'Estimate': value,
                            'Std. Err.': '-',
                            'P. Value': '-'
                        })

            # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
            if 'choice' in params:
                choice = params['choice']

                # ASC
                if 'asc' in choice:
                    for alt_name, alt_value in choice['asc'].items():
                        param_list.append({
                            'Coefficient': f'asc_{alt_name}',
                            'Estimate': alt_value,
                            'Std. Err.': '-',
                            'P. Value': '-'
                        })

                # beta (ì†ì„± ê³„ìˆ˜)
                if 'beta' in choice:
                    beta_values = choice['beta']
                    if isinstance(beta_values, (list, np.ndarray)):
                        for i, attr in enumerate(config.choice.choice_attributes):
                            param_list.append({
                                'Coefficient': f'Î²_{attr}',
                                'Estimate': beta_values[i],
                                'Std. Err.': '-',
                                'P. Value': '-'
                            })

                # theta (LV ì£¼íš¨ê³¼)
                if 'theta' in choice:
                    for theta_name, theta_value in choice['theta'].items():
                        param_list.append({
                            'Coefficient': f'theta_{theta_name}',
                            'Estimate': theta_value,
                            'Std. Err.': '-',
                            'P. Value': '-'
                        })

                # gamma (LV-ì†ì„± ìƒí˜¸ì‘ìš©)
                if 'gamma' in choice:
                    for gamma_name, gamma_value in choice['gamma'].items():
                        param_list.append({
                            'Coefficient': f'gamma_{gamma_name}',
                            'Estimate': gamma_value,
                            'Std. Err.': '-',
                            'P. Value': '-'
                        })
        else:
            print(f"    [ERROR] parametersì™€ parameter_statistics ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤!")

        print(f"    âœ“ ì´ {len(param_list)}ê°œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ")

        # DataFrame ìƒì„±
        df_params = pd.DataFrame(param_list)

        # Estimation statistics ì¶”ê°€
        n_iter = result.get('n_iterations', result.get('iterations', 'N/A'))
        stats_list = [
            {'Coefficient': '', 'Estimate': '', 'Std. Err.': '', 'P. Value': ''},
            {'Coefficient': 'Estimation statistics', 'Estimate': '', 'Std. Err.': '', 'P. Value': ''},
            {'Coefficient': 'Iterations', 'Estimate': n_iter,
             'Std. Err.': 'LL (final)', 'P. Value': f"{result['log_likelihood']:.2f}"},
            {'Coefficient': 'AIC', 'Estimate': f"{result['aic']:.2f}",
             'Std. Err.': 'BIC', 'P. Value': f"{result['bic']:.2f}"}
        ]

        df_stats = pd.DataFrame(stats_list)
        df_combined = pd.concat([df_params, df_stats], ignore_index=True)

        # CSV ì €ì¥ (ìƒì„¸ íŒŒë¼ë¯¸í„°)
        df_combined.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"    âœ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        print(f"      - íŒŒë¼ë¯¸í„° ìˆ˜: {len(param_list)}")
        print(f"      - ìµœì¢… LL: {result['log_likelihood']:.2f}")
        print(f"      - AIC: {result['aic']:.2f}, BIC: {result['bic']:.2f}")

    except Exception as e:
        print(f"\n[ERROR] ì¶”ì • ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\n" + "=" * 70)
    print("ë™ì‹œì¶”ì • ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nëª¨ë¸ êµ¬ì„±:")
    print(f"  - ê²½ë¡œ: {model_description}")
    if MAIN_LVS or MODERATION_LVS or LV_ATTRIBUTE_INTERACTIONS:
        print(f"  - ì„ íƒëª¨ë¸ LV: {', '.join(MAIN_LVS) if MAIN_LVS else 'None'}")
    print(f"\nê²°ê³¼ íŒŒì¼:")
    print(f"  - {csv_filename}")
    print(f"  - {npy_filename}")
    print(f"  - {log_file.name}")


if __name__ == '__main__':
    main()

