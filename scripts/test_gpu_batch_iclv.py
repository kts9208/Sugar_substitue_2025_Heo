"""
ë™ì‹œì¶”ì • (Simultaneous Estimation) - GPU ë°°ì¹˜ ì²˜ë¦¬

ì´ íŒŒì¼ í•˜ë‚˜ë¡œ ëª¨ë“  ë™ì‹œì¶”ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ê²½ë¡œ ì„¤ì •ê³¼ ì„ íƒëª¨ë¸ ì„¤ì •ë§Œ ë³€ê²½í•˜ë©´ ë‹¤ì–‘í•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
1. PATHS ë”•ì…”ë„ˆë¦¬ì—ì„œ ì›í•˜ëŠ” ê²½ë¡œë¥¼ True/Falseë¡œ ì„¤ì •
2. MAIN_LVS, MODERATION_LVS, LV_ATTRIBUTE_INTERACTIONSì—ì„œ ì„ íƒëª¨ë¸ ì„¤ì •
3. ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ê²½ë¡œ êµ¬ì„± ë° íŒŒì¼ëª… ìƒì„±
4. ê²°ê³¼ íŒŒì¼ëª…: simultaneous_{ê²½ë¡œëª…}_{ì„ íƒëª¨ë¸LV}_results_{timestamp}.csv

ì£¼ìš” ê¸°ëŠ¥:
- ê²½ë¡œ ì„¤ì •: True/Falseë¡œ ê°„ë‹¨í•˜ê²Œ ì¼œê³  ë„ê¸°
- ì„ íƒëª¨ë¸ ì„¤ì •: ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ ë°©ì‹
- ìë™ íŒŒì¼ëª… ìƒì„±: ê²½ë¡œì™€ ì„ íƒëª¨ë¸ì— ë”°ë¼ íŒŒì¼ëª… ìë™ ìƒì„±
- ì´ˆê¸°ê°’ ë¡œë“œ: ìˆœì°¨ì¶”ì • ê²°ê³¼ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš© (ì„ íƒì‚¬í•­)
- GPU ë°°ì¹˜ ì²˜ë¦¬: ê³ ì† ë™ì‹œì¶”ì •

Author: Sugar Substitute Research Team
Date: 2025-11-17
"""

import sys
import pandas as pd
import numpy as np
import time
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ê³µí†µ ìœ í‹¸ë¦¬í‹° import
sys.path.insert(0, str(project_root / 'examples'))
from model_config_utils import (
    build_paths_from_config,
    build_choice_config_dict,
    generate_simultaneous_filename
)

from src.analysis.hybrid_choice_model.iclv_models.iclv_config import (
    MeasurementConfig,
    ChoiceConfig,
    EstimationConfig
)
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_config import (
    MultiLatentStructuralConfig,
    MultiLatentConfig,
    create_sugar_substitute_multi_lv_config
)
from src.analysis.hybrid_choice_model.iclv_models.simultaneous_gpu_batch_estimator import SimultaneousGPUBatchEstimator
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_measurement import MultiLatentMeasurement
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_structural import MultiLatentStructural
from src.analysis.hybrid_choice_model.iclv_models.choice_equations import MultinomialLogitChoice


# ============================================================================
# ğŸ¯ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ - ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ============================================================================

# 1. ê²½ë¡œ ì„¤ì •: True/Falseë¡œ ê°„ë‹¨í•˜ê²Œ ì¼œê³  ë„ê¸°
PATHS = {
    'HC->PB': True,   # ê±´ê°•ê´€ì‹¬ë„ â†’ ê±´ê°•ìœ ìµì„±
    'HC->PP': False,  # ê±´ê°•ê´€ì‹¬ë„ â†’ ê°€ê²©ìˆ˜ì¤€
    'HC->PI': False,  # ê±´ê°•ê´€ì‹¬ë„ â†’ êµ¬ë§¤ì˜ë„
    'PB->PI': True,   # ê±´ê°•ìœ ìµì„± â†’ êµ¬ë§¤ì˜ë„
    'PP->PI': False,  # ê°€ê²©ìˆ˜ì¤€ â†’ êµ¬ë§¤ì˜ë„
    'NK->PI': False,  # ì˜ì–‘ì§€ì‹ â†’ êµ¬ë§¤ì˜ë„
}

# 2. ì„ íƒëª¨ë¸ ì„¤ì • (ìˆœì°¨ì¶”ì • 2ë‹¨ê³„ì™€ ë™ì¼í•œ ì„¤ì •)
# âœ… ìˆœì°¨ì¶”ì • 2ë‹¨ê³„(sequential_stage2_with_extended_model.py)ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
# âœ… ì´ˆê¸°ê°’ íŒŒì¼(INITIAL_PARAMS_FILE)ê³¼ ì¼ì¹˜í•´ì•¼ í•¨!

# ğŸ“Œ ì ì¬ë³€ìˆ˜ ì£¼íš¨ê³¼ (ì›í•˜ëŠ” ì ì¬ë³€ìˆ˜ë§Œ ì¶”ê°€)
# ì˜ˆì‹œ: [] = Base Model (ì ì¬ë³€ìˆ˜ ì—†ìŒ)
#      ['purchase_intention'] = Base + PI ì£¼íš¨ê³¼
#      ['purchase_intention', 'nutrition_knowledge'] = Base + PI + NK ì£¼íš¨ê³¼
MAIN_LVS = ['purchase_intention', 'nutrition_knowledge']  # Auto-generated

# ğŸ“Œ ì¡°ì ˆíš¨ê³¼ (ì ì¬ë³€ìˆ˜ 2ê°œ ì„¸íŠ¸)
# ì˜ˆì‹œ: [('perceived_price', 'nutrition_knowledge')] = PPì™€ NKì˜ ì¡°ì ˆíš¨ê³¼
MODERATION_LVS = []  # Auto-generated

# ğŸ“Œ LV-Attribute ìƒí˜¸ì‘ìš© (ì ì¬ë³€ìˆ˜-ì†ì„± 2ê°œ ì„¸íŠ¸)
# ì˜ˆì‹œ: [('purchase_intention', 'price')] = PI Ã— price ìƒí˜¸ì‘ìš©
#      [('purchase_intention', 'price'), ('nutrition_knowledge', 'health_label')]
LV_ATTRIBUTE_INTERACTIONS = [('purchase_intention', 'health_label'), ('nutrition_knowledge', 'price')]  # Auto-generated

# 3. ì´ˆê¸°ê°’ ì„¤ì •
# ìˆœì°¨ì¶”ì • ê²°ê³¼ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš© (íŒŒì¼ëª… ì§€ì •)
# Noneì´ë©´ ìë™ ì´ˆê¸°í™” ì‚¬ìš©
# âš ï¸ ì¤‘ìš”: ì´ˆê¸°ê°’ íŒŒì¼ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ìœ„ì˜ ì„ íƒëª¨ë¸ ì„¤ì •(MAIN_LVS, LV_ATTRIBUTE_INTERACTIONS)ì´
#          ìˆœì°¨ì¶”ì • 2ë‹¨ê³„(sequential_stage2_with_extended_model.py)ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤!
INITIAL_PARAMS_FILE = None  # âœ… ì¼ë‹¨ ìë™ ì´ˆê¸°í™”ë¡œ í…ŒìŠ¤íŠ¸ (íŒŒì¼ í˜•ì‹ ë¬¸ì œë¡œ ì¸í•´)

# 4. GPU ë©”ëª¨ë¦¬ ì„¤ì •
CPU_MEMORY_THRESHOLD_MB = 2000  # CPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
GPU_MEMORY_THRESHOLD_MB = 5000  # GPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)

# 5. ì¶”ì • ì„¤ì •
N_DRAWS = 100  # Halton draws ìˆ˜
MAX_ITERATIONS = 1000  # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

# ============================================================================
# ğŸ¤– ìë™ ì²˜ë¦¬ ì˜ì—­ - ìˆ˜ì • ë¶ˆí•„ìš”
# ============================================================================


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # 1. ê²½ë¡œ êµ¬ì„±
    hierarchical_paths, path_name, model_description = build_paths_from_config(PATHS)

    print("=" * 70)
    print(f"ë™ì‹œì¶”ì • (GPU ë°°ì¹˜): {model_description}")
    print("=" * 70)

    if hierarchical_paths:
        print(f"\n[1] ê²½ë¡œ êµ¬ì„± ì™„ë£Œ:")
        for i, path_dict in enumerate(hierarchical_paths, 1):
            target = path_dict['target']
            predictors = path_dict['predictors']
            pred_str = ' + '.join(predictors)
            print(f"    {i}. {pred_str} â†’ {target}")
    else:
        print(f"\n[1] Base Model (ê²½ë¡œ ì—†ìŒ)")

    # 2. ì„ íƒëª¨ë¸ ì„¤ì •
    print(f"\n[2] ì„ íƒëª¨ë¸ ì„¤ì •:")
    if MAIN_LVS:
        print(f"    ì£¼íš¨ê³¼ LV: {', '.join(MAIN_LVS)}")
    if MODERATION_LVS:
        print(f"    ì¡°ì ˆíš¨ê³¼ LV: {', '.join(MODERATION_LVS)}")
    if LV_ATTRIBUTE_INTERACTIONS:
        print(f"    LV-ì†ì„± ìƒí˜¸ì‘ìš©:")
        for lv, attr in LV_ATTRIBUTE_INTERACTIONS:
            print(f"      - {lv} Ã— {attr}")
    if not MAIN_LVS and not MODERATION_LVS and not LV_ATTRIBUTE_INTERACTIONS:
        print(f"    Base Model (ì ì¬ë³€ìˆ˜ ì—†ìŒ)")

    # 3. ë°ì´í„° ë¡œë“œ
    print("\n[3] ë°ì´í„° ë¡œë“œ:")
    data_path = project_root / 'data' / 'processed' / 'iclv' / 'integrated_data.csv'
    data = pd.read_csv(data_path)
    n_individuals = data['respondent_id'].nunique()
    print(f"    ë°ì´í„° shape: {data.shape}")
    print(f"    ì „ì²´ ê°œì¸ ìˆ˜: {n_individuals}")

    # 4. Config ìƒì„±
    print("\n[4] Config ìƒì„±:")

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: ì„ íƒëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬ ìƒì„±
    choice_config_dict = build_choice_config_dict(
        main_lvs=MAIN_LVS,
        lv_attribute_interactions=LV_ATTRIBUTE_INTERACTIONS
    )

    print(f"    ì„ íƒëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬: {choice_config_dict}")

    # Config ìƒì„± (ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ í•¨ìˆ˜ ì‚¬ìš©)
    config = create_sugar_substitute_multi_lv_config(
        custom_paths=hierarchical_paths,
        choice_config_overrides=choice_config_dict,
        n_draws=N_DRAWS,
        max_iterations=MAX_ITERATIONS,
        optimizer='L-BFGS-B',  # âœ… BHHH â†’ L-BFGS-Bë¡œ ë³€ê²½
        use_analytic_gradient=True,
        calculate_se=True,
        gradient_log_level='DETAILED',
        use_parameter_scaling=False  # âœ… ìŠ¤ì¼€ì¼ë§ ë¹„í™œì„±í™”
    )

    print(f"    Config ìƒì„± ì™„ë£Œ")
    print(f"    - ì ì¬ë³€ìˆ˜: 5ê°œ (HC, PB, PP, NK, PI)")
    print(f"    - ì¸¡ì • ë°©ë²•: ì—°ì†í˜• ì„ í˜• (Continuous Linear)")
    print(f"    - Halton draws: {N_DRAWS}")
    print(f"    - ìµœëŒ€ ë°˜ë³µ: {MAX_ITERATIONS}")
    print(f"    - ìµœì í™”: L-BFGS-B (Analytic Gradient)")
    print(f"    - íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§: ë¹„í™œì„±í™”")
    print(f"    - GPU ë°°ì¹˜ ì²˜ë¦¬: í™œì„±í™”")
    
    # 5. ëª¨ë¸ ìƒì„±
    print("\n[5] ëª¨ë¸ ìƒì„±:")
    with open("debug_choice_config.txt", "w", encoding="utf-8") as f:
        f.write(f"config.choice.main_lvs = {config.choice.main_lvs}\n")
        f.write(f"config.choice.lv_attribute_interactions = {config.choice.lv_attribute_interactions}\n")

    try:
        measurement_model = MultiLatentMeasurement(config.measurement_configs)
        structural_model = MultiLatentStructural(config.structural)
        choice_model = MultinomialLogitChoice(config.choice)
        print("    ì¸¡ì •ëª¨ë¸, êµ¬ì¡°ëª¨ë¸, ì„ íƒëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print("    - ì„ íƒëª¨ë¸: Multinomial Logit (MNL)")

        with open("debug_choice_config.txt", "a", encoding="utf-8") as f:
            f.write(f"choice_model.main_lvs = {choice_model.main_lvs}\n")
            f.write(f"choice_model.lv_attribute_interactions = {choice_model.lv_attribute_interactions}\n")
    except Exception as e:
        print(f"    [ERROR] ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 6. Estimator ìƒì„±
    print("\n[6] Estimator ìƒì„±:")
    try:
        estimator = SimultaneousGPUBatchEstimator(
            config,
            use_gpu=True,
            memory_monitor_cpu_threshold_mb=CPU_MEMORY_THRESHOLD_MB,
            memory_monitor_gpu_threshold_mb=GPU_MEMORY_THRESHOLD_MB
        )
        print(f"    ë™ì‹œì¶”ì • GPU ë°°ì¹˜ Estimator ìƒì„± ì™„ë£Œ")
        print(f"    - ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§: CPU {CPU_MEMORY_THRESHOLD_MB}MB, GPU {GPU_MEMORY_THRESHOLD_MB}MB")
    except Exception as e:
        print(f"    [ERROR] Estimator ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 7. ì´ˆê¸°ê°’ ë¡œë“œ (ì„ íƒì‚¬í•­)
    print("\n[7] ì´ˆê¸°ê°’ ë¡œë“œ:")
    initial_params = None

    if INITIAL_PARAMS_FILE:
        # ìˆœì°¨ì¶”ì • ê²°ê³¼ íŒŒì¼ì—ì„œ ì´ˆê¸°ê°’ ë¡œë“œ
        initial_params_path = project_root / 'results' / 'sequential_stage_wise' / INITIAL_PARAMS_FILE

        if initial_params_path.exists():
            print(f"    ì´ˆê¸°ê°’ íŒŒì¼: {INITIAL_PARAMS_FILE}")

            # .pkl íŒŒì¼ì¸ ê²½ìš° (ìˆœì°¨ì¶”ì • 1ë‹¨ê³„ ê²°ê³¼)
            if INITIAL_PARAMS_FILE.endswith('.pkl'):
                import pickle
                with open(initial_params_path, 'rb') as f:
                    stage1_results = pickle.load(f)

                # 1ë‹¨ê³„ ê²°ê³¼ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                print(f"    ìˆœì°¨ì¶”ì • 1ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ")

                # measurement_resultsì™€ structural_resultsì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                if 'measurement_results' in stage1_results and 'structural_results' in stage1_results:
                    meas_params = stage1_results['measurement_results'].get('params', {})
                    struct_params = stage1_results['structural_results'].get('params', {})

                    # DataFrameì´ë‚˜ dictê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                    meas_valid = (isinstance(meas_params, dict) and len(meas_params) > 0) or \
                                 (hasattr(meas_params, 'empty') and not meas_params.empty)
                    struct_valid = (isinstance(struct_params, dict) and len(struct_params) > 0) or \
                                   (hasattr(struct_params, 'empty') and not struct_params.empty)

                    if meas_valid and struct_valid:
                        # íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
                        param_dict = {
                            'measurement': meas_params,
                            'structural': struct_params,
                            'choice': None  # ì„ íƒëª¨ë¸ì€ ìë™ ì´ˆê¸°í™”
                        }

                        print(f"    ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°: {len(meas_params)} LVs")
                        if isinstance(meas_params, dict):
                            for lv_name, lv_params in meas_params.items():
                                if isinstance(lv_params, dict):
                                    print(f"      - {lv_name}: zeta={len(lv_params.get('zeta', []))}, sigma_sq={len(lv_params.get('sigma_sq', []))}")

                        print(f"    êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°:")
                        if isinstance(struct_params, dict):
                            for key, value in struct_params.items():
                                if isinstance(value, (int, float)):
                                    print(f"      - {key}: {value:.6f}")
                                else:
                                    print(f"      - {key}: {value}")
                        else:
                            print(f"      (DataFrame í˜•ì‹: {len(struct_params)} rows)")

                        print(f"    ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°: ìë™ ì´ˆê¸°í™” ì‚¬ìš©")

                        # ParameterManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ì—´ë¡œ ë³€í™˜
                        # ì´ ì‘ì—…ì€ estimator ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ë˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ë”•ì…”ë„ˆë¦¬ë§Œ ì „ë‹¬
                        initial_params = param_dict
                    else:
                        print(f"    [WARNING] íŒŒë¼ë¯¸í„° ì •ë³´ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")
                        print(f"    ìë™ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                        initial_params = None
                else:
                    print(f"    [WARNING] .pkl íŒŒì¼ì— measurement_results ë˜ëŠ” structural_resultsê°€ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"    ìë™ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    initial_params = None

            # .csv íŒŒì¼ì¸ ê²½ìš° (ì´ì „ ë™ì‹œì¶”ì • ê²°ê³¼)
            elif INITIAL_PARAMS_FILE.endswith('.csv'):
                df_initial = pd.read_csv(initial_params_path)

                # Estimation statistics í–‰ ì œê±° (ë¹ˆ í–‰ ì´í›„)
                first_empty_idx = df_initial[df_initial['Coefficient'].isna()].index
                if len(first_empty_idx) > 0:
                    df_initial = df_initial.iloc[:first_empty_idx[0]]

                # Estimate ê°’ë§Œ ì¶”ì¶œ (ìˆœì„œëŒ€ë¡œ)
                initial_params = df_initial['Estimate'].values.astype(float)
                print(f"    ì´ˆê¸°ê°’ ê°œìˆ˜: {len(initial_params)}")
                print(f"    ì´ˆê¸°ê°’ ë²”ìœ„: [{initial_params.min():.4f}, {initial_params.max():.4f}]")
            else:
                print(f"    [WARNING] ì´ˆê¸°ê°’ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INITIAL_PARAMS_FILE}")
                print(f"    ìë™ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            print(f"    [WARNING] ì´ˆê¸°ê°’ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INITIAL_PARAMS_FILE}")
            print(f"    ìë™ ì´ˆê¸°í™”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print(f"    ì´ˆê¸°ê°’ íŒŒì¼ ì§€ì • ì•ˆ ë¨ - ìë™ ì´ˆê¸°í™” ì‚¬ìš©")

    # 8. ì¶”ì • ì‹¤í–‰
    print("\n[8] ë™ì‹œì¶”ì • ì‹¤í–‰:")
    print("    GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë™ì‹œì— ì¶”ì •í•©ë‹ˆë‹¤.")
    print("    [ì£¼ì˜] 5-10ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")

    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = project_root / 'results' / f'simultaneous_estimation_log_{timestamp}.txt'
    print(f"    ë¡œê·¸ íŒŒì¼: {log_file.name}")

    start_time = time.time()

    try:
        result = estimator.estimate(
            data=data,
            measurement_model=measurement_model,
            structural_model=structural_model,
            choice_model=choice_model,
            log_file=str(log_file),
            initial_params=initial_params
        )

        elapsed_time = time.time() - start_time

        # 9. ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 70)
        print("ì¶”ì • ê²°ê³¼")
        print("=" * 70)
        print(f"\nì¶”ì • ì‹œê°„: {elapsed_time/60:.2f}ë¶„ ({elapsed_time:.1f}ì´ˆ)")
        print(f"ìˆ˜ë ´ ì—¬ë¶€: {result['success']}")
        print(f"ë°˜ë³µ íšŸìˆ˜: {result.get('n_iterations', result.get('iterations', 'N/A'))}")
        print(f"ìµœì¢… ë¡œê·¸ìš°ë„: {result['log_likelihood']:.4f}")

        # ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½
        if hasattr(estimator, 'memory_monitor'):
            print("\n" + "=" * 70)
            print("ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½")
            print("=" * 70)
            mem_summary = estimator.memory_monitor.get_memory_summary()
            print(f"í˜„ì¬ CPU ë©”ëª¨ë¦¬: {mem_summary['current_cpu_mb']:.1f}MB")
            if mem_summary['current_gpu_mb'] is not None:
                print(f"í˜„ì¬ GPU ë©”ëª¨ë¦¬: {mem_summary['current_gpu_mb']:.1f}MB")
            if 'cpu_max_mb' in mem_summary:
                print(f"ìµœëŒ€ CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_max_mb']:.1f}MB")
                print(f"í‰ê·  CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_avg_mb']:.1f}MB")
            if 'gpu_max_mb' in mem_summary:
                print(f"ìµœëŒ€ GPU ë©”ëª¨ë¦¬: {mem_summary['gpu_max_mb']:.1f}MB")
                print(f"í‰ê·  GPU ë©”ëª¨ë¦¬: {mem_summary['gpu_avg_mb']:.1f}MB")

        # 10. ê²°ê³¼ ì €ì¥
        print("\n[10] ê²°ê³¼ ì €ì¥:")
        output_dir = project_root / 'results'
        output_dir.mkdir(exist_ok=True)

        # íŒŒì¼ëª… ìƒì„± (ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ ê·œì¹™)
        csv_filename = generate_simultaneous_filename(path_name, config, timestamp)
        csv_file = output_dir / csv_filename

        # íŒŒë¼ë¯¸í„° ì €ì¥ (npy)
        npy_filename = csv_filename.replace('.csv', '.npy')
        params_file = output_dir / npy_filename
        np.save(params_file, result['raw_params'])

        # íŒŒë¼ë¯¸í„° í†µê³„ ì¶”ì¶œ
        print(f"    íŒŒë¼ë¯¸í„° í†µê³„ ì¶”ì¶œ ì¤‘...")
        param_list = []

        if 'parameter_statistics' in result:
            stats = result['parameter_statistics']

            # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜)
            if 'measurement' in stats:
                for lv_name, lv_stats in stats['measurement'].items():
                    # zeta (ìš”ì¸ì ì¬ëŸ‰)
                    if 'zeta' in lv_stats:
                        zeta_stats = lv_stats['zeta']
                        for i in range(len(zeta_stats['estimate'])):
                            indicator_name = config.measurement_configs[lv_name].indicators[i]
                            param_list.append({
                                'Coefficient': f'Î¶_{lv_name}_{indicator_name}',
                                'Estimate': zeta_stats['estimate'][i],
                                'Std. Err.': zeta_stats['std_error'][i],
                                'P. Value': zeta_stats['p_value'][i]
                            })

                    # sigma_sq (ì˜¤ì°¨ë¶„ì‚°) - continuous_linear ë°©ì‹
                    if 'sigma_sq' in lv_stats:
                        sigma_sq_stats = lv_stats['sigma_sq']
                        for i in range(len(sigma_sq_stats['estimate'])):
                            indicator_name = config.measurement_configs[lv_name].indicators[i]
                            param_list.append({
                                'Coefficient': f'ÏƒÂ²_{lv_name}_{indicator_name}',
                                'Estimate': sigma_sq_stats['estimate'][i],
                                'Std. Err.': sigma_sq_stats['std_error'][i],
                                'P. Value': sigma_sq_stats['p_value'][i]
                            })

            # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„° (ê³„ì¸µì  êµ¬ì¡°)
            if 'structural' in stats:
                struct = stats['structural']

                # ê³„ì¸µì  íŒŒë¼ë¯¸í„° (gamma_pred_to_target)
                for key, value in struct.items():
                    if key.startswith('gamma_'):
                        param_list.append({
                            'Coefficient': f'Î³_{key.replace("gamma_", "")}',
                            'Estimate': value['estimate'],
                            'Std. Err.': value['std_error'],
                            'P. Value': value['p_value']
                        })

            # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
            if 'choice' in stats:
                choice = stats['choice']

                # intercept
                if 'intercept' in choice:
                    param_list.append({
                        'Coefficient': 'Î²_Intercept',
                        'Estimate': choice['intercept']['estimate'],
                        'Std. Err.': choice['intercept']['std_error'],
                        'P. Value': choice['intercept']['p_value']
                    })

                # beta
                if 'beta' in choice:
                    beta_stats = choice['beta']
                    for i, attr in enumerate(config.choice.choice_attributes):
                        param_list.append({
                            'Coefficient': f'Î²_{attr}',
                            'Estimate': beta_stats['estimate'][i],
                            'Std. Err.': beta_stats['std_error'][i],
                            'P. Value': beta_stats['p_value'][i]
                        })

                # lambda (ì£¼íš¨ê³¼ LV)
                if 'lambda' in choice:
                    for lv_name, lv_stats in choice['lambda'].items():
                        param_list.append({
                            'Coefficient': f'Î»_{lv_name}',
                            'Estimate': lv_stats['estimate'],
                            'Std. Err.': lv_stats['std_error'],
                            'P. Value': lv_stats['p_value']
                        })

                # lambda_interaction (LV-ì†ì„± ìƒí˜¸ì‘ìš©)
                if 'lambda_interaction' in choice:
                    for interaction_name, interaction_stats in choice['lambda_interaction'].items():
                        param_list.append({
                            'Coefficient': f'Î»_int_{interaction_name}',
                            'Estimate': interaction_stats['estimate'],
                            'Std. Err.': interaction_stats['std_error'],
                            'P. Value': interaction_stats['p_value']
                        })

            print(f"    âœ“ {len(param_list)}ê°œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì™„ë£Œ")
        else:
            print(f"    [WARNING] parameter_statisticsê°€ ì—†ìŠµë‹ˆë‹¤. í‘œì¤€ì˜¤ì°¨ ì—†ì´ ì €ì¥í•©ë‹ˆë‹¤.")

        # DataFrame ìƒì„±
        df_params = pd.DataFrame(param_list)

        # Estimation statistics ì¶”ê°€
        n_iter = result.get('n_iterations', result.get('iterations', 'N/A'))
        stats_list = [
            {'Coefficient': '', 'Estimate': '', 'Std. Err.': '', 'P. Value': ''},
            {'Coefficient': 'Estimation statistics', 'Estimate': '', 'Std. Err.': '', 'P. Value': ''},
            {'Coefficient': 'Iterations', 'Estimate': n_iter,
             'Std. Err.': 'LL (final)', 'P. Value': f"{result['log_likelihood']:.2f}"},
            {'Coefficient': 'AIC', 'Estimate': f"{result['aic']:.2f}",
             'Std. Err.': 'BIC', 'P. Value': f"{result['bic']:.2f}"}
        ]

        df_stats = pd.DataFrame(stats_list)
        df_combined = pd.concat([df_params, df_stats], ignore_index=True)

        # CSV ì €ì¥ (ìƒì„¸ íŒŒë¼ë¯¸í„°)
        df_combined.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"    âœ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        print(f"      - íŒŒë¼ë¯¸í„° ìˆ˜: {len(param_list)}")
        print(f"      - ìµœì¢… LL: {result['log_likelihood']:.2f}")
        print(f"      - AIC: {result['aic']:.2f}, BIC: {result['bic']:.2f}")

    except Exception as e:
        print(f"\n[ERROR] ì¶”ì • ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\n" + "=" * 70)
    print("ë™ì‹œì¶”ì • ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nëª¨ë¸ êµ¬ì„±:")
    print(f"  - ê²½ë¡œ: {model_description}")
    if MAIN_LVS or MODERATION_LVS or LV_ATTRIBUTE_INTERACTIONS:
        print(f"  - ì„ íƒëª¨ë¸ LV: {', '.join(MAIN_LVS) if MAIN_LVS else 'None'}")
    print(f"\nê²°ê³¼ íŒŒì¼:")
    print(f"  - {csv_filename}")
    print(f"  - {npy_filename}")
    print(f"  - {log_file.name}")


if __name__ == '__main__':
    main()

