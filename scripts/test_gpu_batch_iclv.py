"""
ë™ì‹œì¶”ì • (Simultaneous Estimation) - GPU ë°°ì¹˜ ì²˜ë¦¬

ì´ íŒŒì¼ í•˜ë‚˜ë¡œ ëª¨ë“  ë™ì‹œì¶”ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ìˆœì°¨ì¶”ì • 2ë‹¨ê³„ CSV íŒŒì¼ëª…ë§Œ ì§€ì •í•˜ë©´ ìë™ìœ¼ë¡œ ì„¤ì •ì´ íŒŒì‹±ë©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
1. INITIAL_PARAMS_CSVì— ìˆœì°¨ì¶”ì • 2ë‹¨ê³„ ê²°ê³¼ íŒŒì¼ëª… ì§€ì •
   ì˜ˆ: 'st2_HC-PB_PB-PI1_PI2_results.csv'
2. ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ê²½ë¡œ ë° ì„ íƒëª¨ë¸ ì„¤ì • íŒŒì‹±
3. ê²°ê³¼ íŒŒì¼ëª…: simultaneous_{ê²½ë¡œëª…}_{ì„ íƒëª¨ë¸LV}_results_{timestamp}.csv

ì£¼ìš” ê¸°ëŠ¥:
- ìë™ ì„¤ì •: CSV íŒŒì¼ëª…ì—ì„œ ê²½ë¡œ ë° ì„ íƒëª¨ë¸ ì„¤ì • ìë™ ì¶”ì¶œ
- ì´ˆê¸°ê°’: PKL íŒŒì¼ì—ì„œ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ, ë‚˜ë¨¸ì§€ëŠ” 0.1ë¡œ ì´ˆê¸°í™”
- GPU ë°°ì¹˜ ì²˜ë¦¬: ê³ ì† ë™ì‹œì¶”ì •

ì¶”ì • ëŒ€ìƒ:
- ì¸¡ì •ëª¨ë¸: ì¶”ì • O (PKL ì´ˆê¸°ê°’ ì‚¬ìš©)
- êµ¬ì¡°ëª¨ë¸: ì¶”ì • O (ì´ˆê¸°ê°’ 0.1)
- ì„ íƒëª¨ë¸: ì¶”ì • O (ì´ˆê¸°ê°’ 0.1)

Author: Sugar Substitute Research Team
Date: 2025-11-18
"""

import sys
import pandas as pd
import numpy as np
import time
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ê³µí†µ ìœ í‹¸ë¦¬í‹° import
sys.path.insert(0, str(project_root / 'examples'))
from model_config_utils import (
    build_paths_from_config,
    build_choice_config_dict,
    generate_iclv_filename,
    save_simultaneous_results,
    parse_csv_filename,
    parse_csv_content
)

from src.analysis.hybrid_choice_model.iclv_models.multi_latent_config import (
    create_sugar_substitute_multi_lv_config
)
from src.analysis.hybrid_choice_model.iclv_models.simultaneous_gpu_batch_estimator import SimultaneousGPUBatchEstimator
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_measurement import MultiLatentMeasurement
from src.analysis.hybrid_choice_model.iclv_models.multi_latent_structural import MultiLatentStructural
from src.analysis.hybrid_choice_model.iclv_models.choice_equations import MultinomialLogitChoice
from src.analysis.hybrid_choice_model.iclv_models.initial_values_final import get_sigma_sq_initial_value


# ============================================================================
# ğŸ¯ ì‚¬ìš©ì ì„¤ì • ì˜ì—­ - ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ì„¸ìš”!
# ============================================================================

# ============================================================================
# ì„¤ì • ëª¨ë“œ: ìˆ˜ë™ ì„¤ì •
# ============================================================================

print("\n" + "=" * 70)
print("[MANUAL] ìˆ˜ë™ ì„¤ì • ëª¨ë“œ")
print("=" * 70)

# 1. 1ë‹¨ê³„ êµ¬ì¡°ëª¨ë¸ ê²½ë¡œ ì„¤ì • (2path)
PATHS = {
    'HC->PB': True,   # health_concern â†’ perceived_benefit
    'HC->PP': False,
    'HC->PI': False,
    'PB->PI': True,   # perceived_benefit â†’ purchase_intention
    'PP->PI': False,
    'NK->PI': False,
}

# 2. 2ë‹¨ê³„ ì„ íƒëª¨ë¸ ì„¤ì •
MAIN_LVS = ['nutrition_knowledge', 'purchase_intention', 'perceived_price']  # NK, PI, PP ì£¼íš¨ê³¼
MODERATION_LVS = []  # ì¡°ì ˆíš¨ê³¼ ì—†ìŒ
LV_ATTRIBUTE_INTERACTIONS = []  # LV-Attribute ìƒí˜¸ì‘ìš© ì—†ìŒ

# ì„¤ì • ì¶œë ¥
print(f"\n[ëª¨ë¸ ì„¤ì •]")
print(f"  1ë‹¨ê³„ ê²½ë¡œ: {[k for k, v in PATHS.items() if v]}")
print(f"  ì£¼íš¨ê³¼ LV: {MAIN_LVS}")
print(f"  ì¡°ì ˆíš¨ê³¼: {MODERATION_LVS if MODERATION_LVS else 'ì—†ìŒ'}")
print(f"  LV-Attribute ìƒí˜¸ì‘ìš©: {LV_ATTRIBUTE_INTERACTIONS if LV_ATTRIBUTE_INTERACTIONS else 'ì—†ìŒ'}")
print("=" * 70 + "\n")

# âœ… CFA ê²°ê³¼ íŒŒì¼ ì‚¬ìš© (ì¸¡ì •ëª¨ë¸ë§Œ ì¶”ì •ëœ ê²°ê³¼)
# PKL íŒŒì¼ëª…ë„ ìë™ ìƒì„±
from model_config_utils import build_paths_from_config
_, path_name, _, _ = build_paths_from_config(PATHS)
# INITIAL_PARAMS_PKL = f'stage1_{path_name}_results.pkl'  # SEM ê²°ê³¼ (êµ¬ì¡°ëª¨ë¸ í¬í•¨)
INITIAL_PARAMS_PKL = 'cfa_results.pkl'  # âœ… CFA ê²°ê³¼ (ì¸¡ì •ëª¨ë¸ë§Œ)

# 4. GPU ë©”ëª¨ë¦¬ ì„¤ì •
CPU_MEMORY_THRESHOLD_MB = 2000  # CPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
GPU_MEMORY_THRESHOLD_MB = 7000  # GPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB) - 5GB â†’ 7GBë¡œ ì¦ê°€

# 5. ì¶”ì • ì„¤ì •
N_DRAWS = 100  # Halton draws ìˆ˜
MAX_ITERATIONS = 50  # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (1000 â†’ 50ìœ¼ë¡œ ë‹¨ì¶•)

# ============================================================================
# ğŸ¤– ìë™ ì²˜ë¦¬ ì˜ì—­ - ìˆ˜ì • ë¶ˆí•„ìš”
# ============================================================================

# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # 1. ê²½ë¡œ êµ¬ì„±
    hierarchical_paths, path_name, model_description, n_paths = build_paths_from_config(PATHS)

    print("=" * 70)
    print(f"ë™ì‹œì¶”ì • (GPU ë°°ì¹˜): {model_description}")
    print("=" * 70)

    if hierarchical_paths:
        print(f"\n[1] ê²½ë¡œ êµ¬ì„± ì™„ë£Œ:")
        for i, path_dict in enumerate(hierarchical_paths, 1):
            target = path_dict['target']
            predictors = path_dict['predictors']
            pred_str = ' + '.join(predictors)
            print(f"    {i}. {pred_str} â†’ {target}")
    else:
        print(f"\n[1] Base Model (ê²½ë¡œ ì—†ìŒ)")

    # 2. ì„ íƒëª¨ë¸ ì„¤ì •
    print(f"\n[2] ì„ íƒëª¨ë¸ ì„¤ì •:")
    if MAIN_LVS:
        print(f"    ì£¼íš¨ê³¼ LV: {', '.join(MAIN_LVS)}")
    if MODERATION_LVS:
        print(f"    ì¡°ì ˆíš¨ê³¼ LV: {', '.join(MODERATION_LVS)}")
    if LV_ATTRIBUTE_INTERACTIONS:
        print(f"    LV-ì†ì„± ìƒí˜¸ì‘ìš©:")
        for lv, attr in LV_ATTRIBUTE_INTERACTIONS:
            print(f"      - {lv} Ã— {attr}")
    if not MAIN_LVS and not MODERATION_LVS and not LV_ATTRIBUTE_INTERACTIONS:
        print(f"    Base Model (ì ì¬ë³€ìˆ˜ ì—†ìŒ)")

    # 3. ë°ì´í„° ë¡œë“œ
    print("\n[3] ë°ì´í„° ë¡œë“œ:")
    data_path = project_root / 'data' / 'processed' / 'iclv' / 'integrated_data.csv'
    data = pd.read_csv(data_path)
    n_individuals = data['respondent_id'].nunique()
    print(f"    ë°ì´í„° shape: {data.shape}")
    print(f"    ì „ì²´ ê°œì¸ ìˆ˜: {n_individuals}")

    # 4. Config ìƒì„±
    print("\n[4] Config ìƒì„±:")

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: ì„ íƒëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬ ìƒì„±
    choice_config_dict = build_choice_config_dict(
        main_lvs=MAIN_LVS,
        lv_attribute_interactions=LV_ATTRIBUTE_INTERACTIONS
    )

    print(f"    ì„ íƒëª¨ë¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬: {choice_config_dict}")

    # Config ìƒì„± (ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ í•¨ìˆ˜ ì‚¬ìš©)
    config = create_sugar_substitute_multi_lv_config(
        custom_paths=hierarchical_paths,
        choice_config_overrides=choice_config_dict,
        n_draws=N_DRAWS,
        max_iterations=MAX_ITERATIONS,
        optimizer='trust-constr',  # âœ… Trust Region ì‚¬ìš©
        use_analytic_gradient=True,
        calculate_se=True,
        se_method='robust',  # âœ… Sandwich Estimator (Robust SE) ì‚¬ìš©
        gradient_log_level='MINIMAL',  # âœ… DETAILED â†’ MINIMALë¡œ ë³€ê²½ (ì†ë„ ìµœì í™”)
        use_parameter_scaling=False,  # âœ… ìŠ¤ì¼€ì¼ë§ ë¹„í™œì„±í™” (z-score í‘œì¤€í™”ë§Œ í…ŒìŠ¤íŠ¸)
        standardize_choice_attributes=True  # âœ… z-score í‘œì¤€í™” í™œì„±í™”
    )

    print(f"    Config ìƒì„± ì™„ë£Œ")
    print(f"    - ì ì¬ë³€ìˆ˜: 5ê°œ (HC, PB, PP, NK, PI)")
    print(f"    - ì¸¡ì • ë°©ë²•: ì—°ì†í˜• ì„ í˜• (Continuous Linear)")
    print(f"    - Halton draws: {N_DRAWS}")
    print(f"    - ìµœëŒ€ ë°˜ë³µ: {MAX_ITERATIONS}")
    print(f"    - ìµœì í™”: Trust-Constr (Analytic Gradient)")
    print(f"    - í‘œì¤€ì˜¤ì°¨: Sandwich Estimator (Robust SE)")
    print(f"    - íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§: âŒ ë¹„í™œì„±í™” (ëª¨ë“  ìŠ¤ì¼€ì¼ = 1.0)")
    print(f"    - ë°ì´í„° í‘œì¤€í™”: âœ… í™œì„±í™” (z-score)")
    print(f"    - GPU ë°°ì¹˜ ì²˜ë¦¬: í™œì„±í™”")
    
    # 5. ëª¨ë¸ ìƒì„±
    print("\n[5] ëª¨ë¸ ìƒì„±:")
    with open("debug_choice_config.txt", "w", encoding="utf-8") as f:
        f.write(f"config.choice.main_lvs = {config.choice.main_lvs}\n")
        f.write(f"config.choice.lv_attribute_interactions = {config.choice.lv_attribute_interactions}\n")

    try:
        measurement_model = MultiLatentMeasurement(config.measurement_configs)
        structural_model = MultiLatentStructural(config.structural)
        choice_model = MultinomialLogitChoice(config.choice)
        print("    ì¸¡ì •ëª¨ë¸, êµ¬ì¡°ëª¨ë¸, ì„ íƒëª¨ë¸ ìƒì„± ì™„ë£Œ")
        print("    - ì„ íƒëª¨ë¸: Multinomial Logit (MNL)")

        with open("debug_choice_config.txt", "a", encoding="utf-8") as f:
            f.write(f"choice_model.main_lvs = {choice_model.main_lvs}\n")
            f.write(f"choice_model.lv_attribute_interactions = {choice_model.lv_attribute_interactions}\n")
    except Exception as e:
        print(f"    [ERROR] ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # âœ… ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ë¡œë“œ (ë™ì‹œì¶”ì • ì „ìš©)
    # ì´ ë‹¨ê³„ëŠ” ì´ˆê¸°ê°’ ì„¤ì • ì „ì— ìˆ˜í–‰ë˜ì–´ì•¼ í•¨
    pkl_path = project_root / 'results' / 'final' / 'cfa_only' / INITIAL_PARAMS_PKL

    if pkl_path.exists():
        print(f"\n    [INFO] ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ë¡œë“œ ì¤‘...")
        import pickle
        with open(pkl_path, 'rb') as f:
            cfa_results = pickle.load(f)

        if 'loadings' in cfa_results and 'measurement_errors' in cfa_results:
            loadings_df = cfa_results['loadings']
            errors_df = cfa_results['measurement_errors']
            intercepts_df = cfa_results.get('intercepts', None)  # âœ… ì ˆí¸ ë¡œë“œ

            # ê° ì ì¬ë³€ìˆ˜ì˜ ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ì„¤ì •
            for lv_name, model in measurement_model.models.items():
                lv_config = config.measurement_configs[lv_name]
                indicators = lv_config.indicators

                # zeta (ìš”ì¸ì ì¬ëŸ‰)
                zeta_values = []
                for indicator in indicators:
                    row = loadings_df[(loadings_df['lval'] == indicator) &
                                     (loadings_df['op'] == '~') &
                                     (loadings_df['rval'] == lv_name)]

                    if not row.empty:
                        zeta_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator} ~ {lv_name} ìš”ì¸ì ì¬ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©")
                        zeta_values.append(1.0)

                # sigma_sq (ì˜¤ì°¨ë¶„ì‚°)
                sigma_sq_values = []
                for indicator in indicators:
                    row = errors_df[(errors_df['lval'] == indicator) &
                                   (errors_df['op'] == '~~') &
                                   (errors_df['rval'] == indicator)]

                    if not row.empty:
                        sigma_sq_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator}ì˜ ì˜¤ì°¨ë¶„ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
                        sigma_sq_values.append(0.5)

                # âœ… alpha (ì ˆí¸)
                alpha_values = []
                if intercepts_df is not None:
                    for indicator in indicators:
                        row = intercepts_df[(intercepts_df['lval'] == indicator) &
                                           (intercepts_df['op'] == '~') &
                                           (intercepts_df['rval'] == '1')]

                        if not row.empty:
                            alpha_values.append(float(row['Estimate'].iloc[0]))
                        else:
                            print(f"    [WARNING] {indicator}ì˜ ì ˆí¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.0 ì‚¬ìš©")
                            alpha_values.append(0.0)
                else:
                    print(f"    [WARNING] CFA ê²°ê³¼ì— ì ˆí¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì ˆí¸ì„ 0.0ìœ¼ë¡œ ì„¤ì •")
                    alpha_values = [0.0] * len(indicators)

                # ì¸¡ì •ëª¨ë¸ configì— CFA ê²°ê³¼ ì„¤ì •
                model.config.zeta = np.array(zeta_values)
                model.config.sigma_sq = np.array(sigma_sq_values)
                model.config.alpha = np.array(alpha_values)  # âœ… ì ˆí¸ ì¶”ê°€

                print(f"    [INFO] {lv_name}: zeta={len(zeta_values)}ê°œ, sigma_sq={len(sigma_sq_values)}ê°œ, alpha={len(alpha_values)}ê°œ ë¡œë“œ ì™„ë£Œ")

            print(f"    [SUCCESS] ì¸¡ì •ëª¨ë¸ì— CFA ê²°ê³¼ ë¡œë“œ ì™„ë£Œ (ì ˆí¸ í¬í•¨)")
        else:
            print(f"    [WARNING] CFA ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # 6. Estimator ìƒì„±
    print("\n[6] Estimator ìƒì„±:")
    try:
        estimator = SimultaneousGPUBatchEstimator(
            config,
            use_gpu=True,
            memory_monitor_cpu_threshold_mb=CPU_MEMORY_THRESHOLD_MB,
            memory_monitor_gpu_threshold_mb=GPU_MEMORY_THRESHOLD_MB
        )
        print(f"    ë™ì‹œì¶”ì • GPU ë°°ì¹˜ Estimator ìƒì„± ì™„ë£Œ")
        print(f"    - ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§: CPU {CPU_MEMORY_THRESHOLD_MB}MB, GPU {GPU_MEMORY_THRESHOLD_MB}MB")
    except Exception as e:
        print(f"    [ERROR] Estimator ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    # 7. ì´ˆê¸°ê°’ ì„¤ì •
    print("\n[7] ì´ˆê¸°ê°’ ì„¤ì •:")
    print("    [INFO] ì¸¡ì •ëª¨ë¸ (zeta, sigma_sq): CFA ê²°ê³¼ì—ì„œ ë¡œë“œ (ì´ë¯¸ ì™„ë£Œ)")
    print("    [INFO] êµ¬ì¡°ëª¨ë¸ & ì„ íƒëª¨ë¸: 0.1ë¡œ ì´ˆê¸°í™”")

    initial_params = None

    if pkl_path.exists():
        print(f"\n    CFA ê²°ê³¼ ë¡œë“œ: {INITIAL_PARAMS_PKL}")

        # 1. CFA ê²°ê³¼ì—ì„œ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ
        import pickle
        with open(pkl_path, 'rb') as f:
            cfa_results = pickle.load(f)

        # CFA ê²°ê³¼ëŠ” ì§ì ‘ loadingsì™€ measurement_errorsë¥¼ í¬í•¨
        if 'loadings' in cfa_results and 'measurement_errors' in cfa_results:
            print(f"    [INFO] CFA ê²°ê³¼ì—ì„œ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ì¶”ì¶œ")

            loadings_df = cfa_results['loadings']
            errors_df = cfa_results['measurement_errors']
            intercepts_df = cfa_results.get('intercepts', None)  # âœ… ì ˆí¸ ë¡œë“œ

            # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
            measurement_dict = {}
            for lv_name, lv_config in config.measurement_configs.items():
                indicators = lv_config.indicators

                # âœ… zeta (ìš”ì¸ì ì¬ëŸ‰) - CFA loadingsì—ì„œ ì¶”ì¶œ
                zeta_values = []
                for indicator in indicators:
                    row = loadings_df[(loadings_df['lval'] == indicator) &
                                     (loadings_df['op'] == '~') &
                                     (loadings_df['rval'] == lv_name)]

                    if not row.empty:
                        zeta_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator} ~ {lv_name} ìš”ì¸ì ì¬ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1.0 ì‚¬ìš©")
                        zeta_values.append(1.0)

                # âœ… sigma_sq (ì˜¤ì°¨ë¶„ì‚°) - CFA measurement_errorsì—ì„œ ì¶”ì¶œ
                sigma_sq_values = []
                for indicator in indicators:
                    row = errors_df[(errors_df['lval'] == indicator) &
                                   (errors_df['op'] == '~~') &
                                   (errors_df['rval'] == indicator)]

                    if not row.empty:
                        sigma_sq_values.append(float(row['Estimate'].iloc[0]))
                    else:
                        print(f"    [WARNING] {indicator}ì˜ ì˜¤ì°¨ë¶„ì‚°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.5 ì‚¬ìš©")
                        sigma_sq_values.append(0.5)

                # âœ… alpha (ì ˆí¸) - CFA interceptsì—ì„œ ì¶”ì¶œ
                alpha_values = []
                if intercepts_df is not None:
                    for indicator in indicators:
                        row = intercepts_df[(intercepts_df['lval'] == indicator) &
                                           (intercepts_df['op'] == '~') &
                                           (intercepts_df['rval'] == '1')]

                        if not row.empty:
                            alpha_values.append(float(row['Estimate'].iloc[0]))
                        else:
                            print(f"    [WARNING] {indicator}ì˜ ì ˆí¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 0.0 ì‚¬ìš©")
                            alpha_values.append(0.0)
                else:
                    print(f"    [WARNING] CFA ê²°ê³¼ì— ì ˆí¸ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì ˆí¸ì„ 0.0ìœ¼ë¡œ ì„¤ì •")
                    alpha_values = [0.0] * len(indicators)

                measurement_dict[lv_name] = {
                    'zeta': np.array(zeta_values),
                    'sigma_sq': np.array(sigma_sq_values),
                    'alpha': np.array(alpha_values)  # âœ… ì ˆí¸ ì¶”ê°€
                }

                # âœ… ë¡œë“œëœ ê°’ ì¶œë ¥
                print(f"    [INFO] {lv_name} ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ:")
                print(f"      - zeta (ìš”ì¸ì ì¬ëŸ‰): {zeta_values}")
                print(f"      - sigma_sq (ì˜¤ì°¨ë¶„ì‚°): {sigma_sq_values}")
                print(f"      - alpha (ì ˆí¸): {alpha_values}")

            # 2. êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”
            print(f"    [INFO] êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”")
            structural_dict = {}
            for path in config.structural.hierarchical_paths:
                target_lv = path['target']
                predictors = path['predictors']

                for pred_lv in predictors:
                    param_name = f'gamma_{pred_lv}_to_{target_lv}'
                    structural_dict[param_name] = 0.1
                    print(f"      - {param_name}: 0.1")

            # 3. ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”
            print(f"    [INFO] ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°: 0.1ë¡œ ì´ˆê¸°í™”")
            choice_dict = {}

            # Multinomial Logitì˜ ëŒ€ì•ˆ ì´ë¦„ (í•˜ë“œì½”ë”©)
            # opt-outì€ ê¸°ì¤€ ëŒ€ì•ˆì´ë¯€ë¡œ ì œì™¸
            alternatives = ['sugar', 'sugar_free']  # opt-out ì œì™¸

            # ASC (Alternative-Specific Constants)
            for alt in alternatives:
                param_name = f'asc_{alt}'
                choice_dict[param_name] = 0.1
                print(f"      - {param_name}: 0.1")

            # beta (ì†ì„± ê³„ìˆ˜) - ëª¨ë“  ëŒ€ì•ˆì— ê³µí†µ ì ìš©
            for attr in config.choice.choice_attributes:
                param_name = f'beta_{attr}'
                choice_dict[param_name] = 0.1
                print(f"      - {param_name}: 0.1")

            # theta (LV ì£¼íš¨ê³¼) - ê° ëŒ€ì•ˆë³„ë¡œ
            if config.choice.main_lvs:
                for lv in config.choice.main_lvs:
                    for alt in alternatives:
                        param_name = f'theta_{alt}_{lv}'
                        choice_dict[param_name] = 0.1
                        print(f"      - {param_name}: 0.1")

            # gamma (LV-ì†ì„± ìƒí˜¸ì‘ìš©) - ê° ëŒ€ì•ˆë³„ë¡œ
            if config.choice.lv_attribute_interactions:
                for interaction in config.choice.lv_attribute_interactions:
                    lv = interaction['lv']
                    attr = interaction['attribute']
                    for alt in alternatives:
                        param_name = f'gamma_{alt}_{lv}_{attr}'
                        choice_dict[param_name] = 0.1
                        print(f"      - {param_name}: 0.1")

            # âœ… ìµœì¢… ì´ˆê¸°ê°’ ë”•ì…”ë„ˆë¦¬ êµ¬ì„± (ì¸¡ì •ëª¨ë¸ ì œì™¸)
            # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ì´ë¯¸ measurement_model ê°ì²´ì— ë¡œë“œë˜ì–´ ìˆìŒ
            initial_params = {
                'structural': structural_dict,
                'choice': choice_dict
                # âŒ 'measurement' í‚¤ ì œê±°: ë™ì‹œì¶”ì •ì—ì„œëŠ” ë¶ˆí•„ìš”
                #    ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” measurement_model.models[lv_name].configì— ì´ë¯¸ ë¡œë“œë¨
            }

            # ê²°ê³¼ ì¶œë ¥
            print(f"\n    [SUCCESS] ì´ˆê¸°ê°’ ì„¤ì • ì™„ë£Œ:")
            print(f"      - ì¸¡ì •ëª¨ë¸: {len(measurement_dict)} LVs (measurement_model ê°ì²´ì— ë¡œë“œë¨)")
            for lv_name in list(measurement_dict.keys())[:3]:
                lv_params = measurement_dict[lv_name]
                n_zeta = len(lv_params['zeta'])
                print(f"        * {lv_name}: zeta={n_zeta}ê°œ")

            print(f"      - êµ¬ì¡°ëª¨ë¸: {len(structural_dict)}ê°œ íŒŒë¼ë¯¸í„° (0.1ë¡œ ì´ˆê¸°í™”)")
            print(f"      - ì„ íƒëª¨ë¸: {len(choice_dict)}ê°œ íŒŒë¼ë¯¸í„° (0.1ë¡œ ì´ˆê¸°í™”)")

        else:
            print(f"    [ERROR] CFA ê²°ê³¼ì— loadings ë˜ëŠ” measurement_errorsê°€ ì—†ìŠµë‹ˆë‹¤.")
            raise ValueError("CFA ê²°ê³¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. loadingsì™€ measurement_errorsê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        print(f"    [WARNING] CFA ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INITIAL_PARAMS_PKL}")
        raise FileNotFoundError(f"CFA ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")

    # 8. ì¶”ì • ì‹¤í–‰
    print("\n[8] ë™ì‹œì¶”ì • ì‹¤í–‰:")
    print("    [INFO] ì¶”ì • ëª¨ë“œ: êµ¬ì¡°ëª¨ë¸ + ì„ íƒëª¨ë¸ë§Œ ì¶”ì •")
    print("    [INFO] ì¸¡ì •ëª¨ë¸: ê³ ì •ê°’ ì‚¬ìš© (ì¶”ì • ì•ˆ í•¨)")
    print("    [INFO] GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ë™ì‹œì— ì¶”ì •í•©ë‹ˆë‹¤.")
    print("    [ì£¼ì˜] 5-10ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")

    # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ìµœì¢… ê²°ê³¼ í´ë”)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_dir = project_root / 'results' / 'final' / 'simultaneous' / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / f'simultaneous_estimation_log_{timestamp}.txt'
    print(f"    ë¡œê·¸ íŒŒì¼: {log_file.name}")

    start_time = time.time()

    try:
        print(f"\n    [INFO] ì¶”ì • ì‹œì‘...")
        print(f"    [INFO] ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì •:")
        if initial_params:
            print(f"      - ì¸¡ì •ëª¨ë¸: PKLì—ì„œ ë¡œë“œ (ê³ ì •)")
            print(f"      - êµ¬ì¡°ëª¨ë¸: 0.1ë¡œ ì´ˆê¸°í™” (ì¶”ì • ëŒ€ìƒ)")
            print(f"      - ì„ íƒëª¨ë¸: 0.1ë¡œ ì´ˆê¸°í™” (ì¶”ì • ëŒ€ìƒ)")
        else:
            print(f"      - ìë™ ì´ˆê¸°í™” ì‚¬ìš©")

        result = estimator.estimate(
            data=data,
            measurement_model=measurement_model,
            structural_model=structural_model,
            choice_model=choice_model,
            log_file=str(log_file),
            initial_params=initial_params
            # âœ… ë™ì‹œì¶”ì •ì€ í•­ìƒ ì¸¡ì •ëª¨ë¸ ê³ ì • (ì„¤ì • ë¶ˆí•„ìš”)
        )

        print(f"    [SUCCESS] ì¶”ì • ì™„ë£Œ!")

        elapsed_time = time.time() - start_time

        # 9. ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 70)
        print("ì¶”ì • ê²°ê³¼")
        print("=" * 70)
        print(f"\nì¶”ì • ì‹œê°„: {elapsed_time/60:.2f}ë¶„ ({elapsed_time:.1f}ì´ˆ)")
        print(f"ìˆ˜ë ´ ì—¬ë¶€: {result['success']}")
        print(f"ë°˜ë³µ íšŸìˆ˜: {result.get('n_iterations', result.get('iterations', 'N/A'))}")
        print(f"ìµœì¢… ë¡œê·¸ìš°ë„: {result['log_likelihood']:.4f}")

        # ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½
        if hasattr(estimator, 'memory_monitor'):
            print("\n" + "=" * 70)
            print("ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½")
            print("=" * 70)
            mem_summary = estimator.memory_monitor.get_memory_summary()
            print(f"í˜„ì¬ CPU ë©”ëª¨ë¦¬: {mem_summary['current_cpu_mb']:.1f}MB")
            if mem_summary['current_gpu_mb'] is not None:
                print(f"í˜„ì¬ GPU ë©”ëª¨ë¦¬: {mem_summary['current_gpu_mb']:.1f}MB")
            if 'cpu_max_mb' in mem_summary:
                print(f"ìµœëŒ€ CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_max_mb']:.1f}MB")
                print(f"í‰ê·  CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_avg_mb']:.1f}MB")
            if 'gpu_max_mb' in mem_summary:
                print(f"ìµœëŒ€ GPU ë©”ëª¨ë¦¬: {mem_summary['gpu_max_mb']:.1f}MB")
                print(f"í‰ê·  GPU ë©”ëª¨ë¦¬: {mem_summary['gpu_avg_mb']:.1f}MB")

        # 10. ê²°ê³¼ ì €ì¥
        print("\n[10] ê²°ê³¼ ì €ì¥:")
        # ìµœì¢… ê²°ê³¼ í´ë”ì— ì €ì¥
        output_dir = project_root / 'results' / 'final' / 'simultaneous' / 'results'
        output_dir.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ëª… ìƒì„± (ìˆœì°¨ì¶”ì •ê³¼ ë™ì¼í•œ ê·œì¹™, íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±°)
        csv_filename = generate_iclv_filename(
            choice_config=config,
            stage1_model_name=path_name,
            estimation_type='simultaneous'
        ) + '_results.csv'
        csv_file = output_dir / csv_filename

        # íŒŒë¼ë¯¸í„° ì €ì¥ (npy)
        npy_filename = csv_filename.replace('.csv', '.npy')
        params_file = output_dir / npy_filename
        np.save(params_file, result['raw_params'])
        print(f"    âœ“ ì›ì‹œ íŒŒë¼ë¯¸í„° ì €ì¥: {npy_filename}")

        # CSV ì €ì¥ (ë²”ìš© í•¨ìˆ˜ ì‚¬ìš©)
        print(f"    CSV ê²°ê³¼ ì €ì¥ ì¤‘...")
        save_simultaneous_results(
            results=result,
            save_path=csv_file,
            cfa_results=cfa_results,
            config=config
        )
        print(f"    âœ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_filename}")
        print(f"      - ìµœì¢… LL: {result['log_likelihood']:.2f}")
        print(f"      - AIC: {result['aic']:.2f}, BIC: {result['bic']:.2f}")

    except Exception as e:
        print(f"\n[ERROR] ì¶”ì • ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\n" + "=" * 70)
    print("ë™ì‹œì¶”ì • ì™„ë£Œ!")
    print("=" * 70)
    print(f"\nëª¨ë¸ êµ¬ì„±:")
    print(f"  - ê²½ë¡œ: {model_description}")
    if MAIN_LVS or MODERATION_LVS or LV_ATTRIBUTE_INTERACTIONS:
        print(f"  - ì„ íƒëª¨ë¸ LV: {', '.join(MAIN_LVS) if MAIN_LVS else 'None'}")
    print(f"\nê²°ê³¼ íŒŒì¼:")
    print(f"  - {csv_filename}")
    print(f"  - {npy_filename}")
    print(f"  - {log_file.name}")


if __name__ == '__main__':
    main()

