"""
ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° ë¶ˆê· í˜• ì›ì¸ ë¶„ì„

ë¡œê·¸ íŒŒì¼ì—ì„œ ê° ëª¨ë¸ë³„ ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸°ë¥¼ ë¶„ì„í•˜ì—¬
ì™œ ì„ íƒëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ê°€ êµ¬ì¡°ëª¨ë¸ë³´ë‹¤ 10,000ë°° í°ì§€ í™•ì¸
"""
import re
import numpy as np
import pandas as pd
from pathlib import Path


def parse_gradient_from_log(log_file: str):
    """
    ë¡œê·¸ íŒŒì¼ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ ì •ë³´ ì¶”ì¶œ
    """
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Iterationë³„ íŒŒë¼ë¯¸í„°ì™€ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì¶œ
    iterations = []
    
    # "ì „ì²´ íŒŒë¼ë¯¸í„° ê°’ ë° ê·¸ë˜ë””ì–¸íŠ¸:" ì„¹ì…˜ ì°¾ê¸°
    pattern = r'ì „ì²´ íŒŒë¼ë¯¸í„° ê°’ ë° ê·¸ë˜ë””ì–¸íŠ¸:\s+((?:\s+\[\s*\d+\].*\n)+)'
    matches = re.finditer(pattern, content)
    
    for match_idx, match in enumerate(matches):
        param_section = match.group(1)
        
        # ê° íŒŒë¼ë¯¸í„° ë¼ì¸ íŒŒì‹±
        param_pattern = r'\[\s*(\d+)\]\s+(\S+)\s+:\s+param=([+-]?\d+\.\d+e[+-]?\d+),\s+grad=([+-]?\d+\.\d+e[+-]?\d+)'
        param_matches = re.finditer(param_pattern, param_section)
        
        iter_data = {'iteration': match_idx + 1, 'params': []}
        
        for pm in param_matches:
            idx = int(pm.group(1))
            name = pm.group(2)
            param_val = float(pm.group(3))
            grad_val = float(pm.group(4))
            
            iter_data['params'].append({
                'index': idx,
                'name': name,
                'param': param_val,
                'grad': grad_val,
                'grad_abs': abs(grad_val)
            })
        
        if iter_data['params']:
            iterations.append(iter_data)
    
    return iterations


def categorize_parameters(param_name: str) -> str:
    """
    íŒŒë¼ë¯¸í„° ì´ë¦„ìœ¼ë¡œ ëª¨ë¸ ë¶„ë¥˜
    """
    if param_name.startswith('gamma_'):
        return 'êµ¬ì¡°ëª¨ë¸'
    elif param_name.startswith('asc_') or param_name.startswith('beta_'):
        return 'ì„ íƒëª¨ë¸ (ê³ ì •íš¨ê³¼)'
    elif param_name.startswith('theta_'):
        return 'ì„ íƒëª¨ë¸ (LV ê³„ìˆ˜)'
    elif param_name.startswith('zeta_') or param_name.startswith('tau_'):
        return 'ì¸¡ì •ëª¨ë¸'
    else:
        return 'ê¸°íƒ€'


def analyze_gradient_magnitudes(iterations):
    """
    ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° ë¶„ì„
    """
    print("="*80)
    print("ê·¸ë˜ë””ì–¸íŠ¸ í¬ê¸° ë¶ˆê· í˜• ë¶„ì„")
    print("="*80)
    
    for iter_data in iterations[:5]:  # ì²˜ìŒ 5ê°œ iterationë§Œ
        iter_num = iter_data['iteration']
        params = iter_data['params']
        
        print(f"\n{'='*80}")
        print(f"Iteration #{iter_num}")
        print(f"{'='*80}")
        
        # ëª¨ë¸ë³„ë¡œ ê·¸ë£¹í™”
        by_model = {}
        for p in params:
            model = categorize_parameters(p['name'])
            if model not in by_model:
                by_model[model] = []
            by_model[model].append(p)
        
        # ëª¨ë¸ë³„ í†µê³„
        print(f"\n{'ëª¨ë¸':<30} {'ê°œìˆ˜':>6} {'í‰ê·  |grad|':>15} {'ìµœëŒ€ |grad|':>15} {'ìµœì†Œ |grad|':>15}")
        print("-"*80)
        
        model_stats = []
        for model, params_list in sorted(by_model.items()):
            grads = [p['grad_abs'] for p in params_list]
            avg_grad = np.mean(grads)
            max_grad = np.max(grads)
            min_grad = np.min(grads)
            
            print(f"{model:<30} {len(params_list):>6} {avg_grad:>15.6e} {max_grad:>15.6e} {min_grad:>15.6e}")
            
            model_stats.append({
                'model': model,
                'avg': avg_grad,
                'max': max_grad,
                'min': min_grad
            })
        
        # ë¹„ìœ¨ ê³„ì‚°
        print(f"\n{'ë¹„ìœ¨ ë¶„ì„':<30}")
        print("-"*80)
        
        if len(model_stats) >= 2:
            # êµ¬ì¡°ëª¨ë¸ vs ì„ íƒëª¨ë¸
            struct_stat = next((s for s in model_stats if s['model'] == 'êµ¬ì¡°ëª¨ë¸'), None)
            choice_fixed_stat = next((s for s in model_stats if s['model'] == 'ì„ íƒëª¨ë¸ (ê³ ì •íš¨ê³¼)'), None)
            choice_lv_stat = next((s for s in model_stats if s['model'] == 'ì„ íƒëª¨ë¸ (LV ê³„ìˆ˜)'), None)
            
            if struct_stat and choice_fixed_stat:
                ratio = choice_fixed_stat['avg'] / struct_stat['avg']
                print(f"ì„ íƒëª¨ë¸(ê³ ì •íš¨ê³¼) / êµ¬ì¡°ëª¨ë¸ í‰ê·  ë¹„ìœ¨: {ratio:,.1f}x")
                print(f"  - êµ¬ì¡°ëª¨ë¸ í‰ê· : {struct_stat['avg']:.6e}")
                print(f"  - ì„ íƒëª¨ë¸(ê³ ì •íš¨ê³¼) í‰ê· : {choice_fixed_stat['avg']:.6e}")
            
            if struct_stat and choice_lv_stat:
                ratio = choice_lv_stat['avg'] / struct_stat['avg']
                print(f"ì„ íƒëª¨ë¸(LVê³„ìˆ˜) / êµ¬ì¡°ëª¨ë¸ í‰ê·  ë¹„ìœ¨: {ratio:,.1f}x")
                print(f"  - êµ¬ì¡°ëª¨ë¸ í‰ê· : {struct_stat['avg']:.6e}")
                print(f"  - ì„ íƒëª¨ë¸(LVê³„ìˆ˜) í‰ê· : {choice_lv_stat['avg']:.6e}")
        
        # ê°œë³„ íŒŒë¼ë¯¸í„° ìƒì„¸
        print(f"\n{'íŒŒë¼ë¯¸í„°ë³„ ìƒì„¸':<30}")
        print("-"*80)
        print(f"{'ì¸ë±ìŠ¤':<6} {'ì´ë¦„':<45} {'ëª¨ë¸':<25} {'|grad|':>15}")
        print("-"*80)
        
        for p in sorted(params, key=lambda x: x['grad_abs'], reverse=True):
            model = categorize_parameters(p['name'])
            print(f"{p['index']:<6} {p['name']:<45} {model:<25} {p['grad_abs']:>15.6e}")


def main():
    log_file = "results/simultaneous_estimation_log_20251120_192842.txt"
    
    if not Path(log_file).exists():
        print(f"âŒ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {log_file}")
        return
    
    print(f"ğŸ“Š ë¡œê·¸ íŒŒì¼ ë¶„ì„: {log_file}\n")
    
    iterations = parse_gradient_from_log(log_file)
    
    if not iterations:
        print("âŒ ê·¸ë˜ë””ì–¸íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return
    
    print(f"âœ… {len(iterations)}ê°œ iterationì˜ ê·¸ë˜ë””ì–¸íŠ¸ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ\n")
    
    analyze_gradient_magnitudes(iterations)
    
    print("\n" + "="*80)
    print("ë¶„ì„ ì™„ë£Œ")
    print("="*80)


if __name__ == "__main__":
    main()

