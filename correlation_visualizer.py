#!/usr/bin/env python3
"""
semopy ìƒê´€ê³„ìˆ˜ ê²°ê³¼ ì‹œê°í™” ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ semopy_correlations.pyì—ì„œ ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ë“¤ì„ ë¶ˆëŸ¬ì™€ì„œ
ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ê²°ê³¼ íŒŒì¼ ë¡œë“œ (CSV, JSON)
2. ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ ì‹œê°í™”
3. pê°’ ì‹œê°í™”
4. í†µí•© ì‹œê°í™” (ìƒê´€ê³„ìˆ˜ + ìœ ì˜ì„±)
5. ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ì‹œê°í™”

íŠ¹ì§•:
- ê¸°ì¡´ ëª¨ë“ˆê³¼ ì™„ì „íˆ ë…ë¦½ì 
- ë†’ì€ ì¬ì‚¬ìš©ì„±ê³¼ í™•ì¥ì„±
- ê°„ê²°í•˜ë©´ì„œë„ ìœ ì§€ë³´ìˆ˜ ìš©ì´

Author: Sugar Substitute Research Team
Date: 2025-01-06
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union
import warnings

# ì˜ë¬¸ í°íŠ¸ ì„¤ì • (ê¸€ê¼´ ë¬¸ì œ í•´ê²°)
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings('ignore')


class CorrelationResultLoader:
    """semopy ìƒê´€ê³„ìˆ˜ ê²°ê³¼ íŒŒì¼ ë¡œë”"""
    
    def __init__(self, results_dir: str = "factor_correlations_results"):
        """
        ì´ˆê¸°í™”
        
        Args:
            results_dir: ê²°ê³¼ íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        """
        self.results_dir = Path(results_dir)
        
    def find_latest_files(self) -> Dict[str, Path]:
        """ê°€ì¥ ìµœê·¼ ê²°ê³¼ íŒŒì¼ë“¤ ì°¾ê¸°"""
        if not self.results_dir.exists():
            raise FileNotFoundError(f"ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.results_dir}")
        
        # íŒ¨í„´ë³„ íŒŒì¼ ì°¾ê¸°
        patterns = {
            'correlations': 'semopy_correlations_*.csv',
            'pvalues': 'semopy_pvalues_*.csv',
            'json': 'semopy_results_*.json'
        }
        
        latest_files = {}
        for key, pattern in patterns.items():
            files = list(self.results_dir.glob(pattern))
            if files:
                # íŒŒì¼ëª…ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
                latest_file = sorted(files, key=lambda x: x.stem.split('_')[-1])[-1]
                latest_files[key] = latest_file
            else:
                print(f"Warning: {pattern} íŒ¨í„´ì˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return latest_files
    
    def load_correlation_data(self, correlation_file: Optional[Path] = None, 
                            pvalue_file: Optional[Path] = None) -> Dict[str, pd.DataFrame]:
        """
        ìƒê´€ê³„ìˆ˜ì™€ pê°’ ë°ì´í„° ë¡œë“œ
        
        Args:
            correlation_file: ìƒê´€ê³„ìˆ˜ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ íƒì§€)
            pvalue_file: pê°’ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ íƒì§€)
            
        Returns:
            Dict containing 'correlations' and 'pvalues' DataFrames
        """
        if correlation_file is None or pvalue_file is None:
            latest_files = self.find_latest_files()
            correlation_file = correlation_file or latest_files.get('correlations')
            pvalue_file = pvalue_file or latest_files.get('pvalues')
        
        if not correlation_file or not correlation_file.exists():
            raise FileNotFoundError(f"ìƒê´€ê³„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {correlation_file}")
        if not pvalue_file or not pvalue_file.exists():
            raise FileNotFoundError(f"pê°’ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pvalue_file}")
        
        # ë°ì´í„° ë¡œë“œ
        correlations = pd.read_csv(correlation_file, index_col=0)
        pvalues = pd.read_csv(pvalue_file, index_col=0)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
        print(f"  - ìƒê´€ê³„ìˆ˜: {correlation_file.name}")
        print(f"  - pê°’: {pvalue_file.name}")
        print(f"  - ìš”ì¸ ìˆ˜: {len(correlations)}")
        
        return {
            'correlations': correlations,
            'pvalues': pvalues,
            'correlation_file': correlation_file,
            'pvalue_file': pvalue_file
        }
    
    def load_json_results(self, json_file: Optional[Path] = None) -> Dict:
        """JSON ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        if json_file is None:
            latest_files = self.find_latest_files()
            json_file = latest_files.get('json')
        
        if not json_file or not json_file.exists():
            raise FileNotFoundError(f"JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {json_file.name}")
        return data


class CorrelationVisualizer:
    """ìƒê´€ê³„ìˆ˜ ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self, figsize: Tuple[int, int] = (12, 10), style: str = 'whitegrid'):
        """
        ì´ˆê¸°í™”
        
        Args:
            figsize: ê¸°ë³¸ ê·¸ë˜í”„ í¬ê¸°
            style: seaborn ìŠ¤íƒ€ì¼
        """
        self.figsize = figsize
        sns.set_style(style)
        
        # ì˜ë¬¸ ìš”ì¸ëª… ë§¤í•‘ (ê¸€ê¼´ ë¬¸ì œ í•´ê²°)
        self.factor_labels = {
            'health_concern': 'Health\nConcern',
            'perceived_benefit': 'Perceived\nBenefit',
            'purchase_intention': 'Purchase\nIntention',
            'perceived_price': 'Perceived\nPrice',
            'nutrition_knowledge': 'Nutrition\nKnowledge'
        }
    
    def create_correlation_heatmap(self, correlations: pd.DataFrame, 
                                 pvalues: Optional[pd.DataFrame] = None,
                                 save_path: Optional[str] = None,
                                 show_values: bool = True,
                                 show_significance: bool = True) -> plt.Figure:
        """
        ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ ìƒì„±
        
        Args:
            correlations: ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤
            pvalues: pê°’ ë§¤íŠ¸ë¦­ìŠ¤ (ìœ ì˜ì„± í‘œì‹œìš©)
            save_path: ì €ì¥ ê²½ë¡œ
            show_values: ìˆ˜ì¹˜ í‘œì‹œ ì—¬ë¶€
            show_significance: ìœ ì˜ì„± í‘œì‹œ ì—¬ë¶€
            
        Returns:
            matplotlib Figure ê°ì²´
        """
        fig, ax = plt.subplots(figsize=self.figsize)
        
        # English labels applied
        corr_labeled = correlations.copy()
        corr_labeled.index = [self.factor_labels.get(idx, idx) for idx in correlations.index]
        corr_labeled.columns = [self.factor_labels.get(col, col) for col in correlations.columns]
        
        # íˆíŠ¸ë§µ ìƒì„±
        mask = np.triu(np.ones_like(corr_labeled, dtype=bool), k=1)  # ìƒì‚¼ê° ë§ˆìŠ¤í¬

        # ìƒê´€ê³„ìˆ˜ì™€ pê°’ì„ í•¨ê»˜ í‘œì‹œí•  ì–´ë…¸í…Œì´ì…˜ ìƒì„±
        if show_values and pvalues is not None:
            annot_array = self._create_correlation_with_pvalue_annotations(correlations, pvalues)
            annot_labeled = pd.DataFrame(annot_array,
                                       index=[self.factor_labels.get(idx, idx) for idx in correlations.index],
                                       columns=[self.factor_labels.get(col, col) for col in correlations.columns])

            sns.heatmap(corr_labeled,
                       mask=mask,
                       annot=annot_labeled,
                       fmt='',
                       cmap='RdBu_r',
                       center=0,
                       square=True,
                       cbar_kws={'label': 'Correlation Coefficient'},
                       ax=ax)
        else:
            sns.heatmap(corr_labeled,
                       mask=mask,
                       annot=show_values,
                       fmt='.3f',
                       cmap='RdBu_r',
                       center=0,
                       square=True,
                       cbar_kws={'label': 'Correlation Coefficient'},
                       ax=ax)
        
        # ìœ ì˜ì„± í‘œì‹œ
        if show_significance and pvalues is not None:
            self._add_significance_markers(ax, correlations, pvalues)
        
        ax.set_title('Factor Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š Heatmap saved: {save_path}")
        
        return fig
    
    def create_pvalue_heatmap(self, pvalues: pd.DataFrame,
                            save_path: Optional[str] = None) -> plt.Figure:
        """
        pê°’ì„ ìœ ì˜ì„± ìˆ˜ì¤€ì— ë”°ë¥¸ ìƒ‰ìƒìœ¼ë¡œ êµ¬ë¶„í•œ íˆíŠ¸ë§µ ìƒì„±

        Args:
            pvalues: pê°’ ë§¤íŠ¸ë¦­ìŠ¤
            save_path: ì €ì¥ ê²½ë¡œ

        Returns:
            matplotlib Figure ê°ì²´
        """
        fig, ax = plt.subplots(figsize=self.figsize)

        # ì˜ë¬¸ ë¼ë²¨ ì ìš©
        pval_labeled = pvalues.copy()
        pval_labeled.index = [self.factor_labels.get(idx, idx) for idx in pvalues.index]
        pval_labeled.columns = [self.factor_labels.get(col, col) for col in pvalues.columns]

        # ìƒì‚¼ê° ë§ˆìŠ¤í¬
        mask = np.triu(np.ones_like(pval_labeled, dtype=bool), k=1)

        # pê°’ì„ ìœ ì˜ì„± ìˆ˜ì¤€ì— ë”°ë¼ ì¹´í…Œê³ ë¦¬í™”
        significance_matrix = self._create_significance_matrix(pvalues)
        significance_labeled = pd.DataFrame(significance_matrix,
                                          index=[self.factor_labels.get(idx, idx) for idx in pvalues.index],
                                          columns=[self.factor_labels.get(col, col) for col in pvalues.columns])

        # ìœ ì˜ì„± ìˆ˜ì¤€ë³„ ì–´ë…¸í…Œì´ì…˜ ìƒì„±
        annot_matrix = self._create_significance_annotations(pvalues)
        annot_labeled = pd.DataFrame(annot_matrix,
                                   index=[self.factor_labels.get(idx, idx) for idx in pvalues.index],
                                   columns=[self.factor_labels.get(col, col) for col in pvalues.columns])

        # ì»¤ìŠ¤í…€ ì»¬ëŸ¬ë§µ ìƒì„± (ìœ ì˜ì„± ìˆ˜ì¤€ë³„)
        from matplotlib.colors import ListedColormap
        colors = ['#f0f0f0', '#ffcccc', '#ff9999', '#ff6666', '#cc0000']  # íšŒìƒ‰, ì—°í•œë¹¨ê°• -> ì§„í•œë¹¨ê°•
        custom_cmap = ListedColormap(colors)

        sns.heatmap(significance_labeled,
                   mask=mask,
                   annot=annot_labeled,
                   fmt='',
                   cmap=custom_cmap,
                   square=True,
                   cbar_kws={'label': 'Significance Level'},
                   vmin=0, vmax=4,
                   ax=ax)

        ax.set_title('Factor Correlation Significance Levels', fontsize=16, fontweight='bold', pad=20)

        # ì»¬ëŸ¬ë°” ë¼ë²¨ ìˆ˜ì •
        cbar = ax.collections[0].colorbar
        cbar.set_ticks([0.4, 1.2, 2.0, 2.8, 3.6])
        cbar.set_ticklabels(['n.s.', 'p<0.05', 'p<0.01', 'p<0.001', 'Diagonal'])

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ ìœ ì˜ì„± íˆíŠ¸ë§µ ì €ì¥: {save_path}")

        return fig

    def _create_significance_matrix(self, pvalues: pd.DataFrame) -> np.ndarray:
        """pê°’ì„ ìœ ì˜ì„± ìˆ˜ì¤€ì— ë”°ë¼ ì¹´í…Œê³ ë¦¬í™”í•œ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±"""
        significance_matrix = np.zeros(pvalues.shape)

        for i in range(len(pvalues)):
            for j in range(len(pvalues.columns)):
                p_val = pvalues.iloc[i, j]

                if i == j:
                    significance_matrix[i, j] = 4  # ëŒ€ê°ì„ 
                elif p_val < 0.001:
                    significance_matrix[i, j] = 3  # p < 0.001
                elif p_val < 0.01:
                    significance_matrix[i, j] = 2  # p < 0.01
                elif p_val < 0.05:
                    significance_matrix[i, j] = 1  # p < 0.05
                else:
                    significance_matrix[i, j] = 0  # not significant

        return significance_matrix

    def _create_significance_annotations(self, pvalues: pd.DataFrame) -> np.ndarray:
        """ìœ ì˜ì„± ìˆ˜ì¤€ ì–´ë…¸í…Œì´ì…˜ ìƒì„±"""
        annot_matrix = np.empty(pvalues.shape, dtype=object)

        for i in range(len(pvalues)):
            for j in range(len(pvalues.columns)):
                p_val = pvalues.iloc[i, j]

                if i == j:
                    annot_matrix[i, j] = '1.0'
                elif i > j:  # í•˜ì‚¼ê°ë§Œ í‘œì‹œ
                    if p_val < 0.001:
                        annot_matrix[i, j] = '***'
                    elif p_val < 0.01:
                        annot_matrix[i, j] = '**'
                    elif p_val < 0.05:
                        annot_matrix[i, j] = '*'
                    else:
                        annot_matrix[i, j] = 'n.s.'
                else:
                    annot_matrix[i, j] = ''

        return annot_matrix
    
    def _add_significance_markers(self, ax, correlations: pd.DataFrame, 
                                pvalues: pd.DataFrame):
        """íˆíŠ¸ë§µì— ìœ ì˜ì„± ë§ˆì»¤ ì¶”ê°€"""
        for i in range(len(correlations)):
            for j in range(i+1, len(correlations)):
                p_val = pvalues.iloc[i, j]
                
                # ìœ ì˜ì„± ë§ˆì»¤ ê²°ì •
                if p_val < 0.001:
                    marker = '***'
                elif p_val < 0.01:
                    marker = '**'
                elif p_val < 0.05:
                    marker = '*'
                else:
                    marker = ''
                
                if marker:
                    ax.text(j + 0.5, i + 0.7, marker,
                           ha='center', va='center',
                           fontsize=12, fontweight='bold', color='white')

    def _create_correlation_with_pvalue_annotations(self, correlations: pd.DataFrame,
                                                  pvalues: pd.DataFrame) -> np.ndarray:
        """ìƒê´€ê³„ìˆ˜ì™€ pê°’ì„ í•¨ê»˜ í‘œì‹œí•˜ëŠ” ì–´ë…¸í…Œì´ì…˜ ë°°ì—´ ìƒì„±"""
        annot_array = np.empty(correlations.shape, dtype=object)

        for i in range(len(correlations)):
            for j in range(len(correlations.columns)):
                corr_val = correlations.iloc[i, j]
                p_val = pvalues.iloc[i, j]

                if i == j:
                    # ëŒ€ê°ì„  ìš”ì†Œ
                    annot_array[i, j] = '1.000'
                elif i > j:
                    # í•˜ì‚¼ê° ìš”ì†Œ: ìƒê´€ê³„ìˆ˜ì™€ pê°’ í•¨ê»˜ í‘œì‹œ
                    if p_val < 0.001:
                        p_text = "p<0.001"
                    elif p_val < 0.01:
                        p_text = "p<0.01"
                    elif p_val < 0.05:
                        p_text = "p<0.05"
                    else:
                        p_text = f"p={p_val:.3f}"

                    annot_array[i, j] = f"{corr_val:.3f}\n{p_text}"
                else:
                    # ìƒì‚¼ê° ìš”ì†Œ: ë§ˆìŠ¤í¬ ì²˜ë¦¬ë¨
                    annot_array[i, j] = ""

        return annot_array

    def create_combined_correlation_plot(self, correlations: pd.DataFrame,
                                       pvalues: pd.DataFrame,
                                       save_path: Optional[str] = None) -> plt.Figure:
        """
        ìƒê´€ê³„ìˆ˜ì™€ pê°’ì„ ë™ì‹œì— ë³´ì—¬ì£¼ëŠ” ê²°í•© í”Œë¡¯ ìƒì„±

        Args:
            correlations: ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤
            pvalues: pê°’ ë§¤íŠ¸ë¦­ìŠ¤
            save_path: ì €ì¥ ê²½ë¡œ

        Returns:
            matplotlib Figure ê°ì²´
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))

        # ì˜ë¬¸ ë¼ë²¨ ì ìš©
        corr_labeled = correlations.copy()
        pval_labeled = pvalues.copy()

        corr_labeled.index = [self.factor_labels.get(idx, idx) for idx in correlations.index]
        corr_labeled.columns = [self.factor_labels.get(col, col) for col in correlations.columns]
        pval_labeled.index = [self.factor_labels.get(idx, idx) for idx in pvalues.index]
        pval_labeled.columns = [self.factor_labels.get(col, col) for col in pvalues.columns]

        # ìƒì‚¼ê° ë§ˆìŠ¤í¬
        mask = np.triu(np.ones_like(corr_labeled, dtype=bool), k=1)

        # ì™¼ìª½: ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ (pê°’ ì •ë³´ í¬í•¨)
        annot_array = self._create_correlation_with_pvalue_annotations(correlations, pvalues)
        annot_labeled = pd.DataFrame(annot_array,
                                   index=[self.factor_labels.get(idx, idx) for idx in correlations.index],
                                   columns=[self.factor_labels.get(col, col) for col in correlations.columns])

        sns.heatmap(corr_labeled,
                   mask=mask,
                   annot=annot_labeled,
                   fmt='',
                   cmap='RdBu_r',
                   center=0,
                   square=True,
                   cbar_kws={'label': 'Correlation Coefficient'},
                   ax=ax1)

        ax1.set_title('Correlation Coefficients with P-values', fontsize=14, fontweight='bold', pad=15)

        # ì˜¤ë¥¸ìª½: ìœ ì˜ì„± ìˆ˜ì¤€ íˆíŠ¸ë§µ
        significance_matrix = self._create_significance_matrix(pvalues)
        significance_labeled = pd.DataFrame(significance_matrix,
                                          index=[self.factor_labels.get(idx, idx) for idx in pvalues.index],
                                          columns=[self.factor_labels.get(col, col) for col in pvalues.columns])

        annot_matrix = self._create_significance_annotations(pvalues)
        annot_labeled_sig = pd.DataFrame(annot_matrix,
                                       index=[self.factor_labels.get(idx, idx) for idx in pvalues.index],
                                       columns=[self.factor_labels.get(col, col) for col in pvalues.columns])

        from matplotlib.colors import ListedColormap
        colors = ['#f0f0f0', '#ffcccc', '#ff9999', '#ff6666', '#cc0000']
        custom_cmap = ListedColormap(colors)

        sns.heatmap(significance_labeled,
                   mask=mask,
                   annot=annot_labeled_sig,
                   fmt='',
                   cmap=custom_cmap,
                   square=True,
                   cbar_kws={'label': 'Significance Level'},
                   vmin=0, vmax=4,
                   ax=ax2)

        ax2.set_title('Statistical Significance Levels', fontsize=14, fontweight='bold', pad=15)

        # ì˜¤ë¥¸ìª½ ì»¬ëŸ¬ë°” ë¼ë²¨ ìˆ˜ì •
        cbar2 = ax2.collections[0].colorbar
        cbar2.set_ticks([0.4, 1.2, 2.0, 2.8, 3.6])
        cbar2.set_ticklabels(['n.s.', 'p<0.05', 'p<0.01', 'p<0.001', 'Diagonal'])

        # ì „ì²´ ì œëª©
        fig.suptitle('Factor Correlations: Coefficients and Significance',
                    fontsize=16, fontweight='bold', y=0.98)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ê²°í•© í”Œë¡¯ ì €ì¥: {save_path}")

        return fig

    def create_bubble_plot(self, correlations: pd.DataFrame,
                          pvalues: pd.DataFrame,
                          save_path: Optional[str] = None) -> plt.Figure:
        """
        ìƒê´€ê³„ìˆ˜ì™€ pê°’ì„ ë²„ë¸” í”Œë¡¯ìœ¼ë¡œ ì‹œê°í™”

        Args:
            correlations: ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤
            pvalues: pê°’ ë§¤íŠ¸ë¦­ìŠ¤
            save_path: ì €ì¥ ê²½ë¡œ

        Returns:
            matplotlib Figure ê°ì²´
        """
        fig, ax = plt.subplots(figsize=self.figsize)

        # ë°ì´í„° ì¤€ë¹„
        factor_names = correlations.index.tolist()
        english_names = [self.factor_labels.get(name, name) for name in factor_names]

        x_coords = []
        y_coords = []
        corr_values = []
        p_values = []

        for i in range(len(factor_names)):
            for j in range(i+1, len(factor_names)):
                x_coords.append(i)
                y_coords.append(j)
                corr_values.append(correlations.iloc[i, j])
                p_values.append(pvalues.iloc[i, j])

        # ë²„ë¸” í¬ê¸° (ìƒê´€ê³„ìˆ˜ ì ˆëŒ“ê°’)
        bubble_sizes = [abs(corr) * 1000 for corr in corr_values]

        # ìƒ‰ìƒ (ìœ ì˜ì„± ìˆ˜ì¤€ ê¸°ë°˜)
        colors = []
        for p in p_values:
            if p < 0.001:
                colors.append(3)  # ê°€ì¥ ìœ ì˜í•¨
            elif p < 0.01:
                colors.append(2)
            elif p < 0.05:
                colors.append(1)
            else:
                colors.append(0)  # ìœ ì˜í•˜ì§€ ì•ŠìŒ

        # ë²„ë¸” í”Œë¡¯ ìƒì„±
        scatter = ax.scatter(x_coords, y_coords,
                           s=bubble_sizes,
                           c=colors,
                           cmap='Reds',
                           alpha=0.7,
                           edgecolors='black',
                           linewidth=1,
                           vmin=0, vmax=3)

        # ì»¬ëŸ¬ë°”
        cbar = plt.colorbar(scatter, ax=ax)
        cbar.set_label('Significance Level', fontsize=12)
        cbar.set_ticks([0.375, 1.125, 1.875, 2.625])
        cbar.set_ticklabels(['n.s.', 'p<0.05', 'p<0.01', 'p<0.001'])

        # ì¶• ì„¤ì •
        ax.set_xticks(range(len(english_names)))
        ax.set_yticks(range(len(english_names)))
        ax.set_xticklabels(english_names, rotation=45, ha='right')
        ax.set_yticklabels(english_names)

        # ìƒê´€ê³„ìˆ˜ ê°’ í‘œì‹œ
        for i, (x, y, corr) in enumerate(zip(x_coords, y_coords, corr_values)):
            ax.text(x, y, f'{corr:.3f}',
                   ha='center', va='center',
                   fontsize=10, fontweight='bold',
                   color='white' if abs(corr) > 0.5 else 'black')

        ax.set_title('Factor Correlations: Bubble Plot\n(Size = |Correlation|, Color = Significance)',
                    fontsize=14, fontweight='bold', pad=20)
        ax.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ«§ ë²„ë¸” í”Œë¡¯ ì €ì¥: {save_path}")

        return fig


class NetworkVisualizer:
    """ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ì‹œê°í™” í´ë˜ìŠ¤"""

    def __init__(self, figsize: Tuple[int, int] = (12, 10)):
        """ì´ˆê¸°í™”"""
        self.figsize = figsize

        # ì˜ë¬¸ ìš”ì¸ëª… ë§¤í•‘ (ê¸€ê¼´ ë¬¸ì œ í•´ê²°)
        self.factor_labels = {
            'health_concern': 'Health\nConcern',
            'perceived_benefit': 'Perceived\nBenefit',
            'purchase_intention': 'Purchase\nIntention',
            'perceived_price': 'Perceived\nPrice',
            'nutrition_knowledge': 'Nutrition\nKnowledge'
        }

    def create_network_graph(self, correlations: pd.DataFrame,
                           pvalues: pd.DataFrame,
                           threshold: float = 0.1,
                           save_path: Optional[str] = None) -> plt.Figure:
        """
        ìƒê´€ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±

        Args:
            correlations: ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤
            pvalues: pê°’ ë§¤íŠ¸ë¦­ìŠ¤
            threshold: í‘œì‹œí•  ìµœì†Œ ìƒê´€ê³„ìˆ˜ ì ˆëŒ“ê°’
            save_path: ì €ì¥ ê²½ë¡œ

        Returns:
            matplotlib Figure ê°ì²´
        """
        try:
            import networkx as nx
        except ImportError:
            print("Warning: networkxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì„¤ì¹˜ ë°©ë²•: pip install networkx")
            return None

        fig, ax = plt.subplots(figsize=self.figsize)

        # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
        G = nx.Graph()

        # ë…¸ë“œ ì¶”ê°€ (í•œêµ­ì–´ ë¼ë²¨)
        for factor in correlations.index:
            korean_label = self.factor_labels.get(factor, factor)
            G.add_node(korean_label)

        # ì—£ì§€ ì¶”ê°€ (ìœ ì˜í•œ ìƒê´€ê´€ê³„ë§Œ)
        edges = []
        edge_weights = []
        edge_colors = []

        for i, factor1 in enumerate(correlations.index):
            for j, factor2 in enumerate(correlations.columns):
                if i < j:  # ìƒì‚¼ê°ë§Œ ì²˜ë¦¬
                    corr_val = correlations.iloc[i, j]
                    p_val = pvalues.iloc[i, j]

                    if abs(corr_val) >= threshold and p_val < 0.05:
                        korean_label1 = self.factor_labels.get(factor1, factor1)
                        korean_label2 = self.factor_labels.get(factor2, factor2)

                        G.add_edge(korean_label1, korean_label2, weight=abs(corr_val))
                        edges.append((korean_label1, korean_label2))
                        edge_weights.append(abs(corr_val) * 5)  # ì‹œê°í™”ìš© ê°€ì¤‘ì¹˜

                        # ì–‘ì˜ ìƒê´€ê´€ê³„ëŠ” ë¹¨ê°„ìƒ‰, ìŒì˜ ìƒê´€ê´€ê³„ëŠ” íŒŒë€ìƒ‰
                        edge_colors.append('red' if corr_val > 0 else 'blue')

        # ë ˆì´ì•„ì›ƒ ì„¤ì •
        pos = nx.spring_layout(G, k=2, iterations=50)

        # ë…¸ë“œ ê·¸ë¦¬ê¸°
        nx.draw_networkx_nodes(G, pos,
                              node_color='lightblue',
                              node_size=3000,
                              alpha=0.7,
                              ax=ax)

        # ì—£ì§€ ê·¸ë¦¬ê¸°
        if edges:
            nx.draw_networkx_edges(G, pos,
                                  edgelist=edges,
                                  width=edge_weights,
                                  edge_color=edge_colors,
                                  alpha=0.6,
                                  ax=ax)

        # ë¼ë²¨ ê·¸ë¦¬ê¸°
        nx.draw_networkx_labels(G, pos,
                               font_size=10,
                               font_weight='bold',
                               ax=ax)

        ax.set_title('Factor Correlation Network\n(Significant relationships only, p<0.05)',
                    fontsize=16, fontweight='bold', pad=20)
        ax.axis('off')

        # ë²”ë¡€ ì¶”ê°€
        from matplotlib.lines import Line2D
        legend_elements = [
            Line2D([0], [0], color='red', lw=3, label='Positive Correlation'),
            Line2D([0], [0], color='blue', lw=3, label='Negative Correlation')
        ]
        ax.legend(handles=legend_elements, loc='upper right')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ•¸ï¸ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ì €ì¥: {save_path}")

        return fig


class IntegratedVisualizer:
    """í†µí•© ì‹œê°í™” í´ë˜ìŠ¤"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.loader = CorrelationResultLoader()
        self.visualizer = CorrelationVisualizer()
        self.network_visualizer = NetworkVisualizer()
    
    def create_comprehensive_report(self, output_dir: str = "correlation_visualization_results") -> Dict[str, str]:
        """
        ì¢…í•© ì‹œê°í™” ë³´ê³ ì„œ ìƒì„±
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            
        Returns:
            ìƒì„±ëœ íŒŒì¼ë“¤ì˜ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬
        """
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            data = self.loader.load_correlation_data()
            correlations = data['correlations']
            pvalues = data['pvalues']
            
            generated_files = {}
            
            # 1. ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ
            corr_heatmap_path = output_path / f"correlation_heatmap_{timestamp}.png"
            self.visualizer.create_correlation_heatmap(
                correlations, pvalues, 
                save_path=str(corr_heatmap_path),
                show_significance=True
            )
            generated_files['correlation_heatmap'] = str(corr_heatmap_path)
            
            # 2. pê°’ íˆíŠ¸ë§µ
            pval_heatmap_path = output_path / f"pvalue_heatmap_{timestamp}.png"
            self.visualizer.create_pvalue_heatmap(
                pvalues,
                save_path=str(pval_heatmap_path)
            )
            generated_files['pvalue_heatmap'] = str(pval_heatmap_path)

            # 3. ê²°í•© í”Œë¡¯ (ìƒê´€ê³„ìˆ˜ + pê°’)
            combined_path = output_path / f"combined_plot_{timestamp}.png"
            self.visualizer.create_combined_correlation_plot(
                correlations, pvalues,
                save_path=str(combined_path)
            )
            generated_files['combined_plot'] = str(combined_path)

            # 4. ë²„ë¸” í”Œë¡¯
            bubble_path = output_path / f"bubble_plot_{timestamp}.png"
            self.visualizer.create_bubble_plot(
                correlations, pvalues,
                save_path=str(bubble_path)
            )
            generated_files['bubble_plot'] = str(bubble_path)

            # 5. ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ (networkxê°€ ì„¤ì¹˜ëœ ê²½ìš°)
            network_path = output_path / f"network_graph_{timestamp}.png"
            network_fig = self.network_visualizer.create_network_graph(
                correlations, pvalues,
                threshold=0.1,
                save_path=str(network_path)
            )
            if network_fig is not None:
                generated_files['network_graph'] = str(network_path)
            
            print(f"\nğŸ¨ ì¢…í•© ì‹œê°í™” ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {output_path}")
            print(f"ğŸ“Š ìƒì„±ëœ íŒŒì¼: {len(generated_files)}ê°œ")
            
            return generated_files
            
        except Exception as e:
            print(f"âŒ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def show_summary_statistics(self):
        """ìš”ì•½ í†µê³„ ì¶œë ¥"""
        try:
            data = self.loader.load_correlation_data()
            correlations = data['correlations']
            pvalues = data['pvalues']
            
            print("\n" + "="*60)
            print("ğŸ“Š ìƒê´€ê³„ìˆ˜ ë¶„ì„ ìš”ì•½")
            print("="*60)
            
            # ìƒê´€ê³„ìˆ˜ í†µê³„
            upper_triangle = np.triu(correlations.values, k=1)
            upper_triangle = upper_triangle[upper_triangle != 0]
            
            print(f"\nğŸ“ˆ ìƒê´€ê³„ìˆ˜ í†µê³„:")
            print(f"  - í‰ê· : {upper_triangle.mean():.4f}")
            print(f"  - ìµœëŒ€ê°’: {upper_triangle.max():.4f}")
            print(f"  - ìµœì†Œê°’: {upper_triangle.min():.4f}")
            print(f"  - í‘œì¤€í¸ì°¨: {upper_triangle.std():.4f}")
            
            # ìœ ì˜í•œ ìƒê´€ê´€ê³„ ê°œìˆ˜
            upper_pvals = np.triu(pvalues.values, k=1)
            upper_pvals = upper_pvals[upper_pvals != 0]
            
            significant_count = (upper_pvals < 0.05).sum()
            total_count = len(upper_pvals)
            
            print(f"\nğŸ¯ ìœ ì˜ì„± ë¶„ì„:")
            print(f"  - ì „ì²´ ìƒê´€ê´€ê³„: {total_count}ê°œ")
            print(f"  - ìœ ì˜í•œ ê´€ê³„ (p<0.05): {significant_count}ê°œ")
            print(f"  - ìœ ì˜ì„± ë¹„ìœ¨: {significant_count/total_count*100:.1f}%")
            
        except Exception as e:
            print(f"âŒ ìš”ì•½ í†µê³„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¨ semopy ìƒê´€ê³„ìˆ˜ ê²°ê³¼ ì‹œê°í™”")
    print("="*50)
    
    try:
        # í†µí•© ì‹œê°í™” ì‹¤í–‰
        visualizer = IntegratedVisualizer()
        
        # ìš”ì•½ í†µê³„ ì¶œë ¥
        visualizer.show_summary_statistics()
        
        # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        generated_files = visualizer.create_comprehensive_report()
        
        print(f"\nğŸ“ ìƒì„±ëœ ì‹œê°í™” íŒŒì¼:")
        for key, path in generated_files.items():
            print(f"  - {key}: {Path(path).name}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì‹œê°í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ ìƒê´€ê³„ìˆ˜ ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nğŸ’¥ ì‹œê°í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
