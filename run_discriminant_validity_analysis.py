"""
íŒë³„íƒ€ë‹¹ë„ ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ì™€ ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì™€ì„œ
íŒë³„íƒ€ë‹¹ë„ë¥¼ ê²€ì¦í•˜ê³  ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python run_discriminant_validity_analysis.py

ê¸°ëŠ¥:
1. ìµœì‹  ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ìë™ ë¡œë“œ
2. ìµœì‹  ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼ ìë™ ë¡œë“œ
3. Fornell-Larcker ê¸°ì¤€ìœ¼ë¡œ íŒë³„íƒ€ë‹¹ë„ ê²€ì¦
4. ê²°ê³¼ ì‹œê°í™” ë° ë³´ê³ ì„œ ìƒì„±
"""

import sys
from pathlib import Path
from discriminant_validity_analyzer import DiscriminantValidityAnalyzer

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("íŒë³„íƒ€ë‹¹ë„ ë¶„ì„ (Discriminant Validity Analysis)")
    print("=" * 80)
    print()
    
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        print("1. ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        analyzer = DiscriminantValidityAnalyzer()
        
        # íŒŒì¼ ê²½ë¡œ í™•ì¸
        print(f"   ìƒê´€ê´€ê³„ ë°ì´í„°: {analyzer.correlation_file}")
        print(f"   ì‹ ë¢°ë„ ë°ì´í„°: {analyzer.reliability_file}")
        print()
        
        if not analyzer.correlation_file:
            print("âŒ ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   factor_correlations_results/ ë””ë ‰í† ë¦¬ì— semopy_correlations_*.csv íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
            
        if not analyzer.reliability_file:
            print("âŒ ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   integrated_reliability_results_*/ ë””ë ‰í† ë¦¬ì— reliability_summary_table.csv íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
        
        # ì „ì²´ ë¶„ì„ ì‹¤í–‰
        print("2. íŒë³„íƒ€ë‹¹ë„ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        success = analyzer.run_complete_analysis()
        
        if success:
            print()
            print("âœ… íŒë³„íƒ€ë‹¹ë„ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print()
            print("ìƒì„±ëœ íŒŒì¼ë“¤:")
            print("ğŸ“Š ì‹œê°í™” íŒŒì¼:")
            print("   - correlation_vs_ave_comparison.png: ìƒê´€ê³„ìˆ˜ vs AVE ì œê³±ê·¼ ë¹„êµ")
            print("   - discriminant_validity_matrix.png: íŒë³„íƒ€ë‹¹ë„ ê²€ì¦ ê²°ê³¼ ë§¤íŠ¸ë¦­ìŠ¤")
            print("   - discriminant_validity_dashboard.png: ì¢…í•© ëŒ€ì‹œë³´ë“œ")
            if analyzer.discriminant_validity_results['violations']:
                print("   - discriminant_validity_violations.png: ìœ„ë°˜ ì‚¬í•­ ì‹œê°í™”")
            print()
            print("ğŸ“„ ë³´ê³ ì„œ ë° ë°ì´í„°:")
            print("   - discriminant_validity_report_*.txt: ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ")
            print("   - discriminant_validity_results_*.csv: ê²€ì¦ ê²°ê³¼ ë°ì´í„°")
            print("   - correlation_ave_comparison_matrix_*.csv: ë¹„êµ ë§¤íŠ¸ë¦­ìŠ¤")
            print()
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            summary = analyzer.discriminant_validity_results['summary']
            print("ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
            print(f"   ì „ì²´ ìš”ì¸ ìŒ: {summary['total_factor_pairs']}ê°œ")
            print(f"   ìœ íš¨í•œ ìŒ: {summary['valid_pairs']}ê°œ")
            print(f"   ìœ„ë°˜ ìŒ: {summary['invalid_pairs']}ê°œ")
            print(f"   ìœ íš¨ìœ¨: {summary['validity_rate']:.1%}")
            
            if summary['overall_discriminant_validity']:
                print("   ğŸ‰ ì „ì²´ íŒë³„íƒ€ë‹¹ë„: ë‹¬ì„± âœ…")
                print("      ëª¨ë“  ìš”ì¸ì´ Fornell-Larcker ê¸°ì¤€ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")
            else:
                print("   âš ï¸  ì „ì²´ íŒë³„íƒ€ë‹¹ë„: ë¯¸ë‹¬ì„± âŒ")
                print("      ì¼ë¶€ ìš”ì¸ ìŒì´ íŒë³„íƒ€ë‹¹ë„ ê¸°ì¤€ì„ ìœ„ë°˜í–ˆìŠµë‹ˆë‹¤.")
                print("      ìƒì„¸í•œ ë‚´ìš©ì€ ë³´ê³ ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            
            return True
            
        else:
            print("âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            return False
            
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def check_requirements():
    """í•„ìš”í•œ íŒ¨í‚¤ì§€ í™•ì¸"""
    required_packages = ['pandas', 'numpy', 'matplotlib', 'seaborn']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print(f"pip install {' '.join(missing_packages)}")
        return False
    
    return True

if __name__ == "__main__":
    # íŒ¨í‚¤ì§€ ìš”êµ¬ì‚¬í•­ í™•ì¸
    if not check_requirements():
        sys.exit(1)
    
    # ë©”ì¸ ë¶„ì„ ì‹¤í–‰
    success = main()
    
    if success:
        print("\nğŸ¯ ë¶„ì„ ì™„ë£Œ! discriminant_validity_results/ ë””ë ‰í† ë¦¬ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(0)
    else:
        print("\nğŸ’¥ ë¶„ì„ ì‹¤íŒ¨!")
        sys.exit(1)
