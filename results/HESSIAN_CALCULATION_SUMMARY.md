# Hessian ê³„ì‚° ë¡œì§ ìš”ì•½

**ë‚ ì§œ**: 2025-11-20  
**ë¡œê·¸ íŒŒì¼**: `simultaneous_estimation_log_20251120_192842.txt`

---

## ğŸ¯ í•µì‹¬ ìš”ì•½

### âœ… L-BFGS-BëŠ” `hess_inv`ë¥¼ ì œê³µí•©ë‹ˆë‹¤!

í˜„ì¬ ì‹œìŠ¤í…œì˜ Hessian ê³„ì‚°:

| ë°©ë²• | íƒ€ì… | ì‚¬ìš© ì‹œì  | ìƒíƒœ |
|------|------|-----------|------|
| **L-BFGS-B** | `LbfgsInvHessProduct` | ìµœì í™” ì„±ê³µ ì‹œ ìë™ ì œê³µ | âœ… ì£¼ ë°©ë²• |
| **BFGS** | `numpy.ndarray` | ìµœì í™” ì„±ê³µ ì‹œ ìë™ ì œê³µ | âœ… ì£¼ ë°©ë²• |
| **BHHH** | `numpy.ndarray` | Fallback (hess_inv ì—†ì„ ë•Œ) | âš ï¸ ë“œë¬¼ê²Œ ì‚¬ìš© |

**í˜„ì¬ ë¬¸ì œ**: L-BFGS-Bì˜ Hessian ê·¼ì‚¬ê°€ ill-conditioned â†’ ìµœì í™” ì¤‘ë‹¨ â†’ hess_invë¥¼ ë°›ì„ ìˆ˜ ì—†ìŒ

---

## ğŸ“ 1. L-BFGS-Bì˜ Hessian ê·¼ì‚¬ (ìµœì í™” ì¤‘)

### ì•Œê³ ë¦¬ì¦˜

```python
# L-BFGS-B í•µì‹¬ ë¡œì§
for iteration in range(maxiter):
    # 1. Gradient ê³„ì‚°
    g = jac(x)  # Analytic gradient
    
    # 2. íƒìƒ‰ ë°©í–¥ ê³„ì‚° (Two-loop recursion)
    # H^(-1) Â· gë¥¼ ì•”ë¬µì ìœ¼ë¡œ ê³„ì‚° (ì „ì²´ H ì €ì¥ ì•ˆ í•¨)
    p = two_loop_recursion(s_history, y_history, g)
    
    # 3. Line search
    alpha = line_search(fun, jac, x, p, g)
    
    # 4. íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    x_new = x + alpha * p
    g_new = jac(x_new)
    
    # 5. (s, y) ìŒ ì €ì¥ (ìµœê·¼ 10ê°œë§Œ)
    s = x_new - x  # íŒŒë¼ë¯¸í„° ë³€í™”
    y = g_new - g  # Gradient ë³€í™”
    
    s_history.append(s)
    y_history.append(y)
```

### Two-Loop Recursion

```python
def two_loop_recursion(s_history, y_history, g):
    """
    H^(-1) Â· gë¥¼ ì•”ë¬µì ìœ¼ë¡œ ê³„ì‚°
    
    ì „ì²´ Hessian í–‰ë ¬ì„ ë§Œë“¤ì§€ ì•Šê³ 
    ìµœê·¼ mê°œì˜ (s, y) ìŒë§Œ ì‚¬ìš©
    """
    q = g.copy()
    
    # First loop (backward)
    for i in reversed(range(m)):
        rho[i] = 1.0 / (y[i]^T Â· s[i])  # â† ë¬¸ì œ ë°œìƒ ì§€ì !
        alpha[i] = rho[i] * (s[i]^T Â· q)
        q = q - alpha[i] * y[i]
    
    # Initial Hessian approximation
    gamma = (s[-1]^T Â· y[-1]) / (y[-1]^T Â· y[-1])
    r = gamma * q
    
    # Second loop (forward)
    for i in range(m):
        beta = rho[i] * (y[i]^T Â· r)
        r = r + s[i] * (alpha[i] - beta)
    
    return -r  # íƒìƒ‰ ë°©í–¥
```

### ë¬¸ì œ ë°œìƒ ë©”ì»¤ë‹ˆì¦˜

**Iteration #2 ì‹¤ì œ ë°ì´í„°**:
```
s_k norm: 0.747
y_k norm: 515.4
ë¹„ìœ¨: 690.2  â† ë§¤ìš° í¼!

s_k^T Â· y_k: 319.4
Ï = 1 / 319.4 = 0.00313
```

**Two-loop recursion ì‹¤í–‰**:
```python
# First loop
rho = 0.00313
alpha = 0.00313 * (s^T Â· q)  # s^T Â· qê°€ ë§¤ìš° í¼
q = q - alpha * y  # yê°€ ë§¤ìš° í¬ë¯€ë¡œ qê°€ ê¸‰ê²©íˆ ê°ì†Œ

# ê²°ê³¼
q â‰ˆ 0  # qê°€ ê±°ì˜ 0ì´ ë¨
r = gamma * q â‰ˆ 0
p = -r â‰ˆ 0  # íƒìƒ‰ ë°©í–¥ì´ 0!
```

**ê²°ê³¼**:
- âŒ íƒìƒ‰ ë°©í–¥ `d norm = 0.000000`
- âŒ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ë¶ˆê°€
- âŒ ìµœì í™” ì¤‘ë‹¨

---

## ğŸŸ¢ 2. L-BFGS-Bì˜ hess_inv ì œê³µ

### L-BFGS-BëŠ” hess_invë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤!

```python
result = scipy.optimize.minimize(..., method='L-BFGS-B')

# âœ… hess_inv ì¡´ì¬
print(type(result.hess_inv))
# <class 'scipy.optimize._lbfgsb_py.LbfgsInvHessProduct'>

# numpy ë°°ì—´ë¡œ ë³€í™˜
hess_inv_array = result.hess_inv.todense()
```

**íŠ¹ì§•**:
- íƒ€ì…: `LbfgsInvHessProduct` (BFGSëŠ” `numpy.ndarray`)
- ë©”ëª¨ë¦¬: (s, y) ìŒë§Œ ì €ì¥ (ì „ì²´ í–‰ë ¬ ì €ì¥ ì•ˆ í•¨)
- ë³€í™˜: `todense()` ë©”ì„œë“œë¡œ numpy ë°°ì—´ë¡œ ë³€í™˜
- ì—°ì‚°: `hess_inv @ v` ë²¡í„° ê³± ì§€ì›

---

## ğŸ”µ 3. BHHH Hessian ê³„ì‚° (Fallback)

### ì‚¬ìš© ì‹œì 

**Optimizerê°€ hess_invë¥¼ ì œê³µí•˜ì§€ ì•Šì„ ë•Œë§Œ ì‚¬ìš©** (BFGS/L-BFGS-BëŠ” ì œê³µí•¨)

### ì´ë¡ 

**ì •í™•í•œ Hessian** (2ì°¨ ë¯¸ë¶„):
```
H = âˆ‚Â²LL/âˆ‚Î¸âˆ‚Î¸^T = Î£_i âˆ‚Â²LL_i/âˆ‚Î¸âˆ‚Î¸^T
```

**BHHH ê·¼ì‚¬** (1ì°¨ ë¯¸ë¶„ë§Œ):
```
H â‰ˆ Î£_i (grad_i Ã— grad_i^T)
  = OPG (Outer Product of Gradients)
```

### êµ¬í˜„

```python
def compute_bhhh_hessian(individual_gradients):
    """
    ê°œì¸ë³„ gradientë¡œë¶€í„° BHHH Hessian ê³„ì‚°
    """
    n_params = len(individual_gradients[0])
    hessian = np.zeros((n_params, n_params))
    
    # Î£_i (grad_i Ã— grad_i^T)
    for grad_i in individual_gradients:
        hessian += np.outer(grad_i, grad_i)
    
    # ìµœì†Œí™” ë¬¸ì œì´ë¯€ë¡œ ìŒìˆ˜
    hessian = -hessian
    
    return hessian

def compute_hessian_inverse(hessian):
    """
    Hessian ì—­í–‰ë ¬ ê³„ì‚° (ì •ê·œí™” í¬í•¨)
    """
    # ì •ê·œí™” (ìˆ˜ì¹˜ ì•ˆì •ì„±)
    hessian_reg = hessian + 1e-8 * np.eye(n_params)
    
    # ì—­í–‰ë ¬
    hess_inv = np.linalg.inv(hessian_reg)
    
    return hess_inv

def compute_standard_errors(hess_inv):
    """
    í‘œì¤€ì˜¤ì°¨ ê³„ì‚°
    """
    # SE = sqrt(diag(H^(-1)))
    variances = np.diag(hess_inv)
    se = np.sqrt(np.abs(variances))
    
    return se
```

### ì¥ì 

âœ… **ê³„ì‚° íš¨ìœ¨**: 2ì°¨ ë¯¸ë¶„ ë¶ˆí•„ìš”  
âœ… **ì „ì²´ Hessian**: ëª¨ë“  ìƒê´€ê´€ê³„ í¬í•¨  
âœ… **í‘œì¤€ì˜¤ì°¨**: ì •í™•í•œ SE ê³„ì‚°  
âœ… **ì•ˆì •ì„±**: ì •ê·œí™”ë¡œ ìˆ˜ì¹˜ ì•ˆì •ì„± í™•ë³´

---

## ğŸ”´ 3. í˜„ì¬ ë¬¸ì œ ì§„ë‹¨

### 3.1 L-BFGS-Bì˜ ì‹¤íŒ¨ ì›ì¸

| ì›ì¸ | ì„¤ëª… | ì˜í–¥ |
|------|------|------|
| **Gradient ë¶ˆê· í˜•** | êµ¬ì¡°ëª¨ë¸(~0.01) vs ì„ íƒëª¨ë¸(~600) | y_k normì´ ë§¤ìš° í¼ |
| **íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼** | ëª¨ë‘ 1.0ìœ¼ë¡œ ê³ ì • | ë¶ˆê· í˜• í•´ì†Œ ë¶ˆê°€ |
| **y_k/s_k ë¹„ìœ¨** | 690.2 (ë§¤ìš° í¼) | Ïê°€ ì‘ì•„ì§ |
| **Two-loop ë¶ˆì•ˆì •** | Ï * (í° ê°’) ê³„ì‚° | q â‰ˆ 0 |
| **íƒìƒ‰ ë°©í–¥ 0** | p = -r â‰ˆ 0 | ìµœì í™” ì¤‘ë‹¨ |

### 3.2 ì„±ë¶„ë³„ ë¶„ì„ (Iteration #2)

| ì„±ë¶„ | s_k | y_k | ë¹„ìœ¨ | íŒŒë¼ë¯¸í„° |
|------|-----|-----|------|----------|
| [0] | 8.08e-05 | 6.94e-18 | 0.00 | gamma_HC_PB |
| [1] | -2.07e-05 | 3.71e-06 | 0.18 | gamma_PB_PI |
| [2] | 0.266 | -7.45 | 28.0 | asc_sugar |
| [3] | 0.294 | 172.9 | **589.0** | asc_sugar_free âš ï¸ |
| [4] | 0.350 | 44.7 | 127.8 | beta_health_label |

**í•µì‹¬ ë°œê²¬**:
- ì„±ë¶„ [3] (asc_sugar_free)ì˜ ë¹„ìœ¨ì´ **589**ë¡œ ê·¹ë‹¨ì 
- êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°ëŠ” ê±°ì˜ ë³€í™” ì—†ìŒ
- ì„ íƒëª¨ë¸ gradientê°€ ê³¼ë„í•˜ê²Œ í¼

---

## ğŸ’¡ 4. í•´ê²°ì±…

### 4.1 íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§ í™œì„±í™”

```python
# config ìˆ˜ì •
config.estimation.use_parameter_scaling = True  # í˜„ì¬ False

# íš¨ê³¼
scale_factors = 1.0 / np.maximum(np.abs(initial_gradient), 1.0)
# â†’ Gradient í¬ê¸°ì— ë”°ë¼ ìë™ ìŠ¤ì¼€ì¼ë§
# â†’ y_k/s_k ë¹„ìœ¨ ê°ì†Œ
```

### 4.2 Hessian ì£¼ê¸°ì  ë¦¬ì…‹

```python
# 10 iterationsë§ˆë‹¤ Hessian ì´ˆê¸°í™”
if iteration % 10 == 0:
    s_history.clear()
    y_history.clear()
    # â†’ H = Ië¡œ ë¦¬ì…‹
    # â†’ ill-conditioning ë°©ì§€
```

### 4.3 Trust Region ë°©ë²•

```python
# L-BFGS-B ëŒ€ì‹  Trust Region ì‚¬ìš©
config.estimation.optimizer = 'trust-constr'

# íš¨ê³¼
# â†’ íŒŒë¼ë¯¸í„° ë³€í™”ë¥¼ ì œí•œ
# â†’ Hessian ê·¼ì‚¬ ë¬¸ì œì— ëœ ë¯¼ê°
```

---

## ğŸ“Š 5. ì½”ë“œ ìœ„ì¹˜

### L-BFGS-B ìµœì í™”
- **íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/simultaneous_estimator_fixed.py`
- **ë¼ì¸**: 1305-1340
- **í•¨ìˆ˜**: `estimate()`

### BHHH Hessian ê³„ì‚°
- **íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/bhhh_calculator.py`
- **ë¼ì¸**: 51-164 (compute_bhhh_hessian)
- **ë¼ì¸**: 166-215 (compute_hessian_inverse)
- **ë¼ì¸**: 217-260 (compute_standard_errors)

---

## ğŸ“ ê²°ë¡ 

### âœ… L-BFGS-BëŠ” `hess_inv`ë¥¼ ì œê³µí•©ë‹ˆë‹¤!

**ì½”ë“œ ìˆ˜ì • ì‚¬í•­**:
1. âœ… ì˜ëª»ëœ ì£¼ì„ ìˆ˜ì •: "L-BFGS-BëŠ” hess_inv ì œê³µ ì•ˆ í•¨" â†’ ì‚­ì œ
2. âœ… ë¡œê¹… ëª…í™•í™”: L-BFGS-B vs BFGS êµ¬ë¶„
3. âœ… BHHHëŠ” Fallback: optimizerê°€ hess_invë¥¼ ì œê³µí•˜ì§€ ì•Šì„ ë•Œë§Œ ì‚¬ìš©

**í˜„ì¬ ë¬¸ì œ**:
- L-BFGS-Bì˜ Hessian ê·¼ì‚¬ê°€ ill-conditioned ìƒíƒœ
- y_k/s_k ë¹„ìœ¨ì´ 690ìœ¼ë¡œ ê·¹ë‹¨ì ìœ¼ë¡œ í¼
- Two-loop recursionì—ì„œ íƒìƒ‰ ë°©í–¥ì´ 0ì´ ë¨
- **ìµœì í™”ê°€ ì¤‘ë‹¨ë˜ì–´ hess_invë¥¼ ë°›ì„ ìˆ˜ ì—†ìŒ**

**í•´ê²° ë°©ë²•**:
1. íŒŒë¼ë¯¸í„° ìŠ¤ì¼€ì¼ë§ í™œì„±í™” (1ìˆœìœ„)
2. Hessian ì£¼ê¸°ì  ë¦¬ì…‹ (1ìˆœìœ„)
3. Trust Region ë°©ë²• (2ìˆœìœ„)

**ì°¸ê³  ë¬¸ì„œ**:
- `docs/HESSIAN_CALCULATION_LOGIC_EXPLAINED.md` - ìƒì„¸ ì„¤ëª… (ì—…ë°ì´íŠ¸ë¨)
- `results/HESSIAN_CONVERGENCE_ISSUE_REPORT_20251120.md` - ì§„ë‹¨ ë³´ê³ ì„œ
- `scripts/test_lbfgsb_hess_inv.py` - L-BFGS-B hess_inv í…ŒìŠ¤íŠ¸

