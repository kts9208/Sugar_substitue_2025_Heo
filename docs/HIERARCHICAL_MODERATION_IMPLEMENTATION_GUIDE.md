# ê³„ì¸µì  êµ¬ì¡° ë° ì¡°ì ˆíš¨ê³¼ êµ¬í˜„ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025-11-11  
**ëª©ì **: ì œì•ˆëœ ICLV êµ¬ì¡° ìˆ˜ì •ì‚¬í•­ êµ¬í˜„ ë°©ë²•

---

## ğŸ“‹ êµ¬í˜„ ê°œìš”

### ëª©í‘œ êµ¬ì¡°
```
1ì°¨ LV (ì™¸ìƒ):
  ê±´ê°•ê´€ì‹¬ë„ = Î·â‚ ~ N(0,1)
  ê°€ê²©ìˆ˜ì¤€ = Î·â‚‚ ~ N(0,1)
  ì˜ì–‘ì§€ì‹ = Î·â‚ƒ ~ N(0,1)

2ì°¨ LV (ì¤‘ê°„ ë‚´ìƒ):
  ê±´ê°•ìœ ìµì„± = Î³â‚Â·ê±´ê°•ê´€ì‹¬ë„ + Î·â‚‚

3ì°¨ LV (ìµœì¢… ë‚´ìƒ):
  êµ¬ë§¤ì˜ë„ = Î³â‚‚Â·ê±´ê°•ìœ ìµì„± + Î·â‚ƒ

ì„ íƒëª¨ë¸ (ì¡°ì ˆíš¨ê³¼):
  V = intercept + Î²Â·X + Î»â‚Â·êµ¬ë§¤ì˜ë„ + Î»â‚‚Â·(êµ¬ë§¤ì˜ë„Ã—ê°€ê²©ìˆ˜ì¤€) + Î»â‚ƒÂ·(êµ¬ë§¤ì˜ë„Ã—ì˜ì–‘ì§€ì‹)
```

---

## ğŸ”§ Phase 1: ê³„ì¸µì  êµ¬ì¡° êµ¬í˜„

### Step 1.1: ìƒˆë¡œìš´ Config í´ë˜ìŠ¤ ìƒì„±

**íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/hierarchical_config.py`

```python
"""
Hierarchical Structural Model Configuration
ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸ ì„¤ì •
"""

from dataclasses import dataclass, field
from typing import List, Dict, Optional

@dataclass
class HierarchicalPath:
    """
    ê³„ì¸µì  ê²½ë¡œ ì •ì˜
    
    Example:
        # ê±´ê°•ìœ ìµì„± = Î³â‚ * ê±´ê°•ê´€ì‹¬ë„ + Î·
        HierarchicalPath(
            target='perceived_benefit',
            predictors=['health_concern'],
            error_variance=1.0
        )
    """
    target: str  # ëª©í‘œ ì ì¬ë³€ìˆ˜
    predictors: List[str]  # ì˜ˆì¸¡ ì ì¬ë³€ìˆ˜ë“¤
    error_variance: float = 1.0
    fix_error_variance: bool = True


@dataclass
class HierarchicalStructuralConfig:
    """
    ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸ ì„¤ì •
    
    êµ¬ì¡°:
    - 1ì°¨ LV (ì™¸ìƒ): LV_i = Î·_i ~ N(0, 1)
    - 2ì°¨+ LV (ë‚´ìƒ): LV_j = Î£(Î³_k * LV_k) + Î·_j
    
    Example:
        config = HierarchicalStructuralConfig(
            first_order_lvs=['health_concern', 'perceived_price', 'nutrition_knowledge'],
            hierarchical_paths=[
                HierarchicalPath(
                    target='perceived_benefit',
                    predictors=['health_concern'],
                    error_variance=1.0
                ),
                HierarchicalPath(
                    target='purchase_intention',
                    predictors=['perceived_benefit'],
                    error_variance=1.0
                )
            ]
        )
    """
    
    # 1ì°¨ ì ì¬ë³€ìˆ˜ (ì™¸ìƒ)
    first_order_lvs: List[str]
    
    # ê³„ì¸µì  ê²½ë¡œ
    hierarchical_paths: List[HierarchicalPath]
    
    # ì‚¬íšŒì¸êµ¬í•™ì  ë³€ìˆ˜ (ì„ íƒì‚¬í•­)
    covariates: List[str] = field(default_factory=list)
    
    def __post_init__(self):
        """ê²€ì¦"""
        # ëª¨ë“  targetì´ first_order_lvsì— ì—†ëŠ”ì§€ í™•ì¸
        for path in self.hierarchical_paths:
            if path.target in self.first_order_lvs:
                raise ValueError(
                    f"Target '{path.target}'ëŠ” first_order_lvsì— ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # ëª¨ë“  predictorê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            all_lvs = self.first_order_lvs + [p.target for p in self.hierarchical_paths]
            for pred in path.predictors:
                if pred not in all_lvs:
                    raise ValueError(
                        f"Predictor '{pred}'ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                    )
    
    def get_all_latent_variables(self) -> List[str]:
        """ëª¨ë“  ì ì¬ë³€ìˆ˜ ë°˜í™˜"""
        return self.first_order_lvs + [p.target for p in self.hierarchical_paths]
    
    def get_n_parameters(self) -> int:
        """êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜"""
        n_params = 0
        for path in self.hierarchical_paths:
            n_params += len(path.predictors)  # gamma ê³„ìˆ˜
        return n_params
    
    def get_parameter_names(self) -> List[str]:
        """íŒŒë¼ë¯¸í„° ì´ë¦„ ë¦¬ìŠ¤íŠ¸"""
        names = []
        for path in self.hierarchical_paths:
            for pred in path.predictors:
                names.append(f'gamma_{pred}_to_{path.target}')
        return names
```

---

### Step 1.2: ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸ í´ë˜ìŠ¤ ìƒì„±

**íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/hierarchical_structural.py`

```python
"""
Hierarchical Structural Model
ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple
from scipy.stats import norm
import logging

from .hierarchical_config import HierarchicalStructuralConfig, HierarchicalPath

logger = logging.getLogger(__name__)


class HierarchicalStructural:
    """
    ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸
    
    êµ¬ì¡°:
    - 1ì°¨ LV: LV_i = Î·_i ~ N(0, 1)
    - 2ì°¨+ LV: LV_j = Î£(Î³_k * LV_k) + Î·_j
    
    Example:
        ê±´ê°•ê´€ì‹¬ë„ (1ì°¨) â†’ ê±´ê°•ìœ ìµì„± (2ì°¨) â†’ êµ¬ë§¤ì˜ë„ (3ì°¨)
    """
    
    def __init__(self, config: HierarchicalStructuralConfig):
        self.config = config
        self.first_order_lvs = config.first_order_lvs
        self.hierarchical_paths = config.hierarchical_paths
        self.covariates = config.covariates
        
        self.n_first_order = len(self.first_order_lvs)
        self.n_params = config.get_n_parameters()
        
        logger.info(f"HierarchicalStructural ì´ˆê¸°í™”")
        logger.info(f"  1ì°¨ LV ({self.n_first_order}ê°œ): {self.first_order_lvs}")
        logger.info(f"  ê³„ì¸µ ê²½ë¡œ ({len(self.hierarchical_paths)}ê°œ)")
        for path in self.hierarchical_paths:
            logger.info(f"    {path.predictors} â†’ {path.target}")
        logger.info(f"  ì´ íŒŒë¼ë¯¸í„°: {self.n_params}ê°œ")
    
    def predict(self, data: pd.DataFrame,
                first_order_draws: np.ndarray,
                params: Dict[str, float],
                higher_order_draws: Dict[str, float]) -> Dict[str, float]:
        """
        ê³„ì¸µì  ì ì¬ë³€ìˆ˜ ì˜ˆì¸¡
        
        Args:
            data: ê°œì¸ ë°ì´í„°
            first_order_draws: 1ì°¨ LV draws (n_first_order,)
            params: êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
                {
                    'gamma_health_concern_to_perceived_benefit': float,
                    'gamma_perceived_benefit_to_purchase_intention': float,
                    ...
                }
            higher_order_draws: 2ì°¨+ LV ì˜¤ì°¨í•­ draws
                {
                    'perceived_benefit': float,
                    'purchase_intention': float
                }
        
        Returns:
            ëª¨ë“  ì ì¬ë³€ìˆ˜ ê°’
        """
        latent_vars = {}
        
        # 1ì°¨ LV (ì™¸ìƒ)
        for i, lv_name in enumerate(self.first_order_lvs):
            latent_vars[lv_name] = first_order_draws[i]
        
        # 2ì°¨+ LV (ë‚´ìƒ) - ìˆœì„œëŒ€ë¡œ ê³„ì‚°
        for path in self.hierarchical_paths:
            # ì˜ˆì¸¡ê°’ ê³„ì‚°
            lv_mean = 0.0
            for pred in path.predictors:
                param_name = f'gamma_{pred}_to_{path.target}'
                gamma = params[param_name]
                lv_mean += gamma * latent_vars[pred]
            
            # ì˜¤ì°¨í•­ ì¶”ê°€
            error_draw = higher_order_draws[path.target]
            latent_vars[path.target] = (
                lv_mean + np.sqrt(path.error_variance) * error_draw
            )
        
        return latent_vars
    
    def log_likelihood(self, data: pd.DataFrame,
                      latent_vars: Dict[str, float],
                      first_order_draws: np.ndarray,
                      params: Dict[str, float],
                      higher_order_draws: Dict[str, float]) -> float:
        """
        ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸ ë¡œê·¸ìš°ë„
        
        LL = Î£ log P(LV_1st) + Î£ log P(LV_higher | LV_predictors)
        """
        ll = 0.0
        
        # 1ì°¨ LV: N(0, 1)
        for lv_name in self.first_order_lvs:
            ll += norm.logpdf(latent_vars[lv_name], loc=0, scale=1)
        
        # 2ì°¨+ LV: N(Î£(Î³ * LV_pred), ÏƒÂ²)
        for path in self.hierarchical_paths:
            # í‰ê·  ê³„ì‚°
            lv_mean = 0.0
            for pred in path.predictors:
                param_name = f'gamma_{pred}_to_{path.target}'
                gamma = params[param_name]
                lv_mean += gamma * latent_vars[pred]
            
            # ë¡œê·¸ìš°ë„
            ll += norm.logpdf(
                latent_vars[path.target],
                loc=lv_mean,
                scale=np.sqrt(path.error_variance)
            )
        
        return ll
    
    def initialize_parameters(self) -> Dict[str, float]:
        """íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”"""
        params = {}
        for path in self.hierarchical_paths:
            for pred in path.predictors:
                param_name = f'gamma_{pred}_to_{path.target}'
                params[param_name] = 0.0
        return params
    
    def get_parameter_names(self) -> List[str]:
        """íŒŒë¼ë¯¸í„° ì´ë¦„ ë¦¬ìŠ¤íŠ¸"""
        return self.config.get_parameter_names()
```

---

## ğŸ”§ Phase 2: ì¡°ì ˆíš¨ê³¼ êµ¬í˜„

### Step 2.1: ì¡°ì ˆíš¨ê³¼ í¬í•¨ ì„ íƒëª¨ë¸ í´ë˜ìŠ¤

**íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/choice_with_moderation.py`

```python
"""
Choice Model with Moderation Effects
ì¡°ì ˆíš¨ê³¼ê°€ í¬í•¨ëœ ì„ íƒëª¨ë¸
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional
from scipy.stats import norm
import logging

from .iclv_config import ChoiceConfig

logger = logging.getLogger(__name__)


class BinaryProbitChoiceWithModeration:
    """
    ì¡°ì ˆíš¨ê³¼ê°€ í¬í•¨ëœ Binary Probit ì„ íƒëª¨ë¸
    
    Model:
        V = intercept + Î²Â·X + Î»_mainÂ·LV_main + Î£(Î»_mod_i Â· LV_main Â· LV_mod_i)
        P(Yes) = Î¦(V)
    
    Example:
        V = intercept + Î²Â·X + Î»â‚Â·PI + Î»â‚‚Â·(PIÃ—PP) + Î»â‚ƒÂ·(PIÃ—NK)
        
        ì—¬ê¸°ì„œ:
        - PI: êµ¬ë§¤ì˜ë„ (ì£¼ ì ì¬ë³€ìˆ˜)
        - PP: ê°€ê²©ìˆ˜ì¤€ (ì¡°ì ˆë³€ìˆ˜ 1)
        - NK: ì˜ì–‘ì§€ì‹ (ì¡°ì ˆë³€ìˆ˜ 2)
    """
    
    def __init__(self, config: ChoiceConfig,
                 main_lv: str = 'purchase_intention',
                 moderator_lvs: Optional[List[str]] = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: ì„ íƒëª¨ë¸ ì„¤ì •
            main_lv: ì£¼ ì ì¬ë³€ìˆ˜ ì´ë¦„
            moderator_lvs: ì¡°ì ˆë³€ìˆ˜ ì ì¬ë³€ìˆ˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        self.config = config
        self.choice_attributes = config.choice_attributes
        self.price_variable = config.price_variable
        self.main_lv = main_lv
        self.moderator_lvs = moderator_lvs or []
        
        self.n_attributes = len(self.choice_attributes)
        self.n_moderators = len(self.moderator_lvs)
        
        logger.info(f"BinaryProbitChoiceWithModeration ì´ˆê¸°í™”")
        logger.info(f"  ì„ íƒ ì†ì„±: {self.choice_attributes}")
        logger.info(f"  ì£¼ ì ì¬ë³€ìˆ˜: {self.main_lv}")
        logger.info(f"  ì¡°ì ˆë³€ìˆ˜: {self.moderator_lvs}")
    
    def log_likelihood(self, data: pd.DataFrame,
                      latent_vars: Dict[str, float],
                      params: Dict) -> float:
        """
        ì¡°ì ˆíš¨ê³¼ í¬í•¨ ë¡œê·¸ìš°ë„
        
        Args:
            data: ì„ íƒ ë°ì´í„°
            latent_vars: ëª¨ë“  ì ì¬ë³€ìˆ˜ ê°’
            params: {
                'intercept': float,
                'beta': np.ndarray (n_attributes,),
                'lambda_main': float,
                'lambda_mod': np.ndarray (n_moderators,)
            }
        """
        intercept = params['intercept']
        beta = params['beta']
        lambda_main = params['lambda_main']
        lambda_mod = params.get('lambda_mod', np.zeros(self.n_moderators))
        
        # ì„ íƒ ì†ì„±
        X = data[self.choice_attributes].values
        choice = data['choice'].values
        
        # ì£¼ ì ì¬ë³€ìˆ˜
        lv_main = latent_vars[self.main_lv]
        
        # íš¨ìš© ê³„ì‚°
        V = intercept + X @ beta + lambda_main * lv_main
        
        # ì¡°ì ˆíš¨ê³¼ ì¶”ê°€
        for i, mod_lv_name in enumerate(self.moderator_lvs):
            lv_mod = latent_vars[mod_lv_name]
            V += lambda_mod[i] * (lv_main * lv_mod)
        
        # í™•ë¥  ë° ë¡œê·¸ìš°ë„
        prob_yes = norm.cdf(V)
        prob_yes = np.clip(prob_yes, 1e-10, 1 - 1e-10)
        
        ll = np.sum(
            choice * np.log(prob_yes) +
            (1 - choice) * np.log(1 - prob_yes)
        )
        
        return ll
    
    def get_n_parameters(self) -> int:
        """íŒŒë¼ë¯¸í„° ìˆ˜"""
        return 1 + self.n_attributes + 1 + self.n_moderators
    
    def initialize_parameters(self) -> Dict:
        """íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”"""
        params = {
            'intercept': 0.0,
            'beta': np.zeros(self.n_attributes),
            'lambda_main': 1.0,
            'lambda_mod': np.zeros(self.n_moderators)
        }
        
        # ê°€ê²© ë³€ìˆ˜ ìŒìˆ˜ ì´ˆê¸°í™”
        if self.price_variable in self.choice_attributes:
            price_idx = self.choice_attributes.index(self.price_variable)
            params['beta'][price_idx] = -1.0
        
        return params
```

---

## ğŸ“ Phase 3: í†µí•© ë° í…ŒìŠ¤íŠ¸

### Step 3.1: ì„¤ì • ì˜ˆì‹œ

```python
from src.analysis.hybrid_choice_model.iclv_models import (
    MeasurementConfig,
    ChoiceConfig,
    EstimationConfig
)
from src.analysis.hybrid_choice_model.iclv_models.hierarchical_config import (
    HierarchicalStructuralConfig,
    HierarchicalPath
)

# ì¸¡ì •ëª¨ë¸ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
measurement_configs = {
    'health_concern': MeasurementConfig(...),
    'perceived_benefit': MeasurementConfig(...),
    'perceived_price': MeasurementConfig(...),
    'nutrition_knowledge': MeasurementConfig(...),
    'purchase_intention': MeasurementConfig(...)
}

# ê³„ì¸µì  êµ¬ì¡°ëª¨ë¸ ì„¤ì • (NEW)
structural_config = HierarchicalStructuralConfig(
    first_order_lvs=['health_concern', 'perceived_price', 'nutrition_knowledge'],
    hierarchical_paths=[
        HierarchicalPath(
            target='perceived_benefit',
            predictors=['health_concern'],
            error_variance=1.0
        ),
        HierarchicalPath(
            target='purchase_intention',
            predictors=['perceived_benefit'],
            error_variance=1.0
        )
    ],
    covariates=[]  # ì‚¬íšŒì¸êµ¬í•™ì  ë³€ìˆ˜ ì œê±°
)

# ì„ íƒëª¨ë¸ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
choice_config = ChoiceConfig(
    choice_attributes=['sugar_free', 'health_label', 'price']
)
```

---

## âœ… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] HierarchicalStructuralConfig í´ë˜ìŠ¤ ìƒì„±
- [ ] HierarchicalStructural í´ë˜ìŠ¤ ìƒì„±
- [ ] BinaryProbitChoiceWithModeration í´ë˜ìŠ¤ ìƒì„±
- [ ] ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ íŒŒë¼ë¯¸í„° ë³µì› í…ŒìŠ¤íŠ¸
- [ ] ì‹¤ì œ ë°ì´í„°ë¡œ ìˆ˜ë ´ì„± í™•ì¸
- [ ] ê¸°ì¡´ ëª¨ë¸ê³¼ ì í•©ë„ ë¹„êµ (AIC, BIC)
- [ ] ê°„ì ‘íš¨ê³¼ ê³„ì‚° (ê±´ê°•ê´€ì‹¬ë„ â†’ ê±´ê°•ìœ ìµì„± â†’ êµ¬ë§¤ì˜ë„)
- [ ] ì¡°ì ˆíš¨ê³¼ í•´ì„ (Simple Slopes Analysis)

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### íŒŒë¼ë¯¸í„° ì¶”ì • ê²°ê³¼ ì˜ˆì‹œ

```
êµ¬ì¡°ëª¨ë¸:
  Î³â‚ (ê±´ê°•ê´€ì‹¬ë„ â†’ ê±´ê°•ìœ ìµì„±): 0.65 (SE=0.08, p<0.001)
  Î³â‚‚ (ê±´ê°•ìœ ìµì„± â†’ êµ¬ë§¤ì˜ë„): 0.72 (SE=0.09, p<0.001)

ì„ íƒëª¨ë¸:
  Î»â‚ (êµ¬ë§¤ì˜ë„ ì£¼íš¨ê³¼): 1.23 (SE=0.15, p<0.001)
  Î»â‚‚ (êµ¬ë§¤ì˜ë„ Ã— ê°€ê²©ìˆ˜ì¤€): -0.34 (SE=0.12, p<0.01)
  Î»â‚ƒ (êµ¬ë§¤ì˜ë„ Ã— ì˜ì–‘ì§€ì‹): 0.28 (SE=0.11, p<0.05)

ê°„ì ‘íš¨ê³¼:
  ê±´ê°•ê´€ì‹¬ë„ â†’ ê±´ê°•ìœ ìµì„± â†’ êµ¬ë§¤ì˜ë„: 0.47 (0.65 Ã— 0.72)
```

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **ì´ë¡ ì  íƒ€ë‹¹ì„± í™•ì¸**: ì—°êµ¬ ê°€ì„¤ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€í† 
2. **êµ¬í˜„ ì‹œì‘**: Phase 1ë¶€í„° ë‹¨ê³„ì  êµ¬í˜„
3. **í…ŒìŠ¤íŠ¸**: ì‹œë®¬ë ˆì´ì…˜ ë° ì‹¤ì œ ë°ì´í„° ê²€ì¦
4. **ê²°ê³¼ í•´ì„**: ê°„ì ‘íš¨ê³¼ ë° ì¡°ì ˆíš¨ê³¼ ë¶„ì„

