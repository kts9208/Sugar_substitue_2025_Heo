# GPU Analytic Gradient ë¬¸ì œì  ë¶„ì„

## ğŸ” Executive Summary

GPU Analytic Gradient êµ¬í˜„ì—ì„œ ë°œê²¬ëœ **7ê°€ì§€ ì£¼ìš” ë¬¸ì œì **:

| # | ë¬¸ì œ | ì‹¬ê°ë„ | ì˜í–¥ | ìƒíƒœ |
|---|------|--------|------|------|
| 1 | **Importance Weighting ëˆ„ë½** | ğŸ”´ Critical | NaN, ì˜ëª»ëœ ê·¸ë˜ë””ì–¸íŠ¸ | ë¯¸êµ¬í˜„ |
| 2 | **ì¸¡ì •ëª¨ë¸: ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©** | ğŸ”´ Critical | ëŒ€ë¶€ë¶„ ë°ì´í„° ë¬´ì‹œ | ë²„ê·¸ |
| 3 | **ë‹¨ìˆœ í•©ì‚° (ê°€ì¤‘í‰ê·  ì•„ë‹˜)** | ğŸ”´ Critical | ìˆ˜í•™ì  ì˜¤ë¥˜ | ë²„ê·¸ |
| 4 | **êµ¬ì¡°ëª¨ë¸: ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©** | ğŸŸ¡ Major | ê³µë³€ëŸ‰ ì •ë³´ ì†ì‹¤ | ë²„ê·¸ |
| 5 | **ì„ íƒëª¨ë¸: ìˆœì°¨ ì²˜ë¦¬** | ğŸŸ¡ Major | GPU ë¯¸í™œìš© | ë¹„íš¨ìœ¨ |
| 6 | **Likelihood ê³„ì‚° ëˆ„ë½** | ğŸ”´ Critical | Weighting ë¶ˆê°€ëŠ¥ | ë¯¸êµ¬í˜„ |
| 7 | **ìˆ˜ì¹˜ ì•ˆì •ì„± ë¶€ì¡±** | ğŸŸ¡ Major | NaN ë°œìƒ ê°€ëŠ¥ | ë¶€ë¶„ êµ¬í˜„ |

**ê²°ë¡ **: í˜„ì¬ êµ¬í˜„ì€ **ìˆ˜í•™ì ìœ¼ë¡œ ì˜ëª»ë˜ì—ˆìœ¼ë©°**, ìˆ˜ì • ì—†ì´ëŠ” ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ğŸ“‹ ë¬¸ì œì  ìƒì„¸ ë¶„ì„

### ë¬¸ì œ 1: Importance Weighting ëˆ„ë½ ğŸ”´

#### í˜„ì¬ êµ¬í˜„ (GPU)

```python
# gpu_gradient_batch.py, Line 126-127
grad_zeta = cp.asnumpy(grad_zeta_batch.sum(axis=0))  # âŒ ë‹¨ìˆœ í•©ì‚°
grad_tau = cp.asnumpy(grad_tau_batch.sum(axis=0))    # âŒ ë‹¨ìˆœ í•©ì‚°
```

#### ì˜¬ë°”ë¥¸ êµ¬í˜„ (CPU)

```python
# multi_latent_gradient.py, Line 379-384
# Importance weights ê³„ì‚°
total_likelihood = sum(draw_likelihoods)
weights = np.array(draw_likelihoods) / total_likelihood

# ê°€ì¤‘í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
for w, grad in zip(weights, draw_gradients):
    weighted_meas[lv_name]['grad_zeta'] += w * grad['measurement'][lv_name]['grad_zeta']
```

#### ë¬¸ì œì 

**GPU ë²„ì „ì€ ëª¨ë“  drawsì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë‹¨ìˆœ í•©ì‚°í•©ë‹ˆë‹¤:**
```
grad_GPU = Î£áµ¢ grad_i  # âŒ ì˜ëª»ë¨
```

**ì˜¬ë°”ë¥¸ ë°©ë²•ì€ importance weightingì…ë‹ˆë‹¤:**
```
grad_correct = Î£áµ¢ wáµ¢ Â· grad_i  # âœ… ì˜¬ë°”ë¦„
where wáµ¢ = L_i / Î£â±¼ L_j
```

#### ì˜í–¥

1. **ìˆ˜í•™ì  ì˜¤ë¥˜**: ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì¶”ì •ì˜ í•µì‹¬ ì›ë¦¬ ìœ„ë°˜
2. **í¸í–¥ëœ ê·¸ë˜ë””ì–¸íŠ¸**: ìš°ë„ê°€ ë‚®ì€ drawsë„ ë™ì¼í•œ ê°€ì¤‘ì¹˜
3. **NaN ë°œìƒ**: ê·¹ë‹¨ì ì¸ ê·¸ë˜ë””ì–¸íŠ¸ ê°’ ëˆ„ì 
4. **ìˆ˜ë ´ ì‹¤íŒ¨**: BFGSê°€ ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ ì´ë™

#### ìˆ˜ì • ë°©ë²•

```python
# 1. ê° drawì˜ likelihood ê³„ì‚°
ll_batch = compute_likelihood_batch_gpu(ind_data, lvs_list, params)  # (n_draws,)

# 2. Importance weights ê³„ì‚°
weights = cp.exp(ll_batch) / cp.sum(cp.exp(ll_batch))  # (n_draws,)

# 3. ê°€ì¤‘í‰ê· 
grad_zeta = cp.asnumpy(cp.sum(weights[:, None] * grad_zeta_batch, axis=0))
grad_tau = cp.asnumpy(cp.sum(weights[:, None, None] * grad_tau_batch, axis=0))
```

---

### ë¬¸ì œ 2: ì¸¡ì •ëª¨ë¸ - ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš© ğŸ”´

#### í˜„ì¬ êµ¬í˜„

```python
# gpu_gradient_batch.py, Line 74
first_row = ind_data.iloc[0]  # âŒ ì²« ë²ˆì§¸ í–‰ë§Œ

for i, indicator in enumerate(config.indicators):
    if indicator not in first_row.index:  # âŒ ì²« ë²ˆì§¸ í–‰ì—ì„œë§Œ í™•ì¸
        continue
    
    y = first_row[indicator]  # âŒ ì²« ë²ˆì§¸ í–‰ì˜ ê°’ë§Œ
```

#### ì˜¬ë°”ë¥¸ êµ¬í˜„ (CPU)

```python
# multi_latent_gradient.py, Line 101-130
for idx in range(len(data)):  # âœ… ëª¨ë“  í–‰ ìˆœíšŒ
    row = data.iloc[idx]
    
    for i, indicator in enumerate(indicators):
        if indicator not in row.index:
            continue
        
        y = row[indicator]  # âœ… ê° í–‰ì˜ ê°’
```

#### ë¬¸ì œì 

**ê°œì¸ì˜ ì„ íƒ ìƒí™©ì´ 18ê°œì¸ë°, ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©:**
```
ê°œì¸ ë°ì´í„°:
  Row 0: q1=3, q2=4, q3=2, ...  âœ… ì‚¬ìš©ë¨
  Row 1: q1=4, q2=3, q3=5, ...  âŒ ë¬´ì‹œë¨
  Row 2: q1=2, q2=5, q3=3, ...  âŒ ë¬´ì‹œë¨
  ...
  Row 17: q1=5, q2=2, q3=4, ... âŒ ë¬´ì‹œë¨

â†’ 94.4% (17/18) ë°ì´í„° ì†ì‹¤!
```

#### ì˜í–¥

1. **ì •ë³´ ì†ì‹¤**: ëŒ€ë¶€ë¶„ì˜ ì¸¡ì • ë°ì´í„° ë¬´ì‹œ
2. **í¸í–¥ëœ ì¶”ì •**: ì²« ë²ˆì§¸ ì„ íƒ ìƒí™©ì—ë§Œ ì˜ì¡´
3. **ì˜ëª»ëœ ê·¸ë˜ë””ì–¸íŠ¸**: ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ì˜¤ë¥˜
4. **ìˆ˜ë ´ ë¶ˆê°€ëŠ¥**: ì˜ëª»ëœ ì •ë³´ë¡œ ìµœì í™”

#### ìˆ˜ì • ë°©ë²•

```python
# ëª¨ë“  ì„ íƒ ìƒí™©ì— ëŒ€í•´ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
for idx in range(len(ind_data)):
    row = ind_data.iloc[idx]
    
    for i, indicator in enumerate(config.indicators):
        if indicator not in row.index:
            continue
        
        y = row[indicator]
        if pd.isna(y):
            continue
        
        # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° (í˜„ì¬ ì½”ë“œì™€ ë™ì¼)
        ...
```

---

### ë¬¸ì œ 3: ë‹¨ìˆœ í•©ì‚° (ê°€ì¤‘í‰ê·  ì•„ë‹˜) ğŸ”´

#### í˜„ì¬ êµ¬í˜„

```python
# gpu_gradient_batch.py
# ì¸¡ì •ëª¨ë¸ (Line 126-127)
grad_zeta = cp.asnumpy(grad_zeta_batch.sum(axis=0))  # âŒ sum
grad_tau = cp.asnumpy(grad_tau_batch.sum(axis=0))    # âŒ sum

# êµ¬ì¡°ëª¨ë¸ (Line 195-198)
grad_gamma_lv = cp.dot(exo_lv_gpu.T, residual) / error_variance  # âŒ dot (sum)
grad_gamma_x = residual.sum() / error_variance * X_gpu           # âŒ sum

# ì„ íƒëª¨ë¸ (Line 297-303)
grad_intercept_total += cp.sum(sign * mills).item()  # âŒ sum
grad_beta_total += cp.dot(attr_gpu.T, sign * mills)  # âŒ sum
grad_lambda_total += cp.sum(sign * mills * lv).item()  # âŒ sum
```

#### ì˜¬ë°”ë¥¸ êµ¬í˜„ (CPU)

```python
# multi_latent_gradient.py, Line 421-434
for w, grad in zip(weights, draw_gradients):  # âœ… ê°€ì¤‘ì¹˜ ì‚¬ìš©
    # ì¸¡ì •ëª¨ë¸
    weighted_meas[lv_name]['grad_zeta'] += w * grad['measurement'][lv_name]['grad_zeta']
    weighted_meas[lv_name]['grad_tau'] += w * grad['measurement'][lv_name]['grad_tau']
    
    # êµ¬ì¡°ëª¨ë¸
    weighted_struct['grad_gamma_lv'] += w * grad['structural']['grad_gamma_lv']
    weighted_struct['grad_gamma_x'] += w * grad['structural']['grad_gamma_x']
    
    # ì„ íƒëª¨ë¸
    weighted_choice['grad_intercept'] += w * grad['choice']['grad_intercept']
    weighted_choice['grad_beta'] += w * grad['choice']['grad_beta']
    weighted_choice['grad_lambda'] += w * grad['choice']['grad_lambda']
```

#### ë¬¸ì œì 

**ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì¶”ì •ì˜ í•µì‹¬ ì›ë¦¬:**

```
E[âˆ‡ log L] = âˆ« âˆ‡ log L(Î¸|Î·) Â· f(Î·) dÎ·
           â‰ˆ (1/R) Î£áµ£ âˆ‡ log L(Î¸|Î·áµ£)  # âŒ ë‹¨ìˆœ í‰ê·  (Monte Carlo)
           â‰ˆ Î£áµ£ wáµ£ Â· âˆ‡ log L(Î¸|Î·áµ£)   # âœ… ê°€ì¤‘í‰ê·  (Importance Sampling)

where wáµ£ = L(Î¸|Î·áµ£) / Î£â‚› L(Î¸|Î·â‚›)
```

**GPU ë²„ì „ì€ ê°€ì¤‘ì¹˜ ì—†ì´ í•©ì‚°:**
```
grad_GPU = Î£áµ£ grad_r  # âŒ ì˜ëª»ë¨
```

**ì˜¬ë°”ë¥¸ ë°©ë²•:**
```
grad_correct = Î£áµ£ wáµ£ Â· grad_r  # âœ… ì˜¬ë°”ë¦„
```

#### ì˜í–¥

1. **ì´ë¡ ì  ì˜¤ë¥˜**: Importance sampling ì›ë¦¬ ìœ„ë°˜
2. **í¸í–¥ëœ ì¶”ì •**: ëª¨ë“  drawsë¥¼ ë™ë“±í•˜ê²Œ ì·¨ê¸‰
3. **ë¹„íš¨ìœ¨ì **: ìš°ë„ê°€ ë‚®ì€ drawsë„ ë™ì¼í•œ ì˜í–¥
4. **ìˆ˜ë ´ ë¬¸ì œ**: ì˜ëª»ëœ ê·¸ë˜ë””ì–¸íŠ¸ ë°©í–¥

---

### ë¬¸ì œ 4: êµ¬ì¡°ëª¨ë¸ - ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš© ğŸŸ¡

#### í˜„ì¬ êµ¬í˜„

```python
# gpu_gradient_batch.py, Line 178-179
first_row = ind_data.iloc[0]  # âŒ ì²« ë²ˆì§¸ í–‰ë§Œ
X = np.array([first_row[cov] if cov in first_row.index else 0.0 for cov in covariates])
```

#### ë¬¸ì œì 

**ê³µë³€ëŸ‰ì€ ê°œì¸ë³„ë¡œ ë™ì¼í•˜ë¯€ë¡œ í° ë¬¸ì œëŠ” ì•„ë‹ˆì§€ë§Œ:**
- ì²« ë²ˆì§¸ í–‰ì— ê³µë³€ëŸ‰ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬
- ë‹¤ë¥¸ í–‰ì— ê³µë³€ëŸ‰ì´ ìˆì–´ë„ ë¬´ì‹œ

#### ì˜í–¥

- **ì¤‘ê°„ ìˆ˜ì¤€**: ê³µë³€ëŸ‰ì€ ë³´í†µ ëª¨ë“  í–‰ì— ë™ì¼í•˜ê²Œ ì¡´ì¬
- **ì ì¬ì  ë²„ê·¸**: ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥

#### ìˆ˜ì • ë°©ë²•

```python
# ê°œì¸ ìˆ˜ì¤€ ê³µë³€ëŸ‰ ì¶”ì¶œ (ì²« ë²ˆì§¸ í–‰ ì‚¬ìš©ì€ OK, í•˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ)
# ë˜ëŠ” ind_dataì—ì„œ ê°œì¸ IDë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì¶”ì¶œ
person_data = ind_data.groupby('person_id').first()  # ë” ì•ˆì „
X = np.array([person_data[cov] for cov in covariates])
```

---

### ë¬¸ì œ 5: ì„ íƒëª¨ë¸ - ìˆœì°¨ ì²˜ë¦¬ ğŸŸ¡

#### í˜„ì¬ êµ¬í˜„

```python
# gpu_gradient_batch.py, Line 275-303
for draw_idx in range(n_draws):  # âŒ ìˆœì°¨ ì²˜ë¦¬
    lv = lv_gpu[draw_idx]
    
    V = intercept + cp.dot(attr_gpu, beta_gpu) + lambda_lv * lv
    prob = cp_ndtr(V)
    phi = cp_norm_pdf(V)
    
    # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì 
    grad_intercept_total += cp.sum(sign * mills).item()
    grad_beta_total += cp.dot(attr_gpu.T, sign * mills)
    grad_lambda_total += cp.sum(sign * mills * lv).item()
```

#### ë¬¸ì œì 

**GPUì˜ ì¥ì ì„ í™œìš©í•˜ì§€ ëª»í•¨:**
- 100ê°œ drawsë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- GPU ë³‘ë ¬ ì²˜ë¦¬ ë¯¸í™œìš©

#### ì˜¬ë°”ë¥¸ êµ¬í˜„ (ë°°ì¹˜)

```python
# ëª¨ë“  drawsë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
lv_batch = lv_gpu[:, None]  # (n_draws, 1)
attr_batch = attr_gpu[None, :, :]  # (1, n_situations, n_attributes)

# Broadcastingìœ¼ë¡œ ëª¨ë“  draws ë™ì‹œ ê³„ì‚°
V_batch = intercept + cp.dot(attr_batch, beta_gpu) + lambda_lv * lv_batch
# Shape: (n_draws, n_situations)

prob_batch = cp_ndtr(V_batch)
phi_batch = cp_norm_pdf(V_batch)

# ë°°ì¹˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
mills_batch = phi_batch / prob_batch
grad_intercept_batch = cp.sum(sign * mills_batch, axis=1)  # (n_draws,)
grad_beta_batch = cp.dot(mills_batch.T, attr_gpu)  # (n_draws, n_attributes)
grad_lambda_batch = cp.sum(sign * mills_batch * lv_batch, axis=1)  # (n_draws,)

# Importance weighting ì ìš©
grad_intercept = cp.sum(weights * grad_intercept_batch)
grad_beta = cp.dot(weights, grad_beta_batch)
grad_lambda = cp.sum(weights * grad_lambda_batch)
```

#### ì˜í–¥

- **ì„±ëŠ¥ ì €í•˜**: GPU ë³‘ë ¬ ì²˜ë¦¬ ë¯¸í™œìš©
- **ì†ë„**: í˜„ì¬ êµ¬í˜„ë„ ëŠë¦¼ (ìˆœì°¨ ì²˜ë¦¬)

---

### ë¬¸ì œ 6: Likelihood ê³„ì‚° ëˆ„ë½ ğŸ”´

#### í˜„ì¬ êµ¬í˜„

```python
# gpu_gradient_batch.py
# Likelihood ê³„ì‚° ì½”ë“œ ì—†ìŒ!
# Importance weightsë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŒ
```

#### í•„ìš”í•œ êµ¬í˜„

```python
def compute_likelihood_batch_gpu(
    ind_data: pd.DataFrame,
    lvs_list: List[Dict[str, float]],
    params: Dict
) -> cp.ndarray:
    """
    ê° drawì˜ likelihood ê³„ì‚° (importance weightingìš©)
    
    Returns:
        (n_draws,) array of log-likelihoods
    """
    n_draws = len(lvs_list)
    ll_batch = cp.zeros(n_draws)
    
    for draw_idx in range(n_draws):
        lv = lvs_list[draw_idx]
        
        # ì¸¡ì •ëª¨ë¸ ìš°ë„
        ll_meas = compute_measurement_ll_gpu(ind_data, lv, params['measurement'])
        
        # êµ¬ì¡°ëª¨ë¸ ìš°ë„
        ll_struct = compute_structural_ll_gpu(ind_data, lv, params['structural'])
        
        # ì„ íƒëª¨ë¸ ìš°ë„
        ll_choice = compute_choice_ll_gpu(ind_data, lv, params['choice'])
        
        # ê²°í•© ìš°ë„
        ll_batch[draw_idx] = ll_meas + ll_struct + ll_choice
    
    return ll_batch
```

#### ì˜í–¥

1. **Importance weighting ë¶ˆê°€ëŠ¥**: ê°€ì¤‘ì¹˜ ê³„ì‚° ë¶ˆê°€
2. **ë‹¨ìˆœ í•©ì‚°ë§Œ ê°€ëŠ¥**: ìˆ˜í•™ì ìœ¼ë¡œ ì˜ëª»ëœ ë°©ë²•
3. **NaN ë°œìƒ**: ê·¹ë‹¨ì ì¸ ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì 

---

### ë¬¸ì œ 7: ìˆ˜ì¹˜ ì•ˆì •ì„± ë¶€ì¡± ğŸŸ¡

#### í˜„ì¬ êµ¬í˜„

```python
# gpu_gradient_batch.py
# ì¼ë¶€ë§Œ êµ¬í˜„ë¨

# ì¸¡ì •ëª¨ë¸ (Line 111)
prob = cp.clip(prob, 1e-10, 1 - 1e-10)  # âœ… êµ¬í˜„ë¨

# ì„ íƒëª¨ë¸ (Line 283)
prob = cp.clip(prob, 1e-10, 1 - 1e-10)  # âœ… êµ¬í˜„ë¨

# í•˜ì§€ë§Œ:
# - log-likelihood ê³„ì‚° ì‹œ log(0) ë°©ì§€ ì—†ìŒ
# - exp overflow/underflow ë°©ì§€ ì—†ìŒ
# - NaN ì²´í¬ ì—†ìŒ
```

#### í•„ìš”í•œ ê°œì„ 

```python
# 1. Log-sum-exp trick for importance weights
def log_sum_exp(log_values):
    max_val = cp.max(log_values)
    return max_val + cp.log(cp.sum(cp.exp(log_values - max_val)))

ll_batch = compute_likelihood_batch_gpu(...)
log_weights = ll_batch - log_sum_exp(ll_batch)
weights = cp.exp(log_weights)

# 2. NaN ì²´í¬
if cp.any(cp.isnan(grad_zeta)):
    logger.warning("NaN detected in grad_zeta")
    grad_zeta = cp.nan_to_num(grad_zeta, nan=0.0)

# 3. Gradient clipping
grad_zeta = cp.clip(grad_zeta, -1e6, 1e6)
```

---

## ğŸ“Š ë¬¸ì œì  ìš”ì•½í‘œ

| ë¬¸ì œ | CPU êµ¬í˜„ | GPU êµ¬í˜„ | ì°¨ì´ì  |
|------|---------|---------|--------|
| **Importance weighting** | âœ… êµ¬í˜„ë¨ | âŒ ëˆ„ë½ | GPUëŠ” ë‹¨ìˆœ í•©ì‚° |
| **ì¸¡ì •ëª¨ë¸ ë°ì´í„°** | âœ… ëª¨ë“  í–‰ | âŒ ì²« í–‰ë§Œ | 94% ë°ì´í„° ì†ì‹¤ |
| **ê°€ì¤‘í‰ê· ** | âœ… ê°€ì¤‘í‰ê·  | âŒ ë‹¨ìˆœ í•©ì‚° | ìˆ˜í•™ì  ì˜¤ë¥˜ |
| **êµ¬ì¡°ëª¨ë¸ ê³µë³€ëŸ‰** | âœ… ì˜¬ë°”ë¦„ | âš ï¸ ì²« í–‰ë§Œ | ì ì¬ì  ë²„ê·¸ |
| **ì„ íƒëª¨ë¸ ë°°ì¹˜** | âŒ ìˆœì°¨ | âŒ ìˆœì°¨ | ë‘˜ ë‹¤ ë¹„íš¨ìœ¨ |
| **Likelihood ê³„ì‚°** | âœ… êµ¬í˜„ë¨ | âŒ ëˆ„ë½ | Weighting ë¶ˆê°€ |
| **ìˆ˜ì¹˜ ì•ˆì •ì„±** | âœ… ì™„ì „ | âš ï¸ ë¶€ë¶„ | NaN ìœ„í—˜ |

---

## ğŸ”§ ìˆ˜ì • ìš°ì„ ìˆœìœ„

### Priority 1 (Critical) - ì¦‰ì‹œ ìˆ˜ì • í•„ìš”

1. **Importance weighting êµ¬í˜„**
   - Likelihood ê³„ì‚° í•¨ìˆ˜ ì¶”ê°€
   - Weights ê³„ì‚° ë° ì ìš©
   - ì˜ˆìƒ ì‘ì—…: 2-3ì‹œê°„

2. **ì¸¡ì •ëª¨ë¸ ëª¨ë“  í–‰ ì²˜ë¦¬**
   - Loop ì¶”ê°€í•˜ì—¬ ëª¨ë“  ì„ íƒ ìƒí™© ì²˜ë¦¬
   - ì˜ˆìƒ ì‘ì—…: 1ì‹œê°„

3. **ê°€ì¤‘í‰ê· ìœ¼ë¡œ ë³€ê²½**
   - ëª¨ë“  sumì„ weighted sumìœ¼ë¡œ ë³€ê²½
   - ì˜ˆìƒ ì‘ì—…: 1ì‹œê°„

### Priority 2 (Major) - ì„±ëŠ¥ ê°œì„ 

4. **ì„ íƒëª¨ë¸ ë°°ì¹˜ ì²˜ë¦¬**
   - For loop ì œê±°, broadcasting ì‚¬ìš©
   - ì˜ˆìƒ ì‘ì—…: 2ì‹œê°„

5. **ìˆ˜ì¹˜ ì•ˆì •ì„± ê°•í™”**
   - Log-sum-exp trick
   - NaN ì²´í¬ ë° ì²˜ë¦¬
   - Gradient clipping
   - ì˜ˆìƒ ì‘ì—…: 1-2ì‹œê°„

### Priority 3 (Minor) - ì½”ë“œ í’ˆì§ˆ

6. **êµ¬ì¡°ëª¨ë¸ ê³µë³€ëŸ‰ ì¶”ì¶œ ê°œì„ **
   - ë” ì•ˆì „í•œ ë°©ë²• ì‚¬ìš©
   - ì˜ˆìƒ ì‘ì—…: 30ë¶„

---

## ğŸ“ˆ ìˆ˜ì • í›„ ì˜ˆìƒ ì„±ëŠ¥

| í•­ëª© | í˜„ì¬ (ë²„ê·¸) | ìˆ˜ì • í›„ |
|------|------------|---------|
| **ì •í™•ë„** | âŒ ì˜ëª»ë¨ | âœ… ì˜¬ë°”ë¦„ |
| **ì†ë„** | NaN ì—ëŸ¬ | ~22ì´ˆ/ê·¸ë˜ë””ì–¸íŠ¸ |
| **ì•ˆì •ì„±** | âŒ ë¶ˆì•ˆì • | âœ… ì•ˆì •ì  |
| **ìˆ˜ë ´** | âŒ ì‹¤íŒ¨ | âœ… ì„±ê³µ ì˜ˆìƒ |

---

## ğŸ’¡ ê²°ë¡ 

**í˜„ì¬ GPU Analytic Gradient êµ¬í˜„ì€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.**

**ì£¼ìš” ì´ìœ :**
1. Importance weighting ëˆ„ë½ â†’ ìˆ˜í•™ì  ì˜¤ë¥˜
2. ëŒ€ë¶€ë¶„ ë°ì´í„° ë¬´ì‹œ â†’ ì •ë³´ ì†ì‹¤
3. ë‹¨ìˆœ í•©ì‚° â†’ ì´ë¡ ì  ì˜¤ë¥˜

**ìˆ˜ì • ì˜ˆìƒ ì‹œê°„:** 8-12ì‹œê°„

**ìˆ˜ì • í›„ ì´ë“:** 77ë¶„ â†’ 22ì´ˆ (210ë°° í–¥ìƒ)

**ê¶Œì¥ì‚¬í•­:**
- ë‹¨ê¸°: Numerical gradient ì‚¬ìš© (ì•ˆì •ì )
- ì¤‘ê¸°: GPU gradient ìˆ˜ì • (1-2ì£¼)
- ì¥ê¸°: í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼

