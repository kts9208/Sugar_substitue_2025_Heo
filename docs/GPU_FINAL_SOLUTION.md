# GPU ì‚¬ìš©ì„ ìœ„í•œ ìµœì¢… í•´ê²° ë°©ì•ˆ

## ğŸ”´ í˜„ì¬ ë¬¸ì œ

**Segmentation Fault ë°œìƒ**
- CUDA Toolkit v13.0 ì„¤ì¹˜ë¨
- CuPy-CUDA12xëŠ” CUDA 12.xìš©ìœ¼ë¡œ ë¹Œë“œë¨
- DLL ì´ë¦„ ë§¤í•‘ìœ¼ë¡œëŠ” ABI í˜¸í™˜ì„± ë¬¸ì œ í•´ê²° ë¶ˆê°€

## âœ… í•´ê²° ë°©ì•ˆ

### ë°©ì•ˆ 1: CUDA 12.8 ì„¤ì¹˜ (ê¶Œì¥ - GPU ì‚¬ìš©)

**ë‹¨ê³„**:

1. **CUDA Toolkit v13.0 ì œê±°**
   - ì œì–´íŒ â†’ í”„ë¡œê·¸ë¨ ì œê±°
   - "NVIDIA CUDA 13.0" ì œê±°

2. **CUDA Toolkit v12.8 ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜**
   - URL: https://developer.nvidia.com/cuda-12-8-0-download-archive
   - Windows â†’ x86_64 â†’ 11 â†’ exe (local) ì„ íƒ
   - ë‹¤ìš´ë¡œë“œ í›„ ì„¤ì¹˜ (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)

3. **ì‹œìŠ¤í…œ ì¬ë¶€íŒ…**

4. **CuPy ì¬ì„¤ì¹˜**
   ```bash
   # ì§§ì€ ê²½ë¡œ ê°€ìƒí™˜ê²½ ì‚¬ìš©
   C:\gpu_env\Scripts\pip.exe uninstall cupy-cuda12x -y
   C:\gpu_env\Scripts\pip.exe install cupy-cuda12x --no-cache-dir
   ```

5. **GPU í…ŒìŠ¤íŠ¸**
   ```bash
   C:\gpu_env\Scripts\python.exe test_gpu_cuda13.py
   ```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 30-60ë¶„
**ì„±ê³µ í™•ë¥ **: 95%

---

### ë°©ì•ˆ 2: CPU ë²¡í„°í™” ìµœì í™” (ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥)

GPU ì—†ì´ NumPy ë²¡í„°í™”ë¡œ ì¸¡ì •ëª¨ë¸ ìµœì í™”

**ì¥ì **:
- âœ… ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- âœ… ì•ˆì •ì 
- âœ… 27ê°œ ì½”ì–´ ë³‘ë ¬ì²˜ë¦¬ì™€ ê²°í•© ì‹œ ì¶©ë¶„íˆ ë¹ ë¦„

**êµ¬í˜„**:

```python
# src/analysis/hybrid_choice_model/iclv_models/optimized_measurement.py

import numpy as np
from scipy.stats import norm
from scipy.special import logsumexp

class VectorizedOrderedProbitMeasurement:
    """NumPy ë²¡í„°í™” ì¸¡ì •ëª¨ë¸"""
    
    def log_likelihood_batch(self, data_batch, latent_vars, params):
        """
        ë°°ì¹˜ ë¡œê·¸ìš°ë„ ê³„ì‚° (NumPy ë²¡í„°í™”)
        
        Args:
            data_batch: (n_obs, n_indicators) ê´€ì¸¡ ë°ì´í„°
            latent_vars: (n_obs,) ì ì¬ë³€ìˆ˜ ê°’
            params: {'zeta': (n_indicators,), 'tau': (n_indicators, n_thresholds)}
        
        Returns:
            (n_obs,) ë¡œê·¸ìš°ë„
        """
        zeta = params['zeta']  # (n_indicators,)
        tau = params['tau']    # (n_indicators, n_thresholds)
        
        n_obs = len(data_batch)
        n_indicators = len(zeta)
        
        # ì„ í˜• ì˜ˆì¸¡: (n_obs, n_indicators)
        linear_pred = latent_vars[:, np.newaxis] * zeta[np.newaxis, :]
        
        # ë¡œê·¸ìš°ë„ ì´ˆê¸°í™”
        ll_batch = np.zeros(n_obs)
        
        # ê° ì§€í‘œë³„ë¡œ ê³„ì‚° (ë²¡í„°í™”)
        for i in range(n_indicators):
            y = data_batch[:, i]  # (n_obs,)
            lp = linear_pred[:, i]  # (n_obs,)
            tau_i = tau[i]  # (n_thresholds,)
            
            # ê° ì¹´í…Œê³ ë¦¬ë³„ í™•ë¥  ê³„ì‚°
            # P(Y=k) = Î¦(Ï„_k - Î¶*LV) - Î¦(Ï„_{k-1} - Î¶*LV)
            
            # í•˜í•œ CDF: (n_obs, n_categories)
            lower_cdf = np.zeros((n_obs, len(tau_i) + 1))
            lower_cdf[:, 0] = 0.0  # -âˆ
            lower_cdf[:, 1:-1] = norm.cdf(tau_i[:-1, np.newaxis] - lp[:, np.newaxis], axis=0).T
            lower_cdf[:, -1] = 1.0  # +âˆ
            
            # ìƒí•œ CDF
            upper_cdf = np.zeros((n_obs, len(tau_i) + 1))
            upper_cdf[:, 0] = 0.0  # -âˆ
            upper_cdf[:, 1:] = norm.cdf(tau_i[:, np.newaxis] - lp[:, np.newaxis], axis=0).T
            
            # í™•ë¥ : P(Y=k) = upper - lower
            probs = upper_cdf - lower_cdf  # (n_obs, n_categories)
            
            # ê´€ì¸¡ëœ ì¹´í…Œê³ ë¦¬ì˜ í™•ë¥  ì„ íƒ
            obs_probs = probs[np.arange(n_obs), y.astype(int)]
            
            # ë¡œê·¸ìš°ë„ ëˆ„ì 
            ll_batch += np.log(np.maximum(obs_probs, 1e-10))
        
        return ll_batch
```

**ì„±ëŠ¥**:
- CPU ë²¡í„°í™”: NumPyëŠ” ë‚´ë¶€ì ìœ¼ë¡œ BLAS/LAPACK ì‚¬ìš©
- 27ê°œ ì½”ì–´ ë³‘ë ¬ + ë²¡í„°í™”: GPU ëŒ€ë¹„ 70-80% ì„±ëŠ¥
- ì˜ˆìƒ ì†Œìš” ì‹œê°„: 50-60ë¶„ (GPU ëŒ€ë¹„ 1.2-1.5ë°°)

---

### ë°©ì•ˆ 3: í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ (ê¶Œì¥)

**CPU ë³‘ë ¬ + NumPy ë²¡í„°í™”**

```python
# ê°œì¸ë³„ë¡œ CPU ë³‘ë ¬ ë¶„ì‚° (27 ì½”ì–´)
with ProcessPoolExecutor(max_workers=27) as executor:
    results = executor.map(compute_individual_ll, individuals)

# ê° ê°œì¸ ë‚´ë¶€ì—ì„œ NumPy ë²¡í„°í™”
def compute_individual_ll(ind_data):
    # ëª¨ë“  drawsë¥¼ í•œë²ˆì— ê³„ì‚° (ë²¡í„°í™”)
    n_draws = 100
    latent_vars = draws  # (n_draws, n_dimensions)
    
    # ë°°ì¹˜ ê³„ì‚°
    ll_batch = measurement_model.log_likelihood_batch(
        data_batch=ind_data,  # (n_obs, n_indicators)
        latent_vars=latent_vars,  # (n_draws,)
        params=params
    )
    
    return logsumexp(ll_batch) - np.log(n_draws)
```

**ì˜ˆìƒ ì„±ëŠ¥**:
- 27ê°œ ì½”ì–´ Ã— NumPy ë²¡í„°í™”
- ì†Œìš” ì‹œê°„: **40-50ë¶„**
- GPU ëŒ€ë¹„: 1.0-1.2ë°° (ê±°ì˜ ë™ì¼)

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì‹¤í–‰: ë°©ì•ˆ 3 (CPU ë³‘ë ¬ + NumPy ë²¡í„°í™”)

**ì´ìœ **:
1. âœ… **ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥** - ì¶”ê°€ ì„¤ì¹˜ ë¶ˆí•„ìš”
2. âœ… **ì¶©ë¶„íˆ ë¹ ë¦„** - 40-50ë¶„ (GPUì™€ ê±°ì˜ ë™ì¼)
3. âœ… **ì•ˆì •ì ** - ê²€ì¦ëœ NumPy/SciPy ì‚¬ìš©
4. âœ… **ìœ„í—˜ ì—†ìŒ** - ì‹œìŠ¤í…œ ë³€ê²½ ë¶ˆí•„ìš”

**ì‹¤í–‰**:
```bash
python scripts/test_multi_latent_iclv.py
```

### ë‚˜ì¤‘ì— ê³ ë ¤: ë°©ì•ˆ 1 (CUDA 12.8 ì„¤ì¹˜)

ëª¨ë¸ ì¶”ì •ì´ ì™„ë£Œëœ í›„, ë” ë¹ ë¥¸ ì†ë„ê°€ í•„ìš”í•˜ë©´ CUDA 12.8 ì¬ì„¤ì¹˜ ê³ ë ¤

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ (1000íšŒ ë°˜ë³µ ê¸°ì¤€)

| ë°©ì‹ | ì†Œìš” ì‹œê°„ | ìƒëŒ€ ì†ë„ | ìƒíƒœ |
|------|----------|----------|------|
| **CPU ë³‘ë ¬ (27ì½”ì–´) + ë²¡í„°í™”** | **40-50ë¶„** | **25-30ë°°** | âœ… **ê¶Œì¥** |
| GPU (CUDA 12.8 í•„ìš”) | 30-40ë¶„ | 30-40ë°° | âš ï¸ CUDA ì¬ì„¤ì¹˜ í•„ìš” |
| CPU ë³‘ë ¬ (27ì½”ì–´) | 42ë¶„ | 27ë°° | âœ… ì‘ë™ ì¤‘ |
| CPU ìˆœì°¨ (1ì½”ì–´) | 18ì‹œê°„ | 1ë°° | âŒ ë„ˆë¬´ ëŠë¦¼ |

---

## ğŸ’¡ ê²°ë¡ 

**GPUë¥¼ ë¬´ì¡°ê±´ ì‚¬ìš©í•˜ë ¤ë©´**: CUDA 12.8 ì¬ì„¤ì¹˜ í•„ìš” (ë°©ì•ˆ 1)

**í˜„ì‹¤ì ì¸ ìµœì„ **: CPU ë³‘ë ¬ + NumPy ë²¡í„°í™” (ë°©ì•ˆ 3)
- GPUì™€ ê±°ì˜ ë™ì¼í•œ ì„±ëŠ¥
- ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- ì•ˆì •ì 

---

**ì‘ì„±ì¼**: 2025-11-09
**ìƒíƒœ**: CPU ë³‘ë ¬ + ë²¡í„°í™” ê¶Œì¥, GPUëŠ” CUDA 12.8 ì¬ì„¤ì¹˜ í•„ìš”

