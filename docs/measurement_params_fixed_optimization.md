# μΈ΅μ •λ¨λΈ νλΌλ―Έν„° κ³ μ • μ‹ μµμ ν™”

## π“‹ κ°μ”

λ™μ‹μ¶”μ •μ—μ„ **μΈ΅μ •λ¨λΈ νλΌλ―Έν„°λ¥Ό κ³ μ •**ν•λ” κ²½μ°, λ¶ν•„μ”ν• κ³„μ‚°μ„ μ κ±°ν•μ—¬ μ„±λ¥μ„ ν¬κ² ν–¥μƒμ‹ν‚¬ μ μμµλ‹λ‹¤.

### κ³ μ •λλ” νλΌλ―Έν„°

1. **Ξ¶ (zeta)**: μ”μΈμ μ¬λ‰ (Factor Loadings)
2. **ΟƒΒ² (sigma_sq)**: μ¤μ°¨λ¶„μ‚° (Error Variance)

λ‘ νλΌλ―Έν„° λ¨λ‘ μμ°¨μ¶”μ • 1λ‹¨κ³„(SEM)μ—μ„ μ¶”μ •λ κ°’μ„ μ‚¬μ©ν•©λ‹λ‹¤.

## π”΄ κΈ°μ΅΄ λ¬Έμ μ 

μΈ΅μ •λ¨λΈ νλΌλ―Έν„°κ°€ κ³ μ •λμ–΄ μμμ—λ„ λ¶κµ¬ν•κ³ :

1. **μ°λ„ κ³„μ‚°**: λ§¤ iterationλ§λ‹¤ μΈ΅μ •λ¨λΈ μ°λ„λ¥Ό μ¬κ³„μ‚°
2. **κ·Έλλ””μ–ΈνΈ κ³„μ‚°**: λ§¤ iterationλ§λ‹¤ μΈ΅μ •λ¨λΈ κ·Έλλ””μ–ΈνΈλ¥Ό κ³„μ‚° (ν•­μƒ 0)
3. **λ©”λ¨λ¦¬ λ‚­λΉ„**: λ™μΌν• κ°’μ„ λ°λ³µμ μΌλ΅ κ³„μ‚°ν•μ—¬ λ©”λ¨λ¦¬μ™€ μ‹κ°„ λ‚­λΉ„

### μμ‹: 100 iterations, 1000 individuals, 100 draws

- **μΈ΅μ •λ¨λΈ μ°λ„ κ³„μ‚° νμ**: 100 Γ— 1000 Γ— 100 = **10,000,000ν**
- **μΈ΅μ •λ¨λΈ κ·Έλλ””μ–ΈνΈ κ³„μ‚° νμ**: 100 Γ— 1000 Γ— 100 = **10,000,000ν**

ν•μ§€λ§ νλΌλ―Έν„°κ°€ κ³ μ •λμ–΄ μμΌλ―€λ΅:
- μ°λ„λ” **μµμ΄ 1νλ§** κ³„μ‚°ν•λ©΄ λ¨
- κ·Έλλ””μ–ΈνΈλ” **κ³„μ‚°ν•  ν•„μ” μ—†μ** (ν•­μƒ 0)

## β… μµμ ν™” λ°©μ•

### 1. μΈ΅μ •λ¨λΈ μ°λ„ μΊμ‹±

**νμΌ**: `src/analysis/hybrid_choice_model/iclv_models/simultaneous_gpu_batch_estimator.py`

```python
# β… μΈ΅μ •λ¨λΈ μ°λ„: νλΌλ―Έν„° κ³ μ • μ‹ μΊμ‹±
if self._measurement_params_fixed:
    # μΊμ‹ ν‚¤: (κ°μΈ ID, draw μΈλ±μ¤)
    cache_key = (ind_id, j)
    
    if self._cached_measurement_ll is None:
        self._cached_measurement_ll = {}
    
    if cache_key not in self._cached_measurement_ll:
        # μµμ΄ 1νλ§ κ³„μ‚°
        ll_measurement = measurement_model.log_likelihood(
            ind_data, lv, param_dict['measurement']
        )
        self._cached_measurement_ll[cache_key] = ll_measurement
    else:
        # μΊμ‹μ—μ„ κ°€μ Έμ¤κΈ°
        ll_measurement = self._cached_measurement_ll[cache_key]
else:
    # νλΌλ―Έν„°κ°€ λ³€ν•λ―€λ΅ λ§¤λ² κ³„μ‚°
    ll_measurement = measurement_model.log_likelihood(
        ind_data, lv, param_dict['measurement']
    )
```

### 2. μΈ΅μ •λ¨λΈ κ·Έλλ””μ–ΈνΈ κ³„μ‚° μ¤ν‚µ

**νμΌ**: `src/analysis/hybrid_choice_model/iclv_models/multi_latent_gradient.py`

```python
# β… μΈ΅μ •λ¨λΈ νλΌλ―Έν„° κ³ μ • μ‹ κ·Έλλ””μ–ΈνΈ κ³„μ‚° μ¤ν‚µ
if self.measurement_params_fixed:
    # μΈ΅μ •λ¨λΈ κ·Έλλ””μ–ΈνΈλ¥Ό 0μΌλ΅ μ„¤μ • (νλΌλ―Έν„° κ³ μ •)
    grad_meas = {}
    for lv_name in self.measurement_grad.lv_names:
        config = self.measurement_grad.measurement_configs[lv_name]
        measurement_method = getattr(config, 'measurement_method', 'ordered_probit')
        
        n_ind = len(config.indicators)
        grad_meas[lv_name] = {'grad_zeta': np.zeros(n_ind)}
        
        if measurement_method == 'continuous_linear':
            grad_meas[lv_name]['grad_sigma_sq'] = np.zeros(n_ind)
        else:
            n_thresh = config.n_categories - 1
            grad_meas[lv_name]['grad_tau'] = np.zeros((n_ind, n_thresh))
else:
    # νλΌλ―Έν„°κ°€ λ³€ν•λ―€λ΅ κ·Έλλ””μ–ΈνΈ κ³„μ‚°
    grad_meas = self.measurement_grad.compute_gradient(
        ind_data, latent_vars, params_dict['measurement']
    )
```

## π€ μ„±λ¥ ν–¥μƒ μμƒ

### κ³„μ‚° λ³µμ΅λ„ λΉ„κµ

| ν•­λ© | κΈ°μ΅΄ | μµμ ν™” ν›„ | κ°μ„ μ¨ |
|------|------|----------|--------|
| μΈ΅μ •λ¨λΈ μ°λ„ κ³„μ‚° | O(N Γ— R Γ— I) | O(N Γ— R) | **~Iλ°°** |
| μΈ΅μ •λ¨λΈ κ·Έλλ””μ–ΈνΈ κ³„μ‚° | O(N Γ— R Γ— I) | O(1) | **~λ¬΄ν•λ€** |

- N: κ°μΈ μ
- R: Halton draws μ
- I: Iteration μ

### μ‹¤μ  μμ‹ (N=1000, R=100, I=100)

- **μ°λ„ κ³„μ‚°**: 10,000,000ν β†’ 100,000ν (**100λ°° κ°μ†**)
- **κ·Έλλ””μ–ΈνΈ κ³„μ‚°**: 10,000,000ν β†’ 0ν (**μ™„μ „ μ κ±°**)

## π“ μ‚¬μ© λ°©λ²•

### μλ™ κ°μ§€

`SimultaneousGPUBatchEstimator`λ” μ΄κΈ° νλΌλ―Έν„°μ— `measurement` ν‚¤κ°€ μμΌλ©΄ μλ™μΌλ΅ μΈ΅μ •λ¨λΈ νλΌλ―Έν„° κ³ μ • λ¨λ“λ¥Ό ν™μ„±ν™”ν•©λ‹λ‹¤.

```python
# estimate() νΈμ¶ μ‹ initial_paramsμ— measurement ν¬ν•¨
estimator.estimate(
    data=data,
    measurement_model=measurement_model,
    structural_model=structural_model,
    choice_model=choice_model,
    initial_params=initial_params  # {'measurement': {...}, 'structural': {...}, 'choice': {...}}
)
```

### λ΅κ·Έ ν™•μΈ

μµμ ν™”κ°€ ν™μ„±ν™”λλ©΄ λ‹¤μκ³Ό κ°™μ€ λ΅κ·Έκ°€ μ¶λ ¥λ©λ‹λ‹¤:

```
β… μΈ΅μ •λ¨λΈ νλΌλ―Έν„° κ³ μ • λ¨λ“: μ°λ„λ¥Ό μµμ΄ 1νλ§ κ³„μ‚°ν•κ³  μΊμ‹±ν•©λ‹λ‹¤.
β… μΈ΅μ •λ¨λΈ νλΌλ―Έν„° κ³ μ •: κ·Έλλ””μ–ΈνΈ κ³„μ‚° μ¤ν‚µ
```

## π” κ²€μ¦

### μ°λ„ κ°’ ν™•μΈ

μµμ ν™” μ „ν›„ μ°λ„ κ°’μ΄ λ™μΌν•μ§€ ν™•μΈ:

```python
# μµμ ν™” μ „
ll_before = estimator._joint_log_likelihood(params, ...)

# μµμ ν™” ν›„
ll_after = estimator._joint_log_likelihood(params, ...)

assert np.isclose(ll_before, ll_after)
```

### κ·Έλλ””μ–ΈνΈ κ°’ ν™•μΈ

μΈ΅μ •λ¨λΈ κ·Έλλ””μ–ΈνΈκ°€ 0μΈμ§€ ν™•μΈ:

```python
gradients = joint_grad.compute_gradients(...)

for ind_grad in gradients:
    for lv_name, grad in ind_grad['measurement'].items():
        assert np.allclose(grad['grad_zeta'], 0.0)
        if 'grad_sigma_sq' in grad:
            assert np.allclose(grad['grad_sigma_sq'], 0.0)
```

## π“ μ£Όμμ‚¬ν•­

1. **μΈ΅μ •λ¨λΈ νλΌλ―Έν„°κ°€ μ‹¤μ λ΅ κ³ μ •λμ–΄ μλ”μ§€ ν™•μΈ**
   - μμ°¨μ¶”μ • 1λ‹¨κ³„μ—μ„ μ¶”μ •λ κ°’μ„ μ‚¬μ©ν•λ” κ²½μ°μ—λ§ μ μ©
   - Ξ¶ (μ”μΈμ μ¬λ‰)μ™€ ΟƒΒ² (μ¤μ°¨λ¶„μ‚°) λ¨λ‘ μμ°¨μ¶”μ •μ—μ„ λ΅λ“λ¨

2. **μΊμ‹ λ©”λ¨λ¦¬ μ‚¬μ©λ‰**
   - κ°μΈ μ Γ— draws μλ§νΌ μΊμ‹ μ €μ¥
   - λ©”λ¨λ¦¬κ°€ λ¶€μ΅±ν• κ²½μ° μ£Όμ

3. **λ””λ²„κΉ… μ‹**
   - μµμ ν™”λ¥Ό λΉ„ν™μ„±ν™”ν•λ ¤λ©΄ `_measurement_params_fixed = False`λ΅ μ„¤μ •

## π“ μμ°¨μ¶”μ •μ—μ„ μΈ΅μ •λ¨λΈ νλΌλ―Έν„° λ΅λ“

### lavaan κ²°κ³Όμ—μ„ νλΌλ―Έν„° μ¶”μ¶

**νμΌ**: `scripts/test_gpu_batch_iclv.py`

```python
# β… zeta (μ”μΈμ μ¬λ‰) μ¶”μ¶
# lavaanμ—μ„ '~' μ—°μ‚°μλ΅ ν‘ν„λ¨
row = meas_params[(meas_params['lval'] == indicator) &
                 (meas_params['op'] == '~') &
                 (meas_params['rval'] == lv_name)]

# β… sigma_sq (μ¤μ°¨λ¶„μ‚°) μ¶”μ¶
# lavaanμ—μ„ '~~' μ—°μ‚°μλ΅ ν‘ν„λ¨ (μκΈ° μμ‹ κ³Όμ κ³µλ¶„μ‚°)
row = meas_params[(meas_params['lval'] == indicator) &
                 (meas_params['op'] == '~~') &
                 (meas_params['rval'] == indicator)]
```

### λ΅λ“ ν™•μΈ λ΅κ·Έ

```
[INFO] health_concern μΈ΅μ •λ¨λΈ νλΌλ―Έν„° λ΅λ“:
  - zeta (μ”μΈμ μ¬λ‰): [1.0, 0.95, 0.98, ...]
  - sigma_sq (μ¤μ°¨λ¶„μ‚°): [0.61, 0.50, 0.49, ...]
```

