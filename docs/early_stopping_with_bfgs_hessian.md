# ì¡°ê¸° ì¢…ë£Œ + BFGS Hessian ì—­í–‰ë ¬ í™œìš©

## ğŸ¯ í•µì‹¬ ì•„ì´ë””ì–´

**StopIteration ì˜ˆì™¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , BFGSì˜ ì •ìƒ ì¢…ë£Œ ì¡°ê±´ì„ ì¡°ê¸° ì¢…ë£Œ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •**

â†’ BFGSê°€ ì •ìƒ ì¢…ë£Œí•˜ë©´ì„œ `result.hess_inv`ë¥¼ ìë™ ì œê³µ (ì¶”ê°€ ê³„ì‚° 0íšŒ!)

---

## âŒ ì´ì „ ë°©ì‹ì˜ ë¬¸ì œì 

### **ë°©ì‹ 1: StopIteration ì˜ˆì™¸**

```python
def objective(self, x):
    if self.no_improvement_count >= self.patience:
        raise StopIteration("ì¡°ê¸° ì¢…ë£Œ")  # âŒ ì˜ˆì™¸ ë°œìƒ
    return current_ll

try:
    result = optimize.minimize(...)
except StopIteration:
    # âŒ result ê°ì²´ ìƒì„± ì•ˆ ë¨
    # âŒ BFGSì˜ hess_inv ì ‘ê·¼ ë¶ˆê°€ëŠ¥
    # âŒ ì¶”ê°€ ê³„ì‚° í•„ìš” (BHHH: 150íšŒ, ìˆ˜ì¹˜ì : 41,209íšŒ)
    pass
```

**ë¬¸ì œ**:
- âŒ `StopIteration` ì˜ˆì™¸ â†’ `optimize.minimize` ì¤‘ë‹¨
- âŒ `OptimizeResult` ê°ì²´ ìƒì„± ì•ˆ ë¨
- âŒ BFGS ë‚´ë¶€ `hess_inv` ì†Œë©¸
- âŒ ì¶”ê°€ Hessian ê³„ì‚° í•„ìš”

---

## âœ… ìƒˆë¡œìš´ ë°©ì‹: ì •ìƒ ì¢…ë£Œ í™œìš©

### **í•µì‹¬ ì›ë¦¬**

ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì¶©ì¡± ì‹œ:
1. **ë§¤ìš° í° ê°’ ë°˜í™˜** (1e10) â†’ BFGSê°€ "ë” ì´ìƒ ê°œì„  ë¶ˆê°€ëŠ¥"ìœ¼ë¡œ íŒë‹¨
2. **0 ë²¡í„° gradient ë°˜í™˜** â†’ BFGSê°€ "ìµœì ì  ë„ë‹¬"ë¡œ íŒë‹¨
3. **BFGSê°€ ì •ìƒ ì¢…ë£Œ** â†’ `result.hess_inv` ìë™ ì œê³µ
4. **ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ë³µì›** â†’ ì¡°ê¸° ì¢…ë£Œ ì‹œì ì˜ ìµœì ê°’ ì‚¬ìš©

---

### **êµ¬í˜„ ì½”ë“œ**

```python
class EarlyStoppingWrapper:
    """
    StopIteration ì˜ˆì™¸ ëŒ€ì‹  ë§¤ìš° í° ê°’ì„ ë°˜í™˜í•˜ì—¬ BFGSê°€ ì •ìƒ ì¢…ë£Œí•˜ë„ë¡ ìœ ë„
    â†’ BFGSê°€ ì •ìƒ ì¢…ë£Œí•˜ë©´ result.hess_inv ìë™ ì œê³µ (ì¶”ê°€ ê³„ì‚° 0íšŒ!)
    """
    
    def __init__(self, func, grad_func, patience=5, tol=1e-6, ...):
        self.best_ll = np.inf
        self.best_x = None
        self.no_improvement_count = 0
        self.early_stopped = False
    
    def objective(self, x):
        """ì¡°ê¸° ì¢…ë£Œ ì‹œ ë§¤ìš° í° ê°’ ë°˜í™˜"""
        # ì´ë¯¸ ì¡°ê¸° ì¢…ë£Œëœ ê²½ìš°
        if self.early_stopped:
            return 1e10  # âœ… ë§¤ìš° í° ê°’ ë°˜í™˜
        
        current_ll = self.func(x)
        
        # LL ê°œì„  ì²´í¬
        if current_ll < self.best_ll - self.tol:
            self.best_ll = current_ll
            self.best_x = x.copy()
            self.no_improvement_count = 0
        else:
            self.no_improvement_count += 1
        
        # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
        if self.no_improvement_count >= self.patience:
            self.early_stopped = True
            return 1e10  # âœ… ë§¤ìš° í° ê°’ ë°˜í™˜ (ì˜ˆì™¸ ëŒ€ì‹ )
        
        return current_ll
    
    def gradient(self, x):
        """ì¡°ê¸° ì¢…ë£Œ ì‹œ 0 ë²¡í„° ë°˜í™˜"""
        if self.early_stopped:
            return np.zeros_like(x)  # âœ… 0 ë²¡í„° ë°˜í™˜
        
        return self.grad_func(x)
    
    def callback(self, xk):
        """ì¡°ê¸° ì¢…ë£Œ ì‹œ ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ë³µì›"""
        if self.early_stopped and self.best_x is not None:
            xk[:] = self.best_x  # âœ… ìµœì  íŒŒë¼ë¯¸í„° ë³µì›
```

---

### **ìµœì í™” ì‹¤í–‰**

```python
# BFGS ì‹¤í–‰ (ì •ìƒ ì¢…ë£Œ)
result = optimize.minimize(
    early_stopping_wrapper.objective,
    initial_params,
    method='BFGS',  # âœ… BFGS ì‚¬ìš© (hess_inv ì œê³µ)
    jac=early_stopping_wrapper.gradient,
    callback=early_stopping_wrapper.callback,
    options={
        'maxiter': 200,
        'ftol': 1e-6,
        'gtol': 1e-5,
        'disp': True
    }
)

# ì¡°ê¸° ì¢…ë£Œëœ ê²½ìš° ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ë³µì›
if early_stopping_wrapper.early_stopped:
    result = OptimizeResult(
        x=early_stopping_wrapper.best_x,  # âœ… ìµœì  íŒŒë¼ë¯¸í„°
        success=True,
        message="Early stopping",
        fun=early_stopping_wrapper.best_ll,
        nit=early_stopping_wrapper.func_call_count,
        nfev=early_stopping_wrapper.func_call_count,
        njev=early_stopping_wrapper.grad_call_count,
        hess_inv=None  # ë‚˜ì¤‘ì— ì„¤ì •
    )

# Hessian ì—­í–‰ë ¬ ì²˜ë¦¬
if self.config.estimation.calculate_se:
    if hasattr(result, 'hess_inv') and result.hess_inv is not None:
        # âœ… BFGSì˜ hess_inv ì‚¬ìš© (ì¶”ê°€ ê³„ì‚° 0íšŒ!)
        logger.info("Hessian ì—­í–‰ë ¬: BFGSì—ì„œ ìë™ ì œê³µ (ì¶”ê°€ ê³„ì‚° 0íšŒ)")
    else:
        # âŒ L-BFGS-BëŠ” hess_inv ì œê³µ ì•ˆ í•¨
        logger.warning("Hessian ì—­í–‰ë ¬ ì—†ìŒ (L-BFGS-BëŠ” hess_inv ì œê³µ ì•ˆ í•¨)")
        logger.info("í‘œì¤€ì˜¤ì°¨ ê³„ì‚°ì„ ìœ„í•´ì„œëŠ” BFGS ë°©ë²• ì‚¬ìš© ê¶Œì¥")
```

---

## ğŸ“Š ì‘ë™ ì›ë¦¬

### **BFGSì˜ ì¢…ë£Œ ì¡°ê±´**

BFGSëŠ” ë‹¤ìŒ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¥¼ ë§Œì¡±í•˜ë©´ ì¢…ë£Œ:

1. **Gradient normì´ ë§¤ìš° ì‘ìŒ** (`gtol` ê¸°ì¤€)
   - `||gradient|| < gtol` â†’ ìµœì ì  ë„ë‹¬
   - ìš°ë¦¬ì˜ ê²½ìš°: `gradient = 0` â†’ ì¦‰ì‹œ ì¢…ë£Œ

2. **í•¨ìˆ˜ê°’ ë³€í™”ê°€ ë§¤ìš° ì‘ìŒ** (`ftol` ê¸°ì¤€)
   - `|f_new - f_old| < ftol` â†’ ë” ì´ìƒ ê°œì„  ë¶ˆê°€ëŠ¥
   - ìš°ë¦¬ì˜ ê²½ìš°: `f_new = 1e10` (ë§¤ìš° í° ê°’) â†’ ì¦‰ì‹œ ì¢…ë£Œ

3. **ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬** (`maxiter`)

---

### **ì¡°ê¸° ì¢…ë£Œ ì‹œë‚˜ë¦¬ì˜¤**

```
Iteration 1: LL = -40000 (ê°œì„ ) â†’ best_ll = -40000, no_improvement = 0
Iteration 2: LL = -39500 (ê°œì„ ) â†’ best_ll = -39500, no_improvement = 0
Iteration 3: LL = -39400 (ê°œì„ ) â†’ best_ll = -39400, no_improvement = 0
Iteration 4: LL = -39390 (ê°œì„  ë¯¸ë¯¸) â†’ best_ll = -39400, no_improvement = 1
Iteration 5: LL = -39395 (ê°œì„  ë¯¸ë¯¸) â†’ best_ll = -39400, no_improvement = 2
Iteration 6: LL = -39398 (ê°œì„  ë¯¸ë¯¸) â†’ best_ll = -39400, no_improvement = 3
Iteration 7: LL = -39399 (ê°œì„  ë¯¸ë¯¸) â†’ best_ll = -39400, no_improvement = 4
Iteration 8: LL = -39399.5 (ê°œì„  ë¯¸ë¯¸) â†’ best_ll = -39400, no_improvement = 5
         â†“
    ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì¶©ì¡± (patience=5)
         â†“
    early_stopped = True
         â†“
    ë‹¤ìŒ í˜¸ì¶œ ì‹œ:
    - objective() â†’ 1e10 ë°˜í™˜
    - gradient() â†’ [0, 0, ..., 0] ë°˜í™˜
    - callback() â†’ best_xë¡œ ë³µì›
         â†“
    BFGS íŒë‹¨: "gradient=0ì´ê³  í•¨ìˆ˜ê°’ì´ ê¸‰ì¦ â†’ ìµœì ì  ë„ë‹¬, ì¢…ë£Œ"
         â†“
    result.hess_inv ìë™ ìƒì„± âœ…
```

---

## âœ… ì¥ì 

### **1. ì¶”ê°€ ê³„ì‚° 0íšŒ**

| ë°©ë²• | ìš°ë„ ê³„ì‚° | ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° | ì†Œìš” ì‹œê°„ |
|------|-----------|----------------|-----------|
| **StopIteration + BHHH** | 50íšŒ | 150íšŒ | 1.5ë¶„ |
| **StopIteration + ìˆ˜ì¹˜ì ** | 41,209íšŒ | 0íšŒ | 10.5ì¼ |
| **ì •ìƒ ì¢…ë£Œ + BFGS hess_inv** | **0íšŒ** | **0íšŒ** | **0ì´ˆ** |

**BFGS hess_inv í™œìš©**:
- âœ… ì¶”ê°€ ìš°ë„ ê³„ì‚°: **0íšŒ**
- âœ… ì¶”ê°€ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°: **0íšŒ**
- âœ… ì¶”ê°€ ì†Œìš” ì‹œê°„: **0ì´ˆ**
- âœ… **BFGSê°€ ì´ë¯¸ ê³„ì‚°í•œ Hessian ì—­í–‰ë ¬ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©**

---

### **2. ì •í™•ì„±**

| ë°©ë²• | Hessian í¬ê¸° | ìƒê´€ê´€ê³„ | ì •í™•ë„ |
|------|--------------|----------|--------|
| ìˆ˜ì¹˜ì  (ëŒ€ê°) | 202ê°œ | âŒ ë¬´ì‹œ | ë‚®ìŒ |
| BHHH | 40,804ê°œ | âœ… í¬í•¨ | ë†’ìŒ |
| **BFGS hess_inv** | **40,804ê°œ** | **âœ… í¬í•¨** | **ë§¤ìš° ë†’ìŒ** |

**BFGS hess_inv**:
- âœ… ì „ì²´ Hessian ì—­í–‰ë ¬ (202 Ã— 202)
- âœ… íŒŒë¼ë¯¸í„° ê°„ ìƒê´€ê´€ê³„ í¬í•¨
- âœ… BFGSê°€ ìµœì í™” ê³¼ì •ì—ì„œ ëˆ„ì í•œ ì •ë³´ í™œìš©
- âœ… **ê°€ì¥ ì •í™•í•œ Hessian ê·¼ì‚¬**

---

### **3. êµ¬í˜„ ê°„ë‹¨**

**ì´ì „ (StopIteration)**:
```python
try:
    result = optimize.minimize(...)
except StopIteration:
    # ë³µì¡í•œ ì˜ˆì™¸ ì²˜ë¦¬
    # BHHH ê³„ì‚° (50íšŒ gradient)
    # ë˜ëŠ” ìˆ˜ì¹˜ì  ê³„ì‚° (41,209íšŒ ìš°ë„)
    pass
```

**í˜„ì¬ (ì •ìƒ ì¢…ë£Œ)**:
```python
result = optimize.minimize(...)  # ì •ìƒ ì¢…ë£Œ

if early_stopped:
    result.x = best_x  # ìµœì  íŒŒë¼ë¯¸í„° ë³µì›

# result.hess_inv ìë™ ì œê³µ âœ…
```

---

## ğŸ” BFGS vs L-BFGS-B

### **BFGS**

```python
method='BFGS'
```

**ì¥ì **:
- âœ… `result.hess_inv` ì œê³µ (ì „ì²´ Hessian ì—­í–‰ë ¬)
- âœ… ì¶”ê°€ ê³„ì‚° 0íšŒ
- âœ… í‘œì¤€ì˜¤ì°¨ ê³„ì‚° ê°€ëŠ¥

**ë‹¨ì **:
- âŒ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë§ìŒ (O(nÂ²) = 202Â² = 40,804ê°œ ì›ì†Œ)
- âŒ Bounds ì§€ì› ì•ˆ í•¨

---

### **L-BFGS-B**

```python
method='L-BFGS-B'
```

**ì¥ì **:
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (Limited-memory)
- âœ… Bounds ì§€ì›

**ë‹¨ì **:
- âŒ `result.hess_inv` ì œê³µ ì•ˆ í•¨
- âŒ í‘œì¤€ì˜¤ì°¨ ê³„ì‚° ë¶ˆê°€ëŠ¥ (ì¶”ê°€ ê³„ì‚° í•„ìš”)

---

## ğŸ“‹ ê¶Œì¥ ì‚¬í•­

### **í‘œì¤€ì˜¤ì°¨ ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°**

```python
optimizer = 'BFGS'  # âœ… BFGS ì‚¬ìš©
calculate_se = True
```

**ì´ìœ **:
- âœ… `result.hess_inv` ìë™ ì œê³µ
- âœ… ì¶”ê°€ ê³„ì‚° 0íšŒ
- âœ… ê°€ì¥ ì •í™•í•œ í‘œì¤€ì˜¤ì°¨

---

### **í‘œì¤€ì˜¤ì°¨ ê³„ì‚°ì´ ë¶ˆí•„ìš”í•œ ê²½ìš°**

```python
optimizer = 'L-BFGS-B'  # âœ… L-BFGS-B ì‚¬ìš©
calculate_se = False
```

**ì´ìœ **:
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì 
- âœ… Bounds ì§€ì›
- âœ… ë¹ ë¥¸ ìˆ˜ë ´

---

## ğŸ¯ ê²°ë¡ 

**ì¡°ê¸° ì¢…ë£Œ + BFGS Hessian ì—­í–‰ë ¬ í™œìš©**:

1. âœ… **ì¶”ê°€ ê³„ì‚° 0íšŒ** (BHHH: 150íšŒ, ìˆ˜ì¹˜ì : 41,209íšŒ â†’ 0íšŒ)
2. âœ… **ì¶”ê°€ ì‹œê°„ 0ì´ˆ** (BHHH: 1.5ë¶„, ìˆ˜ì¹˜ì : 10.5ì¼ â†’ 0ì´ˆ)
3. âœ… **ê°€ì¥ ì •í™•í•œ Hessian** (BFGSê°€ ìµœì í™” ê³¼ì •ì—ì„œ ëˆ„ì )
4. âœ… **êµ¬í˜„ ê°„ë‹¨** (ì˜ˆì™¸ ì²˜ë¦¬ ë¶ˆí•„ìš”)
5. âœ… **ì •ìƒ ì¢…ë£Œ** (StopIteration ì˜ˆì™¸ ì œê±°)

**ìµœì¢… ì„ íƒ**:
- í‘œì¤€ì˜¤ì°¨ í•„ìš”: **BFGS** (hess_inv ìë™ ì œê³µ)
- í‘œì¤€ì˜¤ì°¨ ë¶ˆí•„ìš”: **L-BFGS-B** (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )

---

## ğŸ“ ì½”ë“œ ë³€ê²½ ìš”ì•½

### **ë³€ê²½ ì „ (StopIteration)**

```python
def objective(self, x):
    if self.no_improvement_count >= self.patience:
        raise StopIteration("ì¡°ê¸° ì¢…ë£Œ")  # âŒ ì˜ˆì™¸
    return current_ll

try:
    result = optimize.minimize(...)
except StopIteration:
    # BHHH ê³„ì‚° (150íšŒ)
    pass
```

### **ë³€ê²½ í›„ (ì •ìƒ ì¢…ë£Œ)**

```python
def objective(self, x):
    if self.early_stopped:
        return 1e10  # âœ… ë§¤ìš° í° ê°’
    
    if self.no_improvement_count >= self.patience:
        self.early_stopped = True
        return 1e10  # âœ… ë§¤ìš° í° ê°’

    return current_ll

def gradient(self, x):
    if self.early_stopped:
        return np.zeros_like(x)  # âœ… 0 ë²¡í„°
    return self.grad_func(x)

result = optimize.minimize(...)  # ì •ìƒ ì¢…ë£Œ

if early_stopped:
    result.x = best_x  # ìµœì  íŒŒë¼ë¯¸í„° ë³µì›

# result.hess_inv ìë™ ì œê³µ âœ…
```

---

**ì™„ë²½í•œ í•´ê²°ì±…! ğŸ‰**

