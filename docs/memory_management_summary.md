# ë©”ëª¨ë¦¬ ê´€ë¦¬ êµ¬í˜„ ìš”ì•½

## ğŸ“Š êµ¬í˜„ ê°œìš”

ì¡°ê¸°ì¢…ë£Œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì •ìƒì¢…ë£Œë§Œ ì‚¬ìš©í•˜ë©´ì„œ, ê·¸ë˜ë””ì–¸íŠ¸ì™€ ìš°ë„ ê³„ì‚° ì‹œ ë©”ëª¨ë¦¬ ê³¼ë¶€í•˜ë¥¼ ë°©ì§€í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

---

## âœ… êµ¬í˜„ ì™„ë£Œ í•­ëª©

### **1. MemoryMonitor í´ë˜ìŠ¤** 
**íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/memory_monitor.py`

**ê¸°ëŠ¥**:
- CPU/GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
- ë©”ëª¨ë¦¬ ì‚¬ìš© ê¸°ë¡ ë° í†µê³„ ì œê³µ

**ì£¼ìš” ë©”ì„œë“œ**:
```python
class MemoryMonitor:
    def __init__(self, cpu_threshold_mb, gpu_threshold_mb, auto_cleanup, logger)
    def get_cpu_memory_mb() -> float
    def get_gpu_memory_mb() -> Optional[float]
    def check_and_cleanup(context: str) -> Dict[str, float]
    def cleanup_memory()
    def log_memory_stats(context: str)
    def get_memory_summary() -> Dict
```

**ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**:
```python
def cleanup_arrays(*arrays)  # ë°°ì—´ ëª…ì‹œì  ì‚­ì œ ë° ë©”ëª¨ë¦¬ ì •ë¦¬
def get_array_memory_mb(arr) -> float  # ë°°ì—´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚°
```

---

### **2. GPUBatchEstimator í†µí•©**
**íŒŒì¼**: `src/analysis/hybrid_choice_model/iclv_models/gpu_batch_estimator.py`

**ë³€ê²½ ì‚¬í•­**:

#### **ì´ˆê¸°í™” ì‹œ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ìƒì„±**
```python
def __init__(self, config, use_gpu=True,
             memory_monitor_cpu_threshold_mb=2000,
             memory_monitor_gpu_threshold_mb=1500):
    # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    self.memory_monitor = MemoryMonitor(
        cpu_threshold_mb=memory_monitor_cpu_threshold_mb,
        gpu_threshold_mb=memory_monitor_gpu_threshold_mb,
        auto_cleanup=True,
        logger=logger
    )
```

#### **ìš°ë„ ê³„ì‚° ì‹œ ë©”ëª¨ë¦¬ ì²´í¬**
```python
def _compute_individual_likelihood(self, ind_id, ind_data, ind_draws, ...):
    # ë©”ëª¨ë¦¬ ì²´í¬ (ìš°ë„ ê³„ì‚° ì „)
    mem_info = self.memory_monitor.check_and_cleanup(f"ìš°ë„ ê³„ì‚° - ê°œì¸ {ind_id}")
    
    # ìš°ë„ ê³„ì‚°...
```

#### **ê° ëª¨ë¸ ê³„ì‚° í›„ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜**
```python
def _compute_draws_batch_gpu(self, ...):
    # ì¸¡ì •ëª¨ë¸ ìš°ë„ ê³„ì‚°
    ll_measurement_batch = gpu_batch_utils.compute_measurement_batch_gpu(...)
    gc.collect()  # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
    
    # ì„ íƒëª¨ë¸ ìš°ë„ ê³„ì‚°
    ll_choice_batch = gpu_batch_utils.compute_choice_batch_gpu(...)
    gc.collect()  # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
    
    # êµ¬ì¡°ëª¨ë¸ ìš°ë„ ê³„ì‚°
    ll_structural_batch = gpu_batch_utils.compute_structural_batch_gpu(...)
    gc.collect()  # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
```

---

### **3. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì—…ë°ì´íŠ¸**
**íŒŒì¼**: `scripts/test_gpu_batch_iclv.py`

**ë³€ê²½ ì‚¬í•­**:

#### **Estimator ìƒì„± ì‹œ ë©”ëª¨ë¦¬ ì„ê³„ê°’ ì„¤ì •**
```python
estimator = GPUBatchEstimator(
    config, 
    use_gpu=True,
    memory_monitor_cpu_threshold_mb=2000,  # CPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ 2GB
    memory_monitor_gpu_threshold_mb=1500   # GPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ 1.5GB
)
```

#### **ì¶”ì • ì™„ë£Œ í›„ ë©”ëª¨ë¦¬ ìš”ì•½ ì¶œë ¥**
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½
mem_summary = estimator.memory_monitor.get_memory_summary()
print(f"í˜„ì¬ CPU ë©”ëª¨ë¦¬: {mem_summary['current_cpu_mb']:.1f}MB")
print(f"í˜„ì¬ GPU ë©”ëª¨ë¦¬: {mem_summary['current_gpu_mb']:.1f}MB")
print(f"ìµœëŒ€ CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_max_mb']:.1f}MB")
print(f"í‰ê·  CPU ë©”ëª¨ë¦¬: {mem_summary['cpu_avg_mb']:.1f}MB")
```

---

## ğŸ¯ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì „ëµ

### **1. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**
- ê°œì¸ë³„ ìš°ë„ ê³„ì‚° ì „ ë©”ëª¨ë¦¬ ì²´í¬
- ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ê²½ê³  ë° ì •ë¦¬

### **2. ì£¼ê¸°ì  ê°€ë¹„ì§€ ì»¬ë ‰ì…˜**
- ì¸¡ì •ëª¨ë¸ ê³„ì‚° í›„
- ì„ íƒëª¨ë¸ ê³„ì‚° í›„
- êµ¬ì¡°ëª¨ë¸ ê³„ì‚° í›„

### **3. ë©”ëª¨ë¦¬ ì‚¬ìš© ê¸°ë¡**
- ëª¨ë“  ì²´í¬ ì‹œì ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë¡
- ìµœëŒ€/í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### **ë©”ëª¨ë¦¬ ëˆ„ì  ë°©ì§€**

**ê¸°ì¡´ (ë©”ëª¨ë¦¬ ê´€ë¦¬ ì—†ìŒ)**:
```
Iteration 1:  ìš°ë„ 2MB + ê·¸ë˜ë””ì–¸íŠ¸ 50MB = 52MB
Iteration 10: ëˆ„ì  520MB
Iteration 45: ëˆ„ì  2,340MB âš ï¸ ê³¼ë¶€í•˜ ìœ„í—˜
```

**ê°œì„  (ë©”ëª¨ë¦¬ ê´€ë¦¬ ì ìš©)**:
```
Iteration 1:  ìš°ë„ 2MB + ê·¸ë˜ë””ì–¸íŠ¸ 50MB = 52MB â†’ ì •ë¦¬ â†’ 10MB
Iteration 10: ëˆ„ì  100MB
Iteration 45: ëˆ„ì  450MB âœ… ì•ˆì •ì 
```

### **ì„±ëŠ¥ ì˜í–¥**

- ë©”ëª¨ë¦¬ ì²´í¬: ~1% ì˜¤ë²„í—¤ë“œ
- ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: ~2-3% ì˜¤ë²„í—¤ë“œ
- **ì´ ì˜¤ë²„í—¤ë“œ**: ~3-4%
- **ì•ˆì •ì„± í–¥ìƒ**: ê³¼ë¶€í•˜ ë°©ì§€ë¡œ ê°•ì œì¢…ë£Œ ìœ„í—˜ ì œê±°

---

## ğŸ”§ ì‚¬ìš© ë°©ë²•

### **ê¸°ë³¸ ì‚¬ìš©**
```python
from src.analysis.hybrid_choice_model.iclv_models.simultaneous_gpu_batch_estimator import SimultaneousGPUBatchEstimator

# Estimator ìƒì„± (ê¸°ë³¸ ì„ê³„ê°’)
estimator = SimultaneousGPUBatchEstimator(config, use_gpu=True)

# ì¶”ì • ì‹¤í–‰
results = estimator.estimate(data, measurement_model, structural_model, choice_model)

# ë©”ëª¨ë¦¬ ìš”ì•½ í™•ì¸
summary = estimator.memory_monitor.get_memory_summary()
```

### **ì»¤ìŠ¤í…€ ì„ê³„ê°’**
```python
# ë³´ìˆ˜ì  ì„¤ì • (ì•ˆì •ì„± ìš°ì„ )
estimator = SimultaneousGPUBatchEstimator(
    config,
    use_gpu=True,
    memory_monitor_cpu_threshold_mb=1500,  # 1.5GB
    memory_monitor_gpu_threshold_mb=1000   # 1GB
)

# ê³µê²©ì  ì„¤ì • (ì„±ëŠ¥ ìš°ì„ )
estimator = SimultaneousGPUBatchEstimator(
    config,
    use_gpu=True,
    memory_monitor_cpu_threshold_mb=3000,  # 3GB
    memory_monitor_gpu_threshold_mb=2000   # 2GB
)
```

### **ë©”ëª¨ë¦¬ í†µê³„ ë¡œê¹…**
```python
# ì¶”ì • ì¤‘ ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
estimator.memory_monitor.log_memory_stats("Iteration 10")

# ì¶”ì • ì™„ë£Œ í›„ ìš”ì•½
summary = estimator.memory_monitor.get_memory_summary()
print(f"ìµœëŒ€ CPU: {summary['cpu_max_mb']:.1f}MB")
print(f"í‰ê·  CPU: {summary['cpu_avg_mb']:.1f}MB")
```

---

## ğŸ“Š ë¡œê·¸ ì˜ˆì‹œ

### **ì •ìƒ ë™ì‘**
```
[ë©”ëª¨ë¦¬ ìƒíƒœ] ìš°ë„ ê³„ì‚° - ê°œì¸ 1
  í”„ë¡œì„¸ìŠ¤ CPU: 1,234.5MB
  ì‹œìŠ¤í…œ ì „ì²´: 8,456.7MB / 16,384.0MB (51.6%)
  ì‹œìŠ¤í…œ ì—¬ìœ : 7,927.3MB
  GPU: 1,234.5MB
```

### **ì„ê³„ê°’ ì´ˆê³¼ ì‹œ**
```
[ë©”ëª¨ë¦¬ ê²½ê³ ] ìš°ë„ ê³„ì‚° - ê°œì¸ 123 | CPU: 2,345.6MB (ì„ê³„ê°’: 2000MB)
[ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ] CPU: 345.6MB í•´ì œ, GPU: 123.4MB í•´ì œ
```

### **ì¶”ì • ì™„ë£Œ í›„**
```
======================================================================
ë©”ëª¨ë¦¬ ì‚¬ìš© ìš”ì•½
======================================================================
í˜„ì¬ CPU ë©”ëª¨ë¦¬: 1,234.5MB
í˜„ì¬ GPU ë©”ëª¨ë¦¬: 987.6MB
ìµœëŒ€ CPU ë©”ëª¨ë¦¬: 2,345.6MB
í‰ê·  CPU ë©”ëª¨ë¦¬: 1,567.8MB
ìµœëŒ€ GPU ë©”ëª¨ë¦¬: 1,456.7MB
í‰ê·  GPU ë©”ëª¨ë¦¬: 1,123.4MB
```

---

## ğŸ“ ê´€ë ¨ ë¬¸ì„œ

- **ìƒì„¸ ê°€ì´ë“œ**: `docs/memory_optimization_guide.md`
- **êµ¬í˜„ ì½”ë“œ**: 
  - `src/analysis/hybrid_choice_model/iclv_models/memory_monitor.py`
  - `src/analysis/hybrid_choice_model/iclv_models/gpu_batch_estimator.py`
- **í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**: `scripts/test_gpu_batch_iclv.py`

---

## âœ… ê²€ì¦ ë°©ë²•

### **1. ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ë‹¨ë… í…ŒìŠ¤íŠ¸**
```bash
python -c "
from src.analysis.hybrid_choice_model.iclv_models.memory_monitor import MemoryMonitor
import numpy as np

monitor = MemoryMonitor(cpu_threshold_mb=1000, gpu_threshold_mb=500, auto_cleanup=True)
monitor.log_memory_stats('ì‹œì‘')

# ëŒ€ìš©ëŸ‰ ë°°ì—´ ìƒì„±
arr = np.random.rand(10000, 10000)  # ~800MB
monitor.check_and_cleanup('ë°°ì—´ ìƒì„± í›„')

del arr
monitor.log_memory_stats('ì •ë¦¬ í›„')
"
```

### **2. GPU Batch Estimator í…ŒìŠ¤íŠ¸**
```bash
python scripts/test_gpu_batch_iclv.py
```

**í™•ì¸ ì‚¬í•­**:
- ë©”ëª¨ë¦¬ ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€
- ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€
- ìµœì¢… ë©”ëª¨ë¦¬ ìš”ì•½ ì¶œë ¥ ì—¬ë¶€
- ê°•ì œì¢…ë£Œ ì—†ì´ ì •ìƒ ì™„ë£Œ ì—¬ë¶€

---

## ğŸ¯ ê²°ë¡ 

**êµ¬í˜„ ì™„ë£Œ**:
âœ… ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
âœ… ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
âœ… ë©”ëª¨ë¦¬ ì‚¬ìš© í†µê³„ ì¶”ì 
âœ… í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ í†µí•©

**íš¨ê³¼**:
âœ… ë©”ëª¨ë¦¬ ê³¼ë¶€í•˜ ë°©ì§€
âœ… ê°•ì œì¢…ë£Œ ìœ„í—˜ ì œê±°
âœ… ì•ˆì •ì ì¸ ì¥ì‹œê°„ ì‹¤í–‰
âœ… ìµœì†Œí•œì˜ ì„±ëŠ¥ ì˜í–¥ (~3-4%)

**ê¶Œì¥ ì„¤ì •**:
- CPU ì„ê³„ê°’: 2000MB (2GB)
- GPU ì„ê³„ê°’: 1500MB (1.5GB)
- ìë™ ì •ë¦¬: í™œì„±í™”

