# ë©”ëª¨ë¦¬ ìµœì í™” ê°€ì´ë“œ

## ğŸ“Š ê°œìš”

ICLV ëª¨ë¸ ì¶”ì • ì‹œ ë©”ëª¨ë¦¬ ê³¼ë¶€í•˜ë¥¼ ë°©ì§€í•˜ê³  ì•ˆì •ì ì¸ ì‹¤í–‰ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ì•ˆì…ë‹ˆë‹¤.

---

## ğŸ” ê°•ì œì¢…ë£Œ ì›ì¸ ë¶„ì„

### **ë°œìƒ ìƒí™©**
- **ì‹œê°„**: 2025-11-10 09:50:49
- **Iteration**: 45/200 (22.5% ì™„ë£Œ)
- **ì‹¤í–‰ ì‹œê°„**: 3ì‹œê°„ 47ë¶„
- **ì¢…ë£Œ ì‹œì **: Gradient ê³„ì‚° ì¤‘

### **ì£¼ìš” ì›ì¸**

#### 1. **ì¥ì‹œê°„ ì‹¤í–‰** âš ï¸
- ì˜ˆìƒ ì´ ì†Œìš” ì‹œê°„: 16-17ì‹œê°„
- ì¡°ê¸° ì¢…ë£Œ ë¹„í™œì„±í™” (`patience=999999`)
- ìµœëŒ€ ë°˜ë³µ 200íšŒ ì„¤ì •

#### 2. **ë©”ëª¨ë¦¬ ëˆ„ì ** âš ï¸
- 326ëª… Ã— 100 draws Ã— 202 íŒŒë¼ë¯¸í„°
- ê° iterationë§ˆë‹¤ ì„ì‹œ ë°°ì—´ ìƒì„±
- ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë¯¸ì‹¤í–‰

#### 3. **GPU/CPU ë©”ëª¨ë¦¬ ì‚¬ìš© íŒ¨í„´**
```
GPU ë©”ëª¨ë¦¬: 2,014 MB / 8,188 MB (24.6%) âœ… ì—¬ìœ  ìˆìŒ
CPU ë©”ëª¨ë¦¬: í™•ì¸ ë¶ˆê°€ âŒ ë¶€ì¡± ê°€ëŠ¥ì„±
```

---

## âœ… í•´ê²° ë°©ì•ˆ

### **ë°©ì•ˆ 1: ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì •ë¦¬** (êµ¬í˜„ ì™„ë£Œ)

#### **MemoryMonitor í´ë˜ìŠ¤**

**ìœ„ì¹˜**: `src/analysis/hybrid_choice_model/iclv_models/memory_monitor.py`

**ê¸°ëŠ¥**:
1. CPU/GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
2. ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
3. ë©”ëª¨ë¦¬ ì‚¬ìš© ê¸°ë¡ ë° í†µê³„

**ì‚¬ìš©ë²•**:
```python
from .memory_monitor import MemoryMonitor

# ì´ˆê¸°í™”
memory_monitor = MemoryMonitor(
    cpu_threshold_mb=2000,  # CPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
    gpu_threshold_mb=1500,  # GPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
    auto_cleanup=True       # ìë™ ì •ë¦¬ í™œì„±í™”
)

# ë©”ëª¨ë¦¬ ì²´í¬ ë° ì •ë¦¬
mem_info = memory_monitor.check_and_cleanup("ìš°ë„ ê³„ì‚°")

# ë©”ëª¨ë¦¬ í†µê³„ ë¡œê¹…
memory_monitor.log_memory_stats("Iteration 10")
```

#### **GPUBatchEstimator í†µí•©**

**ë³€ê²½ ì‚¬í•­**:
```python
class GPUBatchEstimator(SimultaneousEstimator):
    def __init__(self, config, use_gpu=True,
                 memory_monitor_cpu_threshold_mb=2000,
                 memory_monitor_gpu_threshold_mb=1500):
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
        self.memory_monitor = MemoryMonitor(
            cpu_threshold_mb=memory_monitor_cpu_threshold_mb,
            gpu_threshold_mb=memory_monitor_gpu_threshold_mb,
            auto_cleanup=True
        )
```

**ì ìš© ìœ„ì¹˜**:
1. **ìš°ë„ ê³„ì‚° ì „**: ê°œì¸ë³„ ìš°ë„ ê³„ì‚° ì‹œì‘ ì‹œ
2. **ì¸¡ì •ëª¨ë¸ ê³„ì‚° í›„**: `gc.collect()` í˜¸ì¶œ
3. **ì„ íƒëª¨ë¸ ê³„ì‚° í›„**: `gc.collect()` í˜¸ì¶œ
4. **êµ¬ì¡°ëª¨ë¸ ê³„ì‚° í›„**: `gc.collect()` í˜¸ì¶œ

---

### **ë°©ì•ˆ 2: ë°°ì¹˜ í¬ê¸° ì¡°ì •** (ì„ íƒì )

í˜„ì¬ ì „ì²´ 326ëª…ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ëŒ€ì‹ , ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬:

```python
# ì˜ˆì‹œ: 100ëª…ì”© ë°°ì¹˜ ì²˜ë¦¬
batch_size = 100
n_batches = (n_individuals + batch_size - 1) // batch_size

for batch_idx in range(n_batches):
    start_idx = batch_idx * batch_size
    end_idx = min((batch_idx + 1) * batch_size, n_individuals)
    
    # ë°°ì¹˜ ì²˜ë¦¬
    batch_ll = process_batch(start_idx, end_idx)
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    gc.collect()
```

**íš¨ê³¼**:
- CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
- ê³„ì‚° ì•ˆì •ì„± í–¥ìƒ
- ì•½ê°„ì˜ ì†ë„ ì €í•˜ (ë°°ì¹˜ ê°„ ì˜¤ë²„í—¤ë“œ)

---

### **ë°©ì•ˆ 3: ëª…ì‹œì  ë°°ì—´ ì‚­ì œ**

ì„ì‹œ ë°°ì—´ì„ ëª…ì‹œì ìœ¼ë¡œ ì‚­ì œ:

```python
from .memory_monitor import cleanup_arrays

# ê³„ì‚° ìˆ˜í–‰
ll_measurement_batch = compute_measurement_batch_gpu(...)
ll_choice_batch = compute_choice_batch_gpu(...)

# ì‚¬ìš© í›„ ì‚­ì œ
cleanup_arrays(ll_measurement_batch, ll_choice_batch)
```

---

## ğŸ“ˆ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •

### **ìš°ë„ ê³„ì‚° ì‹œ**

**ë°°ì—´ í¬ê¸°**:
- `lvs_list`: 100 draws Ã— 5 LVs Ã— 8 bytes = 4 KB
- `ll_measurement_batch`: 100 draws Ã— 8 bytes = 0.8 KB
- `ll_choice_batch`: 100 draws Ã— 8 bytes = 0.8 KB
- `ll_structural_batch`: 100 draws Ã— 8 bytes = 0.8 KB

**ì´ ë©”ëª¨ë¦¬ (ê°œì¸ë‹¹)**: ~6 KB
**ì „ì²´ (326ëª…)**: ~2 MB

### **ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì‹œ**

**ë°°ì—´ í¬ê¸°**:
- `grad_zeta_batch`: 100 draws Ã— 38 indicators Ã— 8 bytes = 30 KB
- `grad_tau_batch`: 100 draws Ã— 38 Ã— 4 Ã— 8 bytes = 122 KB
- `grad_gamma_lv`: 4 Ã— 8 bytes = 32 bytes
- `grad_gamma_x`: 3 Ã— 8 bytes = 24 bytes

**ì´ ë©”ëª¨ë¦¬ (ê°œì¸ë‹¹)**: ~152 KB
**ì „ì²´ (326ëª…)**: ~50 MB

### **ëˆ„ì  ë©”ëª¨ë¦¬**

**45 iterations í›„**:
- ìš°ë„ ê³„ì‚°: 45 Ã— 2 MB = 90 MB
- ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°: 45 Ã— 50 MB = 2,250 MB âš ï¸

**ë¬¸ì œì **: ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì—†ì´ ëˆ„ì  ì‹œ **2.3 GB** ì‚¬ìš©

---

## ğŸ¯ ê¶Œì¥ ì„¤ì •

### **ë©”ëª¨ë¦¬ ì„ê³„ê°’**

```python
# ë³´ìˆ˜ì  ì„¤ì • (ì•ˆì •ì„± ìš°ì„ )
memory_monitor_cpu_threshold_mb=1500  # 1.5 GB
memory_monitor_gpu_threshold_mb=1000  # 1 GB

# í‘œì¤€ ì„¤ì • (ê· í˜•)
memory_monitor_cpu_threshold_mb=2000  # 2 GB
memory_monitor_gpu_threshold_mb=1500  # 1.5 GB

# ê³µê²©ì  ì„¤ì • (ì„±ëŠ¥ ìš°ì„ )
memory_monitor_cpu_threshold_mb=3000  # 3 GB
memory_monitor_gpu_threshold_mb=2000  # 2 GB
```

### **ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë¹ˆë„**

```python
# ë§¤ iterationë§ˆë‹¤ (ì•ˆì •ì„± ìµœëŒ€)
gc.collect()  # ìš°ë„ ê³„ì‚° í›„
gc.collect()  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° í›„

# 5 iterationsë§ˆë‹¤ (ê· í˜•)
if iteration % 5 == 0:
    gc.collect()

# 10 iterationsë§ˆë‹¤ (ì„±ëŠ¥ ìš°ì„ )
if iteration % 10 == 0:
    gc.collect()
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë¡œê·¸ ì˜ˆì‹œ

### **ì •ìƒ ìƒíƒœ**
```
[ë©”ëª¨ë¦¬ ìƒíƒœ] Iteration 10
  í”„ë¡œì„¸ìŠ¤ CPU: 1,234.5MB
  ì‹œìŠ¤í…œ ì „ì²´: 8,456.7MB / 16,384.0MB (51.6%)
  ì‹œìŠ¤í…œ ì—¬ìœ : 7,927.3MB
  GPU: 1,234.5MB
```

### **ì„ê³„ê°’ ì´ˆê³¼**
```
[ë©”ëª¨ë¦¬ ê²½ê³ ] ìš°ë„ ê³„ì‚° - ê°œì¸ 123 | CPU: 2,345.6MB (ì„ê³„ê°’: 2000MB)
[ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ] CPU: 345.6MB í•´ì œ, GPU: 123.4MB í•´ì œ
```

---

## ğŸ”§ í…ŒìŠ¤íŠ¸ ë°©ë²•

### **1. ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ë‹¨ë… í…ŒìŠ¤íŠ¸**

```python
from src.analysis.hybrid_choice_model.iclv_models.memory_monitor import MemoryMonitor

monitor = MemoryMonitor(
    cpu_threshold_mb=1000,
    gpu_threshold_mb=500,
    auto_cleanup=True
)

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
monitor.log_memory_stats("í…ŒìŠ¤íŠ¸ ì‹œì‘")

# ëŒ€ìš©ëŸ‰ ë°°ì—´ ìƒì„±
import numpy as np
large_array = np.random.rand(10000, 10000)  # ~800 MB

# ë©”ëª¨ë¦¬ ì²´í¬
mem_info = monitor.check_and_cleanup("ëŒ€ìš©ëŸ‰ ë°°ì—´ ìƒì„± í›„")

# ë°°ì—´ ì‚­ì œ
del large_array

# ì •ë¦¬ í›„ í™•ì¸
monitor.log_memory_stats("ì •ë¦¬ í›„")
```

### **2. GPU Batch Estimator í…ŒìŠ¤íŠ¸**

```python
# test_gpu_batch_iclv.pyì—ì„œ
estimator = GPUBatchEstimator(
    config,
    use_gpu=True,
    memory_monitor_cpu_threshold_mb=1500,  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    memory_monitor_gpu_threshold_mb=1000
)

# ì¶”ì • ì‹¤í–‰
results = estimator.estimate(...)

# ë©”ëª¨ë¦¬ ìš”ì•½ í™•ì¸
summary = estimator.memory_monitor.get_memory_summary()
print(f"ìµœëŒ€ CPU ë©”ëª¨ë¦¬: {summary['cpu_max_mb']:.1f}MB")
print(f"í‰ê·  CPU ë©”ëª¨ë¦¬: {summary['cpu_avg_mb']:.1f}MB")
```

---

## ğŸ“ ìš”ì•½

| ë°©ì•ˆ | êµ¬í˜„ ìƒíƒœ | íš¨ê³¼ | ì„±ëŠ¥ ì˜í–¥ |
|------|----------|------|----------|
| **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§** | âœ… ì™„ë£Œ | ê³¼ë¶€í•˜ ë°©ì§€ | ìµœì†Œ (~1%) |
| **ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜** | âœ… ì™„ë£Œ | ë©”ëª¨ë¦¬ ëˆ„ì  ë°©ì§€ | ì‘ìŒ (~2-3%) |
| **ë°°ì¹˜ í¬ê¸° ì¡°ì •** | â¸ï¸ ì„ íƒì  | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ | ì¤‘ê°„ (~5-10%) |
| **ëª…ì‹œì  ë°°ì—´ ì‚­ì œ** | â¸ï¸ ì„ íƒì  | ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ | ìµœì†Œ (~1%) |

**ê¶Œì¥ ì¡°í•©**: ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ + ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ (í˜„ì¬ êµ¬í˜„)

