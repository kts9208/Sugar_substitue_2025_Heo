#!/usr/bin/env python3
"""
5ê°œ ìš”ì¸ ê²½ë¡œë¶„ì„ ì‹¤í–‰ (ê°„ì†Œí™” ë²„ì „)
"""

import pandas as pd
import numpy as np
from datetime import datetime
from path_analysis import (
    PathAnalyzer,
    create_default_path_config,
    create_path_model
)

def run_comprehensive_analysis():
    """5ê°œ ìš”ì¸ ì¢…í•© ë¶„ì„"""
    print("ğŸ” 5ê°œ ìš”ì¸ ê²½ë¡œë¶„ì„ ì‹¤í–‰")
    print("=" * 60)
    print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # 1. ì¢…í•©ì ì¸ êµ¬ì¡°ëª¨ë¸ ì„¤ì •
        variables = ['health_concern', 'perceived_benefit', 'perceived_price', 
                    'nutrition_knowledge', 'purchase_intention']
        
        # ë³µí•©ì ì¸ ê²½ë¡œ ê´€ê³„ ì •ì˜
        paths = [
            ('health_concern', 'perceived_benefit'),      # ê±´ê°•ê´€ì‹¬ë„ -> ì§€ê°ëœí˜œíƒ
            ('health_concern', 'perceived_price'),        # ê±´ê°•ê´€ì‹¬ë„ -> ì§€ê°ëœê°€ê²©
            ('health_concern', 'nutrition_knowledge'),    # ê±´ê°•ê´€ì‹¬ë„ -> ì˜ì–‘ì§€ì‹
            ('nutrition_knowledge', 'perceived_benefit'), # ì˜ì–‘ì§€ì‹ -> ì§€ê°ëœí˜œíƒ
            ('perceived_benefit', 'purchase_intention'),  # ì§€ê°ëœí˜œíƒ -> êµ¬ë§¤ì˜ë„
            ('perceived_price', 'purchase_intention'),    # ì§€ê°ëœê°€ê²© -> êµ¬ë§¤ì˜ë„
            ('nutrition_knowledge', 'purchase_intention'), # ì˜ì–‘ì§€ì‹ -> êµ¬ë§¤ì˜ë„
            ('health_concern', 'purchase_intention')      # ê±´ê°•ê´€ì‹¬ë„ -> êµ¬ë§¤ì˜ë„ (ì§ì ‘íš¨ê³¼)
        ]
        
        # ìƒê´€ê´€ê³„ ì„¤ì •
        correlations = [
            ('perceived_benefit', 'perceived_price'),     # ì§€ê°ëœí˜œíƒ <-> ì§€ê°ëœê°€ê²©
            ('perceived_benefit', 'nutrition_knowledge')  # ì§€ê°ëœí˜œíƒ <-> ì˜ì–‘ì§€ì‹
        ]
        
        # 2. ëª¨ë¸ ìŠ¤í™ ìƒì„±
        model_spec = create_path_model(
            model_type='custom',
            variables=variables,
            paths=paths,
            correlations=correlations
        )
        
        print("ì¢…í•©ì ì¸ êµ¬ì¡°ëª¨ë¸ ìŠ¤í™ ìƒì„± ì™„ë£Œ")
        print(f"í¬í•¨ëœ ë³€ìˆ˜: {len(variables)}ê°œ")
        print(f"ê²½ë¡œ ìˆ˜: {len(paths)}ê°œ")
        print(f"ìƒê´€ê´€ê³„: {len(correlations)}ê°œ")
        
        # 3. ë¶„ì„ ì‹¤í–‰
        config = create_default_path_config(
            standardized=True,
            verbose=True
        )
        
        analyzer = PathAnalyzer(config)
        data = analyzer.load_data(variables)
        print(f"\në°ì´í„° ë¡œë“œ ì™„ë£Œ: {data.shape}")
        
        results = analyzer.fit_model(model_spec, data)
        print(f"ëª¨ë¸ ì í•© ì™„ë£Œ!")
        print(f"ê´€ì¸¡ì¹˜ ìˆ˜: {results['model_info']['n_observations']}")
        print(f"ë³€ìˆ˜ ìˆ˜: {results['model_info']['n_variables']}")
        
        # 4. ì í•©ë„ ì§€ìˆ˜ ì¶œë ¥
        if 'fit_indices' in results and results['fit_indices']:
            print("\n=== ì í•©ë„ ì§€ìˆ˜ ===")
            for index, value in results['fit_indices'].items():
                try:
                    if hasattr(value, 'iloc'):
                        numeric_value = value.iloc[0] if len(value) > 0 else np.nan
                    else:
                        numeric_value = value
                    
                    if isinstance(numeric_value, (int, float)) and not pd.isna(numeric_value):
                        interpretation = interpret_fit_index(index, numeric_value)
                        print(f"  {index}: {numeric_value:.4f} ({interpretation})")
                except:
                    print(f"  {index}: {value}")
        
        # 5. ì£¼ìš” ê²½ë¡œê³„ìˆ˜ ì¶œë ¥ (êµ¬ë§¤ì˜ë„ì— ëŒ€í•œ ì§ì ‘íš¨ê³¼ë§Œ)
        print("\n=== êµ¬ë§¤ì˜ë„ì— ëŒ€í•œ ì§ì ‘íš¨ê³¼ ===")
        if 'path_coefficients' in results and results['path_coefficients']:
            path_coeffs = results['path_coefficients']
            if 'paths' in path_coeffs and path_coeffs['paths']:
                for i, (from_var, to_var) in enumerate(path_coeffs['paths']):
                    if to_var == 'purchase_intention':
                        coeff = path_coeffs.get('coefficients', {}).get(i, 0)
                        print(f"  {from_var} -> {to_var}: {coeff:.4f}")
        
        # 6. ê°„ë‹¨í•œ ê²°ê³¼ ì €ì¥
        save_simple_results(results, variables, paths)
        
        return results
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

def interpret_fit_index(index_name: str, value: float) -> str:
    """ì í•©ë„ ì§€ìˆ˜ í•´ì„"""
    if pd.isna(value):
        return "N/A"
    
    if index_name == 'cfi' or index_name == 'tli':
        if value > 0.95:
            return "ìš°ìˆ˜"
        elif value > 0.90:
            return "ìˆ˜ìš©ê°€ëŠ¥"
        else:
            return "ë¶€ì¡±"
    elif index_name == 'rmsea':
        if value < 0.06:
            return "ìš°ìˆ˜"
        elif value < 0.08:
            return "ìˆ˜ìš©ê°€ëŠ¥"
        else:
            return "ë¶€ì¡±"
    elif index_name == 'srmr':
        if value < 0.08:
            return "ìš°ìˆ˜"
        elif value < 0.10:
            return "ìˆ˜ìš©ê°€ëŠ¥"
        else:
            return "ë¶€ì¡±"
    elif index_name == 'p_value':
        if value > 0.05:
            return "ì¢‹ìŒ (ë¹„ìœ ì˜ì )"
        else:
            return "ë‚˜ì¨ (ìœ ì˜ì )"
    
    return ""

def save_simple_results(results, variables, paths):
    """ê°„ë‹¨í•œ ê²°ê³¼ ì €ì¥"""
    try:
        from pathlib import Path
        output_dir = Path("path_analysis_results")
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ëª¨ë¸ ì •ë³´ ì €ì¥
        model_info = {
            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'variables': variables,
            'paths': [f"{from_var} -> {to_var}" for from_var, to_var in paths],
            'n_observations': results['model_info']['n_observations'],
            'n_variables': results['model_info']['n_variables']
        }
        
        model_file = output_dir / f"5factor_model_info_{timestamp}.txt"
        with open(model_file, 'w', encoding='utf-8') as f:
            f.write("5ê°œ ìš”ì¸ ê²½ë¡œë¶„ì„ ê²°ê³¼\n")
            f.write("=" * 40 + "\n")
            f.write(f"ë¶„ì„ ì¼ì‹œ: {model_info['analysis_date']}\n")
            f.write(f"ê´€ì¸¡ì¹˜ ìˆ˜: {model_info['n_observations']}\n")
            f.write(f"ë³€ìˆ˜ ìˆ˜: {model_info['n_variables']}\n\n")
            
            f.write("í¬í•¨ëœ ë³€ìˆ˜:\n")
            for var in model_info['variables']:
                f.write(f"  - {var}\n")
            
            f.write("\nê²½ë¡œ ê´€ê³„:\n")
            for path in model_info['paths']:
                f.write(f"  - {path}\n")
        
        # 2. ì í•©ë„ ì§€ìˆ˜ ì €ì¥
        if 'fit_indices' in results and results['fit_indices']:
            fit_file = output_dir / f"5factor_fit_indices_{timestamp}.txt"
            with open(fit_file, 'w', encoding='utf-8') as f:
                f.write("ì í•©ë„ ì§€ìˆ˜\n")
                f.write("=" * 20 + "\n")
                for index, value in results['fit_indices'].items():
                    try:
                        if hasattr(value, 'iloc'):
                            numeric_value = value.iloc[0] if len(value) > 0 else np.nan
                        else:
                            numeric_value = value
                        
                        if isinstance(numeric_value, (int, float)) and not pd.isna(numeric_value):
                            interpretation = interpret_fit_index(index, numeric_value)
                            f.write(f"{index}: {numeric_value:.4f} ({interpretation})\n")
                    except:
                        f.write(f"{index}: {value}\n")
        
        # 3. ê²½ë¡œê³„ìˆ˜ ì €ì¥
        if 'path_coefficients' in results and results['path_coefficients']:
            coeff_file = output_dir / f"5factor_path_coefficients_{timestamp}.txt"
            with open(coeff_file, 'w', encoding='utf-8') as f:
                f.write("ê²½ë¡œê³„ìˆ˜\n")
                f.write("=" * 20 + "\n")
                path_coeffs = results['path_coefficients']
                if 'paths' in path_coeffs and path_coeffs['paths']:
                    for i, (from_var, to_var) in enumerate(path_coeffs['paths']):
                        coeff = path_coeffs.get('coefficients', {}).get(i, 0)
                        f.write(f"{from_var} -> {to_var}: {coeff:.4f}\n")
        
        print(f"\nê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
        print(f"  - {model_file}")
        print(f"  - {fit_file}")
        print(f"  - {coeff_file}")
        
    except Exception as e:
        print(f"ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    results = run_comprehensive_analysis()
    
    if results:
        print("\n" + "=" * 60)
        print("ğŸ“Š 5ê°œ ìš”ì¸ ê²½ë¡œë¶„ì„ ì™„ë£Œ!")
        print("=" * 60)
        print("âœ… ëª¨ë¸ ì¶”ì • ì„±ê³µ")
        print("âœ… ì í•©ë„ ì§€ìˆ˜ ê³„ì‚° ì™„ë£Œ")
        print("âœ… ê²½ë¡œê³„ìˆ˜ ì¶”ì¶œ ì™„ë£Œ")
        print("âœ… ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        print("\nê²°ê³¼ íŒŒì¼ë“¤ì´ 'path_analysis_results' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ë¶„ì„ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
