# GPU ë³‘ë ¬í™” ì˜¤ë¥˜ êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“Œ í˜„ì¬ ë°œìƒí•œ ì˜¤ë¥˜

```
KeyError: 'lambda_health_concern'
```

**ë°œìƒ ìœ„ì¹˜**: `parameter_manager.py:353` in `dict_to_array()`
- `param_array.append(param_dict['choice'][name])`ì—ì„œ `lambda_health_concern` í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ

---

## ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„

### 1. **ë¬¸ì œì˜ í•µì‹¬: CPU ëª¨ë“œë¡œ ì‹¤í–‰ë¨**

GPU ë³‘ë ¬í™”ê°€ í™œì„±í™”ë˜ì§€ ì•Šê³  CPU ëª¨ë“œë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.

**ì¦ê±°**:
- ë¡œê·¸ì— "GPU ë³‘ë ¬í™” ìƒíƒœ í™•ì¸" ë©”ì‹œì§€ê°€ ì—†ìŒ
- CPU gradient calculatorê°€ ì‚¬ìš©ë¨
- CPU gradientëŠ” `all_lvs_as_main` ëª¨ë¸ì„ ì§€ì›í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ë‹¨ì¼ `grad_lambda`ë§Œ ë°˜í™˜

### 2. **CPU vs GPU Gradient ë°˜í™˜ êµ¬ì¡° ì°¨ì´**

#### GPU Gradient (`gpu_gradient_batch.py:1673-1679`)
```python
if all_lvs_as_main:
    for lv_name in lambda_lvs.keys():
        gradients[f'grad_lambda_{lv_name}'] = ...
```
**ë°˜í™˜**: `{'grad_lambda_health_concern': ..., 'grad_lambda_perceived_benefit': ..., ...}`

#### CPU Gradient (`gradient_calculator.py:421-429`)
```python
result = {'grad_intercept': ..., 'grad_beta': ...}
for lv_name in lv.keys():
    result[f'grad_lambda_{lv_name}'] = grad_lambda[lv_name]
return result
```
**ë°˜í™˜**: `{'grad_lambda_health_concern': ..., 'grad_lambda_perceived_benefit': ..., ...}`

**ê²°ë¡ **: CPU gradientë„ ì˜¬ë°”ë¥¸ í˜•ì‹ì„ ë°˜í™˜í•©ë‹ˆë‹¤!

---

## ğŸš¨ **ì‹¤ì œ ë¬¸ì œ: ì´ˆê¸°í™” ìˆœì„œ ì˜¤ë¥˜**

### ë¬¸ì œ ë°œìƒ íë¦„

```
1. SimultaneousGPUBatchEstimator.__init__()
   â”œâ”€ self.use_gpu = True
   â””â”€ self.gpu_measurement_model = None  âŒ

2. SimultaneousEstimator.__init__()
   â””â”€ (joint_grad ì´ˆê¸°í™” ì•ˆ í•¨)

3. SimultaneousGPUBatchEstimator.estimate()
   â”œâ”€ self.gpu_measurement_model = GPUMultiLatentMeasurement(...)  âœ…
   â””â”€ super().estimate()

4. SimultaneousEstimator.estimate()
   â”œâ”€ joint_grad ì´ˆê¸°í™” (line 360-434)
   â”‚  â”œâ”€ use_gpu_gradient = self.use_gpu and self.gpu_measurement_model is not None
   â”‚  â”‚  â””â”€ âœ… True (gpu_measurement_modelì´ 3ë²ˆì—ì„œ ìƒì„±ë¨)
   â”‚  â””â”€ MultiLatentJointGradient(use_gpu=True, gpu_measurement_model=...)
   â”‚
   â””â”€ gradient ê³„ì‚° ì‹œì‘

5. _compute_gradient() í˜¸ì¶œ
   â”œâ”€ use_gpu = hasattr(self.joint_grad, 'use_gpu') and self.joint_grad.use_gpu
   â”‚  â””â”€ âœ… True
   â”œâ”€ hasattr(self.joint_grad, 'compute_all_individuals_gradients_full_batch')
   â”‚  â””â”€ âœ… True
   â””â”€ GPU Batch ëª¨ë“œ ì‹¤í–‰ âœ…
```

**ì´ë¡ ì ìœ¼ë¡œëŠ” GPU ëª¨ë“œê°€ í™œì„±í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤!**

---

## ğŸ” **ì‹¤ì œ ì˜¤ë¥˜ ì›ì¸ ì¶”ì **

ë¡œê·¸ë¥¼ ë‹¤ì‹œ í™•ì¸í•œ ê²°ê³¼:
- "GPU ë°°ì¹˜ ê·¸ë˜ë””ì–¸íŠ¸ í™œì„±í™”" ë©”ì‹œì§€ê°€ ì¶œë ¥ë¨ (line 418)
- í•˜ì§€ë§Œ "GPU ë³‘ë ¬í™” ìƒíƒœ í™•ì¸" ë©”ì‹œì§€ê°€ ì—†ìŒ

**ê°€ëŠ¥í•œ ì›ì¸**:
1. `_compute_gradient` ë©”ì„œë“œê°€ í˜¸ì¶œë˜ì§€ ì•ŠìŒ
2. ë˜ëŠ” ë‹¤ë¥¸ ê²½ë¡œë¡œ gradientê°€ ê³„ì‚°ë¨

### ì˜ì‹¬ ì§€ì : `compute_individual_gradient` vs `compute_all_individuals_gradients_full_batch`

`_compute_gradient`ì—ì„œ ë‘ ê°€ì§€ ê²½ë¡œê°€ ìˆìŠµë‹ˆë‹¤:

#### ê²½ë¡œ A: GPU Batch (line 2067-2121)
```python
if use_gpu and hasattr(self.joint_grad, 'compute_all_individuals_gradients_full_batch'):
    all_grad_dicts = self.joint_grad.compute_all_individuals_gradients_full_batch(...)
```

#### ê²½ë¡œ B: CPU ìˆœì°¨ (line 2123-2163)
```python
else:
    for ind_id in individual_ids:
        ind_grad = self.joint_grad.compute_individual_gradient(...)
```

**ë¬¸ì œ**: `compute_individual_gradient`ê°€ í˜¸ì¶œë˜ë©´ CPU ëª¨ë“œë¡œ ì‹¤í–‰ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

---

## ğŸ› **ì˜¤ë¥˜ê°€ ë°œìƒí•˜ê¸° ì‰¬ìš´ êµ¬ì¡°ì  ë¬¸ì œì **

### 1. **ë‹¤ì¸µ ì¡°ê±´ ë¶„ê¸° (Nested Conditionals)**

```python
if is_multi_latent:
    use_gpu = hasattr(self.joint_grad, 'use_gpu') and self.joint_grad.use_gpu
    
    if use_gpu and hasattr(self.joint_grad, 'compute_all_individuals_gradients_full_batch'):
        # GPU Batch
    else:
        # CPU ìˆœì°¨
        for ind_id in individual_ids:
            ind_grad = self.joint_grad.compute_individual_gradient(...)
            # âš ï¸ ì´ ë©”ì„œë“œ ë‚´ë¶€ì—ì„œë„ GPU/CPU ë¶„ê¸°ê°€ ìˆìŒ!
```

**ë¬¸ì œì **:
- 3ë‹¨ê³„ ì¡°ê±´ ë¶„ê¸° (is_multi_latent â†’ use_gpu â†’ compute_individual_gradient ë‚´ë¶€)
- ê° ë‹¨ê³„ì—ì„œ GPU/CPU ëª¨ë“œê°€ ê²°ì •ë¨
- ì¼ê´€ì„± ë³´ì¥ì´ ì–´ë ¤ì›€

### 2. **ì¤‘ë³µëœ GPU/CPU ë¶„ê¸° ë¡œì§**

GPU/CPU ë¶„ê¸°ê°€ ì—¬ëŸ¬ ê³³ì— ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

1. `SimultaneousEstimator._compute_gradient` (line 2050-2179)
2. `MultiLatentJointGradient.compute_individual_gradient` (line 438-447)
3. `MultiLatentJointGradient.compute_all_individuals_gradients_batch` (line 478-510)
4. `MultiLatentJointGradient.compute_all_individuals_gradients_full_batch` (line 547-585)

**ë¬¸ì œì **:
- ê° ë©”ì„œë“œë§ˆë‹¤ `self.use_gpu and self.gpu_measurement_model is not None` ì²´í¬
- ì¡°ê±´ì´ í•˜ë‚˜ë¼ë„ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ ê²½ë¡œë¡œ ì‹¤í–‰ë¨
- ë””ë²„ê¹…ì´ ë§¤ìš° ì–´ë ¤ì›€

### 3. **Gradient ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° ë¶ˆì¼ì¹˜ ê°€ëŠ¥ì„±**

Gradient ë³€í™˜ ê³¼ì •:
```
GPU/CPU Gradient Calculator
  â†“ (ë°˜í™˜)
{'choice': {'grad_lambda_health_concern': ..., 'grad_lambda_perceived_benefit': ...}}
  â†“ (_convert_grad_dict_to_param_style)
{'choice': {'lambda_health_concern': ..., 'lambda_perceived_benefit': ...}}
  â†“ (ParameterManager.dict_to_array)
[..., lambda_health_concern, lambda_perceived_benefit, ...]
```

**ë¬¸ì œì **:
- `_convert_grad_dict_to_param_style`ëŠ” ë‹¨ìˆœíˆ `grad_` ì ‘ë‘ì‚¬ë§Œ ì œê±°
- GPUì™€ CPUê°€ ë‹¤ë¥¸ í‚¤ë¥¼ ë°˜í™˜í•˜ë©´ ë³€í™˜ ì‹¤íŒ¨
- ì˜ˆ: GPUê°€ `grad_lambda`ë¥¼ ë°˜í™˜í•˜ë©´ â†’ `lambda`ë¡œ ë³€í™˜ â†’ `lambda_health_concern`ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ

### 4. **ì•”ë¬µì  ì˜ì¡´ì„± (Implicit Dependencies)**

`ParameterManager.dict_to_array`ëŠ” `param_names`ì— ìˆëŠ” ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ `param_dict`ì— ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.

```python
# parameter_manager.py:352-353
elif name.startswith('lambda_'):
    param_array.append(param_dict['choice'][name])  # âŒ KeyError ë°œìƒ ê°€ëŠ¥
```

**ë¬¸ì œì **:
- ë°©ì–´ì  í”„ë¡œê·¸ë˜ë° ë¶€ì¬ (í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì—†ìŒ)
- ì—ëŸ¬ ë©”ì‹œì§€ê°€ ë¶ˆëª…í™• (ì–´ë–¤ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆëŠ”ì§€ ì•Œê¸° ì–´ë ¤ì›€)
- Gradient ê³„ì‚°ê³¼ Parameter ê´€ë¦¬ê°€ ê°•í•˜ê²Œ ê²°í•©ë¨

### 5. **ë¡œê¹… ë¶ˆì¼ì¹˜**

```python
# Line 2068-2100: self.logger ì‚¬ìš©
self.logger.info("ğŸš€ GPU ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ í™œì„±í™”")

# Line 2055-2064: self.iteration_logger ì‚¬ìš©
self.iteration_logger.info("GPU ë³‘ë ¬í™” ìƒíƒœ í™•ì¸")
```

**ë¬¸ì œì **:
- ê°™ì€ ë©”ì„œë“œ ë‚´ì—ì„œ ë‘ ê°€ì§€ logger í˜¼ìš©
- `self.logger`ëŠ” ì½˜ì†”ì—ë§Œ ì¶œë ¥, `self.iteration_logger`ëŠ” íŒŒì¼ì— ê¸°ë¡
- ë””ë²„ê¹… ì‹œ ë¡œê·¸ íŒŒì¼ë§Œ ë³´ë©´ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë†“ì¹  ìˆ˜ ìˆìŒ

---

## ğŸ’¡ **êµ¬ì¡°ì  ê°œì„  ë°©ì•ˆ**

### ë°©ì•ˆ 1: **ë‹¨ì¼ ì§„ì…ì  íŒ¨í„´ (Single Entry Point)**

í˜„ì¬:
```python
if use_gpu and hasattr(...):
    all_grad_dicts = self.joint_grad.compute_all_individuals_gradients_full_batch(...)
else:
    for ind_id in individual_ids:
        ind_grad = self.joint_grad.compute_individual_gradient(...)
```

ê°œì„ :
```python
# joint_gradê°€ ë‚´ë¶€ì—ì„œ GPU/CPU ê²°ì •
all_grad_dicts = self.joint_grad.compute_gradients(
    all_ind_data, all_ind_draws, params_dict, ...
)
```

**ì¥ì **:
- ì¡°ê±´ ë¶„ê¸°ë¥¼ í•œ ê³³ìœ¼ë¡œ ì§‘ì¤‘
- í˜¸ì¶œìëŠ” GPU/CPU ì—¬ë¶€ë¥¼ ì‹ ê²½ ì“°ì§€ ì•ŠìŒ
- í…ŒìŠ¤íŠ¸ ìš©ì´

### ë°©ì•ˆ 2: **Gradient ë”•ì…”ë„ˆë¦¬ ê²€ì¦ ë ˆì´ì–´**

```python
def _validate_gradient_dict(self, grad_dict: Dict, param_names: List[str]) -> None:
    """Gradient ë”•ì…”ë„ˆë¦¬ê°€ ëª¨ë“  í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•˜ëŠ”ì§€ ê²€ì¦"""
    missing_params = []

    for name in param_names:
        if name.startswith('lambda_'):
            if name not in grad_dict['choice']:
                missing_params.append(name)

    if missing_params:
        available_keys = list(grad_dict['choice'].keys())
        raise ValueError(
            f"Gradient ë”•ì…”ë„ˆë¦¬ì— í•„ìš”í•œ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
            f"  ëˆ„ë½ëœ íŒŒë¼ë¯¸í„°: {missing_params}\n"
            f"  ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {available_keys}"
        )
```

**ì¥ì **:
- ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
- ë¬¸ì œ ë°œìƒ ì§€ì ì„ ë¹ ë¥´ê²Œ íŒŒì•…
- ë°©ì–´ì  í”„ë¡œê·¸ë˜ë°

### ë°©ì•ˆ 3: **GPU ëª¨ë“œ ìƒíƒœ ê°ì²´**

```python
@dataclass
class GPUComputeState:
    """GPU ê³„ì‚° ìƒíƒœë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê´€ë¦¬"""
    enabled: bool
    measurement_model: Optional[Any]
    full_parallel: bool

    def is_ready(self) -> bool:
        """GPU ê³„ì‚°ì´ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸"""
        return self.enabled and self.measurement_model is not None

    def get_mode_name(self) -> str:
        """í˜„ì¬ ëª¨ë“œ ì´ë¦„ ë°˜í™˜"""
        if not self.enabled:
            return "CPU"
        if not self.measurement_model:
            return "CPU (GPU ëª¨ë¸ ì—†ìŒ)"
        if self.full_parallel:
            return "GPU (ì™„ì „ ë³‘ë ¬)"
        return "GPU (ë°°ì¹˜)"
```

**ì¥ì **:
- GPU ìƒíƒœë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê´€ë¦¬
- ì¡°ê±´ ë¶„ê¸° ë¡œì§ ë‹¨ìˆœí™”
- ë¡œê¹… ì¼ê´€ì„± í–¥ìƒ

### ë°©ì•ˆ 4: **í†µí•© ë¡œê¹… ì „ëµ**

```python
def _log_gpu_status(self, state: GPUComputeState):
    """GPU ìƒíƒœë¥¼ ì¼ê´€ë˜ê²Œ ë¡œê¹…"""
    msg = f"Gradient ê³„ì‚° ëª¨ë“œ: {state.get_mode_name()}"

    # ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ê¸°ë¡
    self.logger.info(msg)
    self.iteration_logger.info(msg)

    # ìƒì„¸ ì •ë³´ëŠ” íŒŒì¼ì—ë§Œ
    self.iteration_logger.info(f"  enabled: {state.enabled}")
    self.iteration_logger.info(f"  measurement_model: {state.measurement_model is not None}")
    self.iteration_logger.info(f"  full_parallel: {state.full_parallel}")
```

**ì¥ì **:
- ë¡œê¹… ì¼ê´€ì„±
- ë””ë²„ê¹… ìš©ì´
- ì¤‘ìš”í•œ ì •ë³´ ëˆ„ë½ ë°©ì§€

---

## ğŸ¯ **ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì • ì‚¬í•­**

### 1. **ë°©ì–´ì  í”„ë¡œê·¸ë˜ë° ì¶”ê°€**

`parameter_manager.py:352-353` ìˆ˜ì •:
```python
elif name.startswith('lambda_'):
    if name not in param_dict['choice']:
        raise KeyError(
            f"Gradient ë”•ì…”ë„ˆë¦¬ì— '{name}' íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
            f"ì‚¬ìš© ê°€ëŠ¥í•œ choice gradient í‚¤: {list(param_dict['choice'].keys())}"
        )
    param_array.append(param_dict['choice'][name])
```

### 2. **Gradient ë”•ì…”ë„ˆë¦¬ ë¡œê¹… ê°•í™”**

`_convert_grad_dict_to_param_style` ìˆ˜ì •:
```python
# ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ê¸°ë¡
self.logger.info(f"Choice gradient í‚¤: {list(grad_dict['choice'].keys())}")
self.iteration_logger.info(f"Choice gradient í‚¤: {list(grad_dict['choice'].keys())}")
```

### 3. **GPU ëª¨ë“œ í™•ì¸ ë¡œê¹… í†µì¼**

ëª¨ë“  GPU ê´€ë ¨ ë¡œê·¸ë¥¼ `iteration_logger`ë¡œ í†µì¼

---

## ğŸ“Š **í˜„ì¬ ìƒí™© ìš”ì•½**

| í•­ëª© | ìƒíƒœ | ë¹„ê³  |
|------|------|------|
| GPU ì´ˆê¸°í™” | âœ… ì •ìƒ | `gpu_measurement_model` ìƒì„±ë¨ |
| `joint_grad.use_gpu` | âœ… True | GPU ëª¨ë“œ í™œì„±í™” |
| Gradient ê³„ì‚° ê²½ë¡œ | â“ ë¶ˆëª…í™• | ë¡œê·¸ ë¶€ì¡±ìœ¼ë¡œ í™•ì¸ ë¶ˆê°€ |
| Gradient ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° | âŒ ì˜¤ë¥˜ | `lambda_health_concern` í‚¤ ì—†ìŒ |
| ì—ëŸ¬ ë°œìƒ ìœ„ì¹˜ | `parameter_manager.py:353` | `dict_to_array` |

**ë‹¤ìŒ ë‹¨ê³„**:
1. ë¡œê¹… ê°•í™”í•˜ì—¬ ì‹¤ì œ ì‹¤í–‰ ê²½ë¡œ í™•ì¸
2. Gradient ë”•ì…”ë„ˆë¦¬ êµ¬ì¡° ê²€ì¦
3. CPU/GPU ë¶„ê¸° ë¡œì§ ë‹¨ìˆœí™”


