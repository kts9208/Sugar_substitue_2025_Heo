#!/usr/bin/env python3
"""
semopyë¥¼ ì´ìš©í•œ ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ ë° pê°’ ì¶”ì¶œ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë‹¤ìŒ ê¸°ëŠ¥ë§Œ ì œê³µí•©ë‹ˆë‹¤:
1. 5ê°œ ìš”ì¸ ë°ì´í„° ë¡œë“œ
2. semopyë¥¼ ì´ìš©í•œ ìƒê´€ê³„ìˆ˜ ë° pê°’ ì¶”ì¶œ
3. ê²°ê³¼ ì €ì¥

Author: Sugar Substitute Research Team
Date: 2025-01-06
"""

import pandas as pd
import numpy as np
import json
from datetime import datetime
from pathlib import Path
import logging

# semopy ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import semopy
    from semopy import Model
    SEMOPY_AVAILABLE = True
except ImportError:
    SEMOPY_AVAILABLE = False
    print("Warning: semopy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SemopyCorrelationExtractor:
    """semopyë¥¼ ì´ìš©í•œ ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ ë° pê°’ ì¶”ì¶œê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        if not SEMOPY_AVAILABLE:
            raise ImportError("semopy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install semopyë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    
    def load_survey_data(self):
        """5ê°œ ìš”ì¸ì˜ ì„¤ë¬¸ ë°ì´í„° ë¡œë“œ"""
        logger.info("ì„¤ë¬¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        survey_data_dir = Path("processed_data/survey_data")
        
        # 5ê°œ ìš”ì¸ íŒŒì¼ ì •ì˜
        factor_files = {
            'health_concern': 'health_concern.csv',
            'perceived_benefit': 'perceived_benefit.csv', 
            'purchase_intention': 'purchase_intention.csv',
            'perceived_price': 'perceived_price.csv',
            'nutrition_knowledge': 'nutrition_knowledge.csv'
        }
        
        # ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ê²°í•©
        combined_data = pd.DataFrame()
        
        for factor_name, file_name in factor_files.items():
            file_path = survey_data_dir / file_name
            if file_path.exists():
                data = pd.read_csv(file_path)
                
                # 'no' ì»¬ëŸ¼ ì œì™¸í•˜ê³  ë¬¸í•­ ì»¬ëŸ¼ë§Œ ì¶”ê°€
                item_columns = [col for col in data.columns if col != 'no']
                for col in item_columns:
                    combined_data[col] = data[col]
                
                logger.info(f"{factor_name} ë°ì´í„° ë¡œë“œ: {data.shape}")
            else:
                logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        logger.info(f"ì „ì²´ ê²°í•© ë°ì´í„° í¬ê¸°: {combined_data.shape}")
        return combined_data
    
    def create_semopy_model(self):
        """semopy ëª¨ë¸ ì •ì˜ (ë™ì  ìƒì„±)"""
        # ì‹¤ì œ ë°ì´í„°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸í•­ë“¤ì„ í™•ì¸
        survey_data_dir = Path("processed_data/survey_data")

        # ê° ìš”ì¸ë³„ ì‹¤ì œ ë¬¸í•­ í™•ì¸
        factor_items = {}

        factor_files = {
            'health_concern': 'health_concern.csv',
            'perceived_benefit': 'perceived_benefit.csv',
            'purchase_intention': 'purchase_intention.csv',
            'perceived_price': 'perceived_price.csv',
            'nutrition_knowledge': 'nutrition_knowledge.csv'
        }

        for factor_name, filename in factor_files.items():
            file_path = survey_data_dir / filename
            if file_path.exists():
                import pandas as pd
                data = pd.read_csv(file_path)
                items = [col for col in data.columns if col.startswith('q')]
                factor_items[factor_name] = items

        # ë™ì  ëª¨ë¸ ìƒì„±
        model_lines = []

        if 'health_concern' in factor_items:
            items = " + ".join(factor_items['health_concern'])
            model_lines.append(f"health_concern =~ {items}")

        if 'perceived_benefit' in factor_items:
            items = " + ".join(factor_items['perceived_benefit'])
            model_lines.append(f"perceived_benefit =~ {items}")

        if 'purchase_intention' in factor_items:
            items = " + ".join(factor_items['purchase_intention'])
            model_lines.append(f"purchase_intention =~ {items}")

        if 'perceived_price' in factor_items:
            items = " + ".join(factor_items['perceived_price'])
            model_lines.append(f"perceived_price =~ {items}")

        if 'nutrition_knowledge' in factor_items:
            items = " + ".join(factor_items['nutrition_knowledge'])
            model_lines.append(f"nutrition_knowledge =~ {items}")

        model_desc = "\n".join(model_lines)
        return model_desc
    
    def extract_correlations_and_pvalues(self, data):
        """semopyë¥¼ ì´ìš©í•œ ìƒê´€ê³„ìˆ˜ ë° pê°’ ì¶”ì¶œ"""
        logger.info("semopy ëª¨ë¸ ìƒì„± ë° ì í•© ì¤‘...")
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        clean_data = data.dropna()
        logger.info(f"ì‚¬ìš©ëœ ê´€ì¸¡ì¹˜ ìˆ˜: {len(clean_data)}")
        
        # ëª¨ë¸ ìƒì„± ë° ì í•©
        model_desc = self.create_semopy_model()
        model = Model(model_desc)
        model.fit(clean_data)
        
        logger.info("ëª¨ë¸ ì í•© ì™„ë£Œ")
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        params = model.inspect(std_est=True)
        
        # ìš”ì¸ê°„ ê³µë¶„ì‚° íŒŒë¼ë¯¸í„° í•„í„°ë§
        factor_covs = params[params['op'] == '~~'].copy()
        
        # ìš”ì¸ ì´ë¦„ ì •ì˜
        factor_names = ['health_concern', 'perceived_benefit', 'purchase_intention', 
                       'perceived_price', 'nutrition_knowledge']
        
        # ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ë§Œ í•„í„°ë§
        factor_correlations = factor_covs[
            (factor_covs['lval'].isin(factor_names)) &
            (factor_covs['rval'].isin(factor_names))
        ].copy()
        
        # ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        correlation_matrix = self._build_correlation_matrix(factor_correlations, factor_names)
        
        # pê°’ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        p_value_matrix = self._build_p_value_matrix(factor_correlations, factor_names)
        
        logger.info(f"ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ ì¶”ì¶œ ì™„ë£Œ: {len(factor_names)}ê°œ ìš”ì¸")
        
        return correlation_matrix, p_value_matrix
    
    def _build_correlation_matrix(self, factor_correlations, factor_names):
        """ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±"""
        correlation_matrix = pd.DataFrame(
            index=factor_names, 
            columns=factor_names,
            dtype=float
        )
        
        # ëŒ€ê°ì„  ìš”ì†Œ (ìê¸° ìì‹ ê³¼ì˜ ìƒê´€ê³„ìˆ˜ = 1.0)
        for factor in factor_names:
            correlation_matrix.loc[factor, factor] = 1.0
        
        # ë¹„ëŒ€ê°ì„  ìš”ì†Œ (ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜)
        for _, row in factor_correlations.iterrows():
            lval, rval = row['lval'], row['rval']
            
            if lval != rval and lval in factor_names and rval in factor_names:
                # í‘œì¤€í™”ëœ ì¶”ì •ê°’ ì‚¬ìš© (ìƒê´€ê³„ìˆ˜)
                corr_value = row['Est. Std']
                
                # ëŒ€ì¹­ ë§¤íŠ¸ë¦­ìŠ¤
                correlation_matrix.loc[lval, rval] = corr_value
                correlation_matrix.loc[rval, lval] = corr_value
        
        return correlation_matrix
    
    def _build_p_value_matrix(self, factor_correlations, factor_names):
        """pê°’ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±"""
        p_value_matrix = pd.DataFrame(
            index=factor_names,
            columns=factor_names,
            dtype=float
        )
        
        # ëŒ€ê°ì„  ìš”ì†Œ (ìê¸° ìì‹ ê³¼ì˜ ìƒê´€ê³„ìˆ˜ pê°’ = 0.0)
        for factor in factor_names:
            p_value_matrix.loc[factor, factor] = 0.0
        
        # ë¹„ëŒ€ê°ì„  ìš”ì†Œ (ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ì˜ pê°’)
        for _, row in factor_correlations.iterrows():
            lval, rval = row['lval'], row['rval']
            
            if lval != rval and lval in factor_names and rval in factor_names:
                # pê°’ ì¶”ì¶œ
                p_value = row['p-value']
                
                # ëŒ€ì¹­ ë§¤íŠ¸ë¦­ìŠ¤
                p_value_matrix.loc[lval, rval] = p_value
                p_value_matrix.loc[rval, lval] = p_value
        
        return p_value_matrix
    
    def save_results(self, correlation_matrix, p_value_matrix):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = Path("factor_correlations_results")
        results_dir.mkdir(exist_ok=True)
        
        logger.info("ê²°ê³¼ ì €ì¥ ì¤‘...")
        
        # 1. ìƒê´€ê³„ìˆ˜ CSV ì €ì¥
        corr_file = results_dir / f"semopy_correlations_{timestamp}.csv"
        correlation_matrix.to_csv(corr_file, encoding='utf-8-sig')
        logger.info(f"ìƒê´€ê³„ìˆ˜ ì €ì¥: {corr_file}")
        
        # 2. pê°’ CSV ì €ì¥
        pval_file = results_dir / f"semopy_pvalues_{timestamp}.csv"
        p_value_matrix.to_csv(pval_file, encoding='utf-8-sig')
        logger.info(f"pê°’ ì €ì¥: {pval_file}")
        
        # 3. JSON ê²°ê³¼ ì €ì¥
        json_data = {
            'timestamp': timestamp,
            'analysis_type': 'semopy_factor_correlations',
            'correlations': correlation_matrix.to_dict(),
            'p_values': p_value_matrix.to_dict(),
            'significant_correlations': self._identify_significant_correlations(
                correlation_matrix, p_value_matrix
            ),
            'summary_statistics': {
                'n_factors': len(correlation_matrix),
                'n_significant_correlations': self._count_significant_correlations(p_value_matrix),
                'max_correlation': float(correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].max()),
                'min_correlation': float(correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].min()),
                'mean_correlation': float(correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean())
            }
        }
        
        json_file = results_dir / f"semopy_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        logger.info(f"JSON ê²°ê³¼ ì €ì¥: {json_file}")
        
        return {
            'correlation_file': corr_file,
            'pvalue_file': pval_file,
            'json_file': json_file,
            'timestamp': timestamp
        }
    
    def _identify_significant_correlations(self, correlation_matrix, p_value_matrix):
        """ìœ ì˜í•œ ìƒê´€ê´€ê³„ ì‹ë³„"""
        significant_pairs = []
        factor_names = correlation_matrix.index.tolist()
        
        for i in range(len(factor_names)):
            for j in range(i+1, len(factor_names)):
                factor1 = factor_names[i]
                factor2 = factor_names[j]
                corr_val = correlation_matrix.iloc[i, j]
                p_val = p_value_matrix.iloc[i, j]
                
                if p_val < 0.05:
                    significant_pairs.append({
                        'factor1': factor1,
                        'factor2': factor2,
                        'correlation': float(corr_val),
                        'p_value': float(p_val),
                        'significance_level': '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*'
                    })
        
        return significant_pairs
    
    def _count_significant_correlations(self, p_value_matrix):
        """ìœ ì˜í•œ ìƒê´€ê´€ê³„ ê°œìˆ˜ ê³„ì‚°"""
        upper_triangle = np.triu(p_value_matrix.values, k=1)
        return int((upper_triangle < 0.05).sum())
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        logger.info("=== semopy ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ ë¶„ì„ ì‹œì‘ ===")
        
        try:
            # 1. ë°ì´í„° ë¡œë“œ
            data = self.load_survey_data()
            
            # 2. ìƒê´€ê³„ìˆ˜ ë° pê°’ ì¶”ì¶œ
            correlation_matrix, p_value_matrix = self.extract_correlations_and_pvalues(data)
            
            # 3. ê²°ê³¼ ì €ì¥
            file_info = self.save_results(correlation_matrix, p_value_matrix)
            
            # 4. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            self._print_summary(correlation_matrix, p_value_matrix)
            
            logger.info("=== ë¶„ì„ ì™„ë£Œ ===")
            return file_info
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def _print_summary(self, correlation_matrix, p_value_matrix):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ“Š semopy ìš”ì¸ê°„ ìƒê´€ê³„ìˆ˜ ë¶„ì„ ê²°ê³¼")
        print("="*60)
        
        print(f"\nìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤:")
        print(correlation_matrix.round(4))
        
        print(f"\npê°’ ë§¤íŠ¸ë¦­ìŠ¤:")
        print(p_value_matrix.round(4))
        
        # ìœ ì˜í•œ ìƒê´€ê´€ê³„ ì¶œë ¥
        significant_pairs = self._identify_significant_correlations(correlation_matrix, p_value_matrix)
        
        print(f"\nğŸ“ˆ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ìƒê´€ê´€ê³„ (p < 0.05): {len(significant_pairs)}ê°œ")
        for pair in sorted(significant_pairs, key=lambda x: abs(x['correlation']), reverse=True):
            print(f"  {pair['factor1']} â†” {pair['factor2']}: "
                  f"r = {pair['correlation']:+.4f} {pair['significance_level']} "
                  f"(p = {pair['p_value']:.6f})")
        
        print("\nìœ ì˜ìˆ˜ì¤€: *** p<0.001, ** p<0.01, * p<0.05")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        extractor = SemopyCorrelationExtractor()
        file_info = extractor.run_analysis()
        
        print(f"\nğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
        print(f"  - ìƒê´€ê³„ìˆ˜: {file_info['correlation_file']}")
        print(f"  - pê°’: {file_info['pvalue_file']}")
        print(f"  - JSON ê²°ê³¼: {file_info['json_file']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
