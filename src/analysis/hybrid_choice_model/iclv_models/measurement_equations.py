"""
Ordered Probit Measurement Model for ICLV

ì´ ëª¨ë“ˆì€ King (2022)ì˜ Apollo R ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ 
Ordered Probit ì¸¡ì •ëª¨ë¸ì„ Pythonìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

Reference:
- King, A. M. (2022). Microplastics in seafood: Consumer risk perceptions and 
  willingness to pay. Food Quality and Preference, 102, 104650.
- Apollo R package: apollo_op() function for ordered probit
"""

import numpy as np
import pandas as pd
from scipy.stats import norm
from scipy.optimize import minimize
from typing import Dict, List, Optional, Any, Tuple, Union
import logging

logger = logging.getLogger(__name__)


class OrderedProbitMeasurement:
    """
    Ordered Probit ì¸¡ì •ëª¨ë¸
    
    ë¦¬ì»¤íŠ¸ ì²™ë„ ë°ì´í„°ë¥¼ ì˜¬ë°”ë¥´ê²Œ ëª¨ë¸ë§í•˜ëŠ” ì¸¡ì •ë°©ì •ì‹ì…ë‹ˆë‹¤.
    
    Model:
        P(Y_i = k) = Î¦(Ï„_k - Î¶*LV) - Î¦(Ï„_{k-1} - Î¶*LV)
    
    ì—¬ê¸°ì„œ:
        - Y_i: ê´€ì¸¡ì§€í‘œ (1, 2, 3, 4, 5 for 5-point Likert scale)
        - Ï„: ì„ê³„ê°’ (thresholds) - ë²”ì£¼ ê²½ê³„
        - Î¶: ìš”ì¸ì ì¬ëŸ‰ (factor loadings)
        - LV: ì ì¬ë³€ìˆ˜ (latent variable)
        - Î¦: í‘œì¤€ì •ê·œ ëˆ„ì ë¶„í¬í•¨ìˆ˜
    
    Apollo R ì½”ë“œ ëŒ€ì‘:
        op_settings = list(
            outcomeOrdered = Q13,
            V = zeta_Q13 * LV,
            tau = c(tau_Q13_1, tau_Q13_2, tau_Q13_3, tau_Q13_4),
            componentName = "indic_Q13"
        )
        P[["indic_Q13"]] = apollo_op(op_settings, functionality)
    """
    
    def __init__(self, config):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: MeasurementConfig ê°ì²´
                - indicators: ê´€ì¸¡ì§€í‘œ ë¦¬ìŠ¤íŠ¸
                - n_categories: ë²”ì£¼ ìˆ˜ (ì˜ˆ: 5ì  ì²™ë„ = 5)
                - indicator_types: ì§€í‘œ ìœ í˜• ('ordered', 'continuous', 'binary')
        """
        self.config = config
        self.n_indicators = len(config.indicators)
        self.n_categories = config.n_categories
        self.n_thresholds = config.n_categories - 1  # 5ì  ì²™ë„ â†’ 4ê°œ ì„ê³„ê°’
        
        # íŒŒë¼ë¯¸í„° (ì¶”ì • í›„ ì €ì¥)
        self.zeta = None  # ìš”ì¸ì ì¬ëŸ‰ (n_indicators,)
        self.tau = None   # ì„ê³„ê°’ (n_indicators, n_thresholds)
        
        self.fitted = False
        
        logger.info(f"OrderedProbitMeasurement ì´ˆê¸°í™”: {self.n_indicators}ê°œ ì§€í‘œ, {self.n_categories}ì  ì²™ë„")
    
    def log_likelihood(self, data: pd.DataFrame, latent_var: float,
                      params: Dict[str, np.ndarray]) -> float:
        """
        ë¡œê·¸ìš°ë„ ê³„ì‚° (King 2022 Apollo ì½”ë“œ ê¸°ë°˜)

        ğŸ”´ ìˆ˜ì •: ì¸¡ì •ëª¨ë¸ì€ ê°œì¸ë‹¹ 1ë²ˆë§Œ ê³„ì‚° (ì§€í‘œëŠ” ê°œì¸ íŠ¹ì„±)

        Args:
            data: ê´€ì¸¡ì§€í‘œ ë°ì´í„° (ê°œì¸ì˜ ì—¬ëŸ¬ ì„ íƒ ìƒí™©)
            latent_var: ì ì¬ë³€ìˆ˜ ê°’ (ìŠ¤ì¹¼ë¼ - ê°œì¸ë‹¹ 1ê°œ)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
                - 'zeta': ìš”ì¸ì ì¬ëŸ‰ (n_indicators,)
                - 'tau': ì„ê³„ê°’ (n_indicators, n_thresholds)

        Returns:
            ë¡œê·¸ìš°ë„ ê°’
        """
        zeta = params['zeta']
        tau = params['tau']

        total_ll = 0.0

        # ğŸ”´ ìˆ˜ì •: ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš© (ì§€í‘œëŠ” ê°œì¸ íŠ¹ì„±ì´ë¯€ë¡œ ëª¨ë“  í–‰ì´ ë™ì¼)
        first_row = data.iloc[0]

        # ê° ì§€í‘œì— ëŒ€í•´
        for i, indicator in enumerate(self.config.indicators):
            if indicator not in first_row.index:
                continue

            y = first_row[indicator]
            if np.isnan(y):
                continue

            zeta_i = zeta[i]
            tau_i = tau[i]  # (n_thresholds,)

            # Ordered Probit í™•ë¥  ê³„ì‚°
            prob = self._ordered_probit_probability(y, latent_var, zeta_i, tau_i)

            # ë¡œê·¸ìš°ë„ ëˆ„ì 
            if prob > 0:
                total_ll += np.log(prob)
            else:
                total_ll += -1e10  # ë§¤ìš° ì‘ì€ ê°’

        return total_ll
    
    def _ordered_probit_probability(self, y: float, lv: float, 
                                   zeta: float, tau: np.ndarray) -> float:
        """
        Ordered Probit í™•ë¥  ê³„ì‚°
        
        P(Y=k) = Î¦(Ï„_k - Î¶*LV) - Î¦(Ï„_{k-1} - Î¶*LV)
        
        Apollo R ì½”ë“œ:
            V = zeta * LV
            P(Y=k) = pnorm(tau[k] - V) - pnorm(tau[k-1] - V)
        
        Args:
            y: ê´€ì¸¡ê°’ (1, 2, 3, 4, 5)
            lv: ì ì¬ë³€ìˆ˜ ê°’
            zeta: ìš”ì¸ì ì¬ëŸ‰
            tau: ì„ê³„ê°’ ë°°ì—´ (n_thresholds,)
        
        Returns:
            í™•ë¥  P(Y=k)
        """
        k = int(y) - 1  # 1-5 â†’ 0-4
        
        # V = zeta * LV (Apollo ì½”ë“œì™€ ë™ì¼)
        V = zeta * lv
        
        # ê²½ê³„ ì¡°ê±´
        if k == 0:
            # P(Y=1) = Î¦(Ï„_1 - V)
            prob = norm.cdf(tau[0] - V)
        elif k == self.n_categories - 1:
            # P(Y=5) = 1 - Î¦(Ï„_4 - V)
            prob = 1 - norm.cdf(tau[-1] - V)
        else:
            # P(Y=k) = Î¦(Ï„_k - V) - Î¦(Ï„_{k-1} - V)
            prob = norm.cdf(tau[k] - V) - norm.cdf(tau[k-1] - V)
        
        # ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•´ í´ë¦¬í•‘
        prob = np.clip(prob, 1e-10, 1 - 1e-10)
        
        return prob
    
    def predict(self, latent_var: np.ndarray, params: Dict[str, np.ndarray]) -> pd.DataFrame:
        """
        ì ì¬ë³€ìˆ˜ë¡œë¶€í„° ê´€ì¸¡ì§€í‘œ ì˜ˆì¸¡
        
        Args:
            latent_var: ì ì¬ë³€ìˆ˜ ê°’ (n_obs,)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ì˜ˆì¸¡ëœ ì§€í‘œ ê°’ (n_obs, n_indicators)
        """
        zeta = params['zeta']
        tau = params['tau']
        
        n_obs = len(latent_var)
        predictions = np.zeros((n_obs, self.n_indicators))
        
        for i in range(self.n_indicators):
            zeta_i = zeta[i]
            tau_i = tau[i]
            
            for j in range(n_obs):
                lv = latent_var[j]
                
                # ê° ë²”ì£¼ì˜ í™•ë¥  ê³„ì‚°
                probs = []
                for k in range(1, self.n_categories + 1):
                    prob = self._ordered_probit_probability(k, lv, zeta_i, tau_i)
                    probs.append(prob)
                
                # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ë²”ì£¼ ì„ íƒ
                predictions[j, i] = np.argmax(probs) + 1
        
        return pd.DataFrame(predictions, columns=self.config.indicators)
    
    def predict_probabilities(self, latent_var: np.ndarray, 
                             params: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """
        ê° ë²”ì£¼ì˜ í™•ë¥  ì˜ˆì¸¡
        
        Args:
            latent_var: ì ì¬ë³€ìˆ˜ ê°’ (n_obs,)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ì§€í‘œë³„ ë²”ì£¼ í™•ë¥  ë”•ì…”ë„ˆë¦¬
        """
        zeta = params['zeta']
        tau = params['tau']
        
        n_obs = len(latent_var)
        probabilities = {}
        
        for i, indicator in enumerate(self.config.indicators):
            zeta_i = zeta[i]
            tau_i = tau[i]
            
            # (n_obs, n_categories) í™•ë¥  í–‰ë ¬
            probs = np.zeros((n_obs, self.n_categories))
            
            for j in range(n_obs):
                lv = latent_var[j]
                
                for k in range(1, self.n_categories + 1):
                    probs[j, k-1] = self._ordered_probit_probability(k, lv, zeta_i, tau_i)
            
            probabilities[indicator] = probs
        
        return probabilities
    
    def fit(self, data: pd.DataFrame, initial_params: Optional[Dict[str, np.ndarray]] = None) -> Dict[str, Any]:
        """
        ì¸¡ì •ëª¨ë¸ ë‹¨ë… ì¶”ì • (Sequential ë°©ì‹ìš©)
        
        Note: ICLV ë™ì‹œ ì¶”ì •ì—ì„œëŠ” ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ ,
              SimultaneousEstimatorê°€ log_likelihood()ë¥¼ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            data: ê´€ì¸¡ì§€í‘œ ë°ì´í„°
            initial_params: ì´ˆê¸° íŒŒë¼ë¯¸í„° (ì„ íƒ)
        
        Returns:
            ì¶”ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("ì¸¡ì •ëª¨ë¸ ë‹¨ë… ì¶”ì • ì‹œì‘ (Sequential ë°©ì‹)")
        
        # ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì •
        if initial_params is None:
            initial_params = self._get_initial_parameters()
        
        # ê°„ë‹¨í•œ ìš”ì¸ì ìˆ˜ ê³„ì‚° (í‰ê· )
        latent_var = data[self.config.indicators].mean(axis=1).values
        
        # íŒŒë¼ë¯¸í„° ë²¡í„°í™”
        param_vector = self._pack_parameters(initial_params)
        
        # ìš°ë„í•¨ìˆ˜ ì •ì˜
        def negative_log_likelihood(params_vec):
            params = self._unpack_parameters(params_vec)
            ll = self.log_likelihood(data, latent_var, params)
            return -ll
        
        # ìµœì í™”
        result = minimize(
            negative_log_likelihood,
            param_vector,
            method='L-BFGS-B',
            options={'maxiter': 1000}
        )
        
        # ê²°ê³¼ ì €ì¥
        self.zeta = self._unpack_parameters(result.x)['zeta']
        self.tau = self._unpack_parameters(result.x)['tau']
        self.fitted = True
        
        logger.info("ì¸¡ì •ëª¨ë¸ ì¶”ì • ì™„ë£Œ")
        
        return {
            'zeta': self.zeta,
            'tau': self.tau,
            'log_likelihood': -result.fun,
            'success': result.success
        }
    
    def _get_initial_parameters(self) -> Dict[str, np.ndarray]:
        """ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì • (King 2022 ìŠ¤íƒ€ì¼)"""
        return {
            'zeta': np.ones(self.n_indicators),  # ìš”ì¸ì ì¬ëŸ‰ = 1.0
            'tau': np.tile([-2, -1, 1, 2], (self.n_indicators, 1))  # 5ì  ì²™ë„ ê¸°ë³¸ê°’
        }
    
    def _pack_parameters(self, params: Dict[str, np.ndarray]) -> np.ndarray:
        """íŒŒë¼ë¯¸í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        param_vector = []
        param_vector.extend(params['zeta'])
        param_vector.extend(params['tau'].flatten())
        return np.array(param_vector)
    
    def _unpack_parameters(self, param_vector: np.ndarray) -> Dict[str, np.ndarray]:
        """ë²¡í„°ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ë³€í™˜"""
        idx = 0

        # zeta
        zeta = param_vector[idx:idx + self.n_indicators]
        idx += self.n_indicators

        # tau
        tau = param_vector[idx:].reshape(self.n_indicators, self.n_thresholds)

        return {'zeta': zeta, 'tau': tau}

    def get_n_parameters(self) -> int:
        """
        ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ë°˜í™˜

        Returns:
            íŒŒë¼ë¯¸í„° ìˆ˜ (zeta + tau)
        """
        # zeta: n_indicators
        # tau: n_indicators * n_thresholds
        return self.n_indicators + (self.n_indicators * self.n_thresholds)


class ContinuousLinearMeasurement:
    """
    ì—°ì†í˜• ì„ í˜• ì¸¡ì •ëª¨ë¸ (Continuous Linear Measurement)

    ë¦¬ì»¤íŠ¸ ì²™ë„ë¥¼ ì—°ì†í˜• ë³€ìˆ˜ë¡œ ê°„ì£¼í•˜ì—¬ ì¸¡ì •í•˜ëŠ” SEM ë°©ì‹ì˜ ì¸¡ì •ëª¨ë¸ì…ë‹ˆë‹¤.

    Model:
        Y_i = Î¶_i * LV + Îµ_i
        Îµ_i ~ N(0, ÏƒÂ²_i)

    ì—¬ê¸°ì„œ:
        - Y_i: ê´€ì¸¡ì§€í‘œ (ë¦¬ì»¤íŠ¸ ì²™ë„ ê°’)
        - Î¶_i: ìš”ì¸ì ì¬ëŸ‰ (factor loading)
        - LV: ì ì¬ë³€ìˆ˜ (latent variable)
        - Îµ_i: ì¸¡ì •ì˜¤ì°¨
        - ÏƒÂ²_i: ì˜¤ì°¨ë¶„ì‚°

    Parameters:
        - zeta: ìš”ì¸ì ì¬ëŸ‰ (n_indicators,)
        - sigma_sq: ì˜¤ì°¨ë¶„ì‚° (n_indicators,)

    Total parameters: 2 * n_indicators (ì²« ë²ˆì§¸ ì ì¬ëŸ‰ ê³ ì • ì‹œ 2*n - 1)

    Reference:
        - Bollen, K. A. (1989). Structural Equations with Latent Variables.
        - JÃ¶reskog, K. G. (1970). A general method for analysis of covariance structures.
    """

    def __init__(self, config):
        """
        ì´ˆê¸°í™”

        Args:
            config: MeasurementConfig ê°ì²´
                - indicators: ê´€ì¸¡ì§€í‘œ ë¦¬ìŠ¤íŠ¸
                - fix_first_loading: ì²« ë²ˆì§¸ ì ì¬ëŸ‰ ê³ ì • ì—¬ë¶€
                - fix_error_variance: ì˜¤ì°¨ë¶„ì‚° ê³ ì • ì—¬ë¶€
        """
        self.config = config
        self.n_indicators = len(config.indicators)

        # íŒŒë¼ë¯¸í„° (ì¶”ì • í›„ ì €ì¥)
        self.zeta = None      # ìš”ì¸ì ì¬ëŸ‰ (n_indicators,)
        self.sigma_sq = None  # ì˜¤ì°¨ë¶„ì‚° (n_indicators,)

        self.fitted = False

        logger.info(f"ContinuousLinearMeasurement ì´ˆê¸°í™”: {self.n_indicators}ê°œ ì§€í‘œ")

    def log_likelihood(self, data: pd.DataFrame, latent_var: float,
                      params: Dict[str, np.ndarray]) -> float:
        """
        ë¡œê·¸ìš°ë„ ê³„ì‚° (ì •ê·œë¶„í¬ ê¸°ë°˜)

        Args:
            data: ê´€ì¸¡ì§€í‘œ ë°ì´í„°
            latent_var: ì ì¬ë³€ìˆ˜ ê°’ (ìŠ¤ì¹¼ë¼)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
                - 'zeta': ìš”ì¸ì ì¬ëŸ‰ (n_indicators,)
                - 'sigma_sq': ì˜¤ì°¨ë¶„ì‚° (n_indicators,)

        Returns:
            ë¡œê·¸ìš°ë„ ê°’
        """
        zeta = params['zeta']
        sigma_sq = params['sigma_sq']

        total_ll = 0.0

        # ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš© (ì§€í‘œëŠ” ê°œì¸ íŠ¹ì„±)
        first_row = data.iloc[0]

        # ê° ì§€í‘œì— ëŒ€í•´
        for i, indicator in enumerate(self.config.indicators):
            if indicator not in first_row.index:
                continue

            y_obs = first_row[indicator]

            if pd.isna(y_obs):
                continue

            # ì˜ˆì¸¡ê°’: Y_pred = Î¶_i * LV
            y_pred = zeta[i] * latent_var

            # ì”ì°¨
            residual = y_obs - y_pred

            # ì •ê·œë¶„í¬ ë¡œê·¸ìš°ë„
            # log N(y | Î¼, ÏƒÂ²) = -0.5 * log(2Ï€ * ÏƒÂ²) - 0.5 * (y - Î¼)Â² / ÏƒÂ²
            ll_i = -0.5 * np.log(2 * np.pi * sigma_sq[i])
            ll_i += -0.5 * (residual ** 2) / sigma_sq[i]

            total_ll += ll_i

        return total_ll

    def initialize_parameters(self) -> Dict[str, np.ndarray]:
        """
        íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”

        Returns:
            {
                'zeta': np.ndarray (n_indicators,),
                'sigma_sq': np.ndarray (n_indicators,)
            }
        """
        params = {}

        # ìš”ì¸ì ì¬ëŸ‰ ì´ˆê¸°í™”
        if self.config.initial_loadings is not None:
            zeta = np.array([
                self.config.initial_loadings.get(ind, 1.0)
                for ind in self.config.indicators
            ])
        else:
            # ê¸°ë³¸ê°’: ëª¨ë‘ 1.0
            zeta = np.ones(self.n_indicators)

        # ì²« ë²ˆì§¸ ì ì¬ëŸ‰ ê³ ì • (ì‹ë³„)
        if self.config.fix_first_loading:
            zeta[0] = 1.0

        params['zeta'] = zeta

        # ì˜¤ì°¨ë¶„ì‚° ì´ˆê¸°í™”
        sigma_sq = np.ones(self.n_indicators) * self.config.initial_error_variance
        params['sigma_sq'] = sigma_sq

        return params

    def get_n_parameters(self) -> int:
        """
        ì¶”ì •í•  íŒŒë¼ë¯¸í„° ìˆ˜ ë°˜í™˜

        Returns:
            íŒŒë¼ë¯¸í„° ìˆ˜
        """
        n_params = 0

        # ìš”ì¸ì ì¬ëŸ‰
        if self.config.fix_first_loading:
            n_params += self.n_indicators - 1  # ì²« ë²ˆì§¸ ê³ ì •
        else:
            n_params += self.n_indicators

        # ì˜¤ì°¨ë¶„ì‚°
        if not self.config.fix_error_variance:
            n_params += self.n_indicators

        return n_params

    def get_parameter_bounds(self) -> List[Tuple[float, float]]:
        """
        íŒŒë¼ë¯¸í„° ì œì•½ì¡°ê±´ (bounds)

        Returns:
            [(lower, upper), ...] ë¦¬ìŠ¤íŠ¸
        """
        bounds = []

        # ìš”ì¸ì ì¬ëŸ‰: [-10, 10]
        start_idx = 1 if self.config.fix_first_loading else 0
        for i in range(start_idx, self.n_indicators):
            bounds.append((-10.0, 10.0))

        # ì˜¤ì°¨ë¶„ì‚°: [0.01, 100] (ì–‘ìˆ˜)
        if not self.config.fix_error_variance:
            for i in range(self.n_indicators):
                bounds.append((0.01, 100.0))

        return bounds


def estimate_measurement_model(data: pd.DataFrame, config,
                               initial_params: Optional[Dict[str, np.ndarray]] = None) -> Tuple[OrderedProbitMeasurement, Dict[str, Any]]:
    """
    ì¸¡ì •ëª¨ë¸ ì¶”ì • í—¬í¼ í•¨ìˆ˜

    Args:
        data: ê´€ì¸¡ì§€í‘œ ë°ì´í„°
        config: MeasurementConfig ê°ì²´
        initial_params: ì´ˆê¸° íŒŒë¼ë¯¸í„° (ì„ íƒ)

    Returns:
        (ëª¨ë¸ ê°ì²´, ì¶”ì • ê²°ê³¼)
    """
    model = OrderedProbitMeasurement(config)
    results = model.fit(data, initial_params)
    return model, results

