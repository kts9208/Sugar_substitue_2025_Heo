"""
GPU ë°°ì¹˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°

Analytic gradientë¥¼ GPU ë°°ì¹˜ë¡œ ê³„ì‚°í•˜ì—¬ ì†ë„ë¥¼ í–¥ìƒì‹œí‚µë‹ˆë‹¤.

CPU êµ¬í˜„ (multi_latent_gradient.py)ì˜ ë¡œì§ì„ ë”°ë¥´ë©´ì„œ:
1. Importance weighting êµ¬í˜„ (Apollo ë°©ì‹)
2. ëª¨ë“  ì„ íƒ ìƒí™© ì²˜ë¦¬
3. Likelihood ê³„ì‚° í›„ ê°€ì¤‘í‰ê· 
4. ìˆ˜ì¹˜ ì•ˆì •ì„± ê°•í™”
5. GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
"""

import numpy as np
import pandas as pd
from typing import Dict, List
import logging

logger = logging.getLogger(__name__)

try:
    import cupy as cp
    from cupyx.scipy.special import ndtr as cp_ndtr
    CUPY_AVAILABLE = True

    # CuPyì—ëŠ” norm.pdfê°€ ì—†ìœ¼ë¯€ë¡œ ì§ì ‘ êµ¬í˜„
    def cp_norm_pdf(x):
        """í‘œì¤€ì •ê·œë¶„í¬ PDF: Ï†(x) = (1/âˆš(2Ï€)) * exp(-xÂ²/2)"""
        return cp.exp(-0.5 * x**2) / cp.sqrt(2 * cp.pi)

    def log_sum_exp_gpu(log_values):
        """
        Log-sum-exp trick for numerical stability
        log(Î£ exp(x_i)) = max(x) + log(Î£ exp(x_i - max(x)))
        """
        max_val = cp.max(log_values)
        return max_val + cp.log(cp.sum(cp.exp(log_values - max_val)))

except ImportError:
    CUPY_AVAILABLE = False
    logger.warning("CuPy not available. GPU gradient acceleration disabled.")
    cp_norm_pdf = None
    log_sum_exp_gpu = None


def compute_joint_likelihood_batch_gpu(
    gpu_measurement_model,
    ind_data: pd.DataFrame,
    lvs_list: List[Dict[str, float]],
    draws: np.ndarray,
    params_dict: Dict,
    structural_model,
    choice_model
) -> np.ndarray:
    """
    ê° drawì˜ ê²°í•© likelihood ê³„ì‚° (importance weightingìš©)

    ê¸°ì¡´ gpu_batch_utilsì˜ í•¨ìˆ˜ë“¤ì„ í™œìš©í•©ë‹ˆë‹¤.

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        ind_data: ê°œì¸ ë°ì´í„°
        lvs_list: ê° drawì˜ ì ì¬ë³€ìˆ˜ ê°’ ë¦¬ìŠ¤íŠ¸
        draws: ê°œì¸ì˜ draws (n_draws, n_dimensions)
        params_dict: ëª¨ë“  íŒŒë¼ë¯¸í„° {'measurement': ..., 'structural': ..., 'choice': ...}
        structural_model: êµ¬ì¡°ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        choice_model: ì„ íƒëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ê° drawì˜ log-likelihood ë°°ì—´ (n_draws,)
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    # ê¸°ì¡´ GPU ìš°ë„ ê³„ì‚° í•¨ìˆ˜ë“¤ import
    from . import gpu_batch_utils

    # 1. ì¸¡ì •ëª¨ë¸ ìš°ë„ (ë°°ì¹˜)
    ll_measurement = gpu_batch_utils.compute_measurement_batch_gpu(
        gpu_measurement_model,
        ind_data,
        lvs_list,
        params_dict['measurement']
    )

    # 2. êµ¬ì¡°ëª¨ë¸ ìš°ë„ (ë°°ì¹˜)
    ll_structural = gpu_batch_utils.compute_structural_batch_gpu(
        ind_data,
        lvs_list,
        params_dict['structural'],
        draws,
        structural_model
    )

    # 3. ì„ íƒëª¨ë¸ ìš°ë„ (ë°°ì¹˜)
    ll_choice = gpu_batch_utils.compute_choice_batch_gpu(
        ind_data,
        lvs_list,
        params_dict['choice'],
        choice_model
    )

    # 4. ê²°í•© ìš°ë„
    ll_joint = ll_measurement + ll_structural + ll_choice

    return ll_joint


def compute_importance_weights_gpu(ll_batch: np.ndarray, individual_id: int = None) -> np.ndarray:
    """
    Importance weights ê³„ì‚° (Apollo ë°©ì‹)

    w_r = L_r / Î£_s L_s = exp(ll_r) / Î£_s exp(ll_s)

    Log-sum-exp trick ì‚¬ìš©í•˜ì—¬ ìˆ˜ì¹˜ ì•ˆì •ì„± í™•ë³´

    Args:
        ll_batch: ê° drawì˜ log-likelihood (n_draws,)
        individual_id: ê°œì¸ ID (ë””ë²„ê¹…ìš©)

    Returns:
        importance weights (n_draws,)
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    ll_gpu = cp.asarray(ll_batch)

    # âœ… ë””ë²„ê¹…: likelihood ê°’ í™•ì¸
    ll_min = float(cp.min(ll_gpu))
    ll_max = float(cp.max(ll_gpu))
    ll_mean = float(cp.mean(ll_gpu))

    # NaN/Inf ì²´í¬ (ì…ë ¥ ë‹¨ê³„)
    if cp.any(cp.isnan(ll_gpu)):
        n_nan = int(cp.sum(cp.isnan(ll_gpu)))
        logger.error(f"[Individual {individual_id}] NaN detected in input LL batch ({n_nan}/{len(ll_batch)} draws)")
        logger.error(f"  LL range: [{ll_min:.2f}, {ll_max:.2f}], mean: {ll_mean:.2f}")
        logger.error(f"  First 10 LL values: {ll_batch[:10]}")
        raise ValueError(f"NaN detected in likelihood for individual {individual_id}. Cannot compute importance weights.")

    if cp.any(cp.isinf(ll_gpu)):
        n_inf = int(cp.sum(cp.isinf(ll_gpu)))
        logger.error(f"[Individual {individual_id}] Inf detected in input LL batch ({n_inf}/{len(ll_batch)} draws)")
        logger.error(f"  LL range: [{ll_min:.2f}, {ll_max:.2f}], mean: {ll_mean:.2f}")
        raise ValueError(f"Inf detected in likelihood for individual {individual_id}. Cannot compute importance weights.")

    # Log-sum-exp trick
    log_sum = log_sum_exp_gpu(ll_gpu)
    log_weights = ll_gpu - log_sum
    weights = cp.exp(log_weights)

    # ìˆ˜ì¹˜ ì•ˆì •ì„± ì²´í¬ (ì¶œë ¥ ë‹¨ê³„)
    if cp.any(cp.isnan(weights)):
        logger.error(f"[Individual {individual_id}] NaN detected in importance weights after exp()")
        logger.error(f"  Input LL range: [{ll_min:.2f}, {ll_max:.2f}], mean: {ll_mean:.2f}")
        logger.error(f"  log_sum: {float(log_sum)}")
        logger.error(f"  log_weights range: [{float(cp.min(log_weights)):.2f}, {float(cp.max(log_weights)):.2f}]")
        raise ValueError(f"NaN in importance weights for individual {individual_id} after normalization.")

    if cp.any(cp.isinf(weights)):
        logger.error(f"[Individual {individual_id}] Inf detected in importance weights after exp()")
        logger.error(f"  Input LL range: [{ll_min:.2f}, {ll_max:.2f}], mean: {ll_mean:.2f}")
        raise ValueError(f"Inf in importance weights for individual {individual_id} after normalization.")

    # ì •ê·œí™” í™•ì¸
    weight_sum = cp.sum(weights)
    if not cp.isclose(weight_sum, 1.0):
        logger.warning(f"[Individual {individual_id}] Weights sum to {float(weight_sum)}, renormalizing")
        weights = weights / weight_sum

    return cp.asnumpy(weights)


def compute_measurement_gradient_batch_gpu(
    gpu_measurement_model,
    ind_data: pd.DataFrame,
    lvs_list: List[Dict[str, float]],
    params: Dict[str, Dict],
    weights: np.ndarray,
    iteration_logger=None,
    log_level: str = 'DETAILED'
) -> Dict[str, Dict]:
    """
    ì¸¡ì •ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ GPU ë°°ì¹˜ë¡œ ê³„ì‚° (ê°€ì¤‘í‰ê·  ì ìš©)

    CPU êµ¬í˜„ (gradient_calculator.pyì˜ MeasurementGradient)ì„ ë”°ë¥´ë©´ì„œ:
    1. ëª¨ë“  ì„ íƒ ìƒí™© ì²˜ë¦¬ (ì²« ë²ˆì§¸ í–‰ë§Œì´ ì•„ë‹˜)
    2. Importance weighting ì ìš©
    3. GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        ind_data: ê°œì¸ ë°ì´í„° (ëª¨ë“  ì„ íƒ ìƒí™©)
        lvs_list: ê° drawì˜ ì ì¬ë³€ìˆ˜ ê°’ [{lv_name: value}, ...]
        params: ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        weights: Importance weights (n_draws,)
        iteration_logger: ë¡œê±° (optional)
        log_level: ë¡œê¹… ë ˆë²¨ ('MINIMAL', 'MODERATE', 'DETAILED')

    Returns:
        ê° LVì˜ ê·¸ë˜ë””ì–¸íŠ¸ {lv_name: {'grad_zeta': ..., 'grad_tau': ...}} or
                          {lv_name: {'grad_zeta': ..., 'grad_sigma_sq': ...}}
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    n_draws = len(lvs_list)
    weights_gpu = cp.asarray(weights)  # (n_draws,)
    gradients = {}

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info("\n[ì¸¡ì •ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°]")

    # ê° ì ì¬ë³€ìˆ˜ë³„ë¡œ ì²˜ë¦¬
    for lv_idx, lv_name in enumerate(params.keys()):
        zeta = params[lv_name]['zeta']
        n_indicators = len(zeta)

        # âœ… measurement_method í™•ì¸ (ëª¨ë¸ ê°ì²´ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
        measurement_method = getattr(gpu_measurement_model.models[lv_name], 'measurement_method', 'ordered_probit')
        config = gpu_measurement_model.models[lv_name].config

        if iteration_logger and log_level == 'DETAILED' and lv_idx == 0:
            iteration_logger.info(f"  ì ì¬ë³€ìˆ˜: {lv_name}")
            iteration_logger.info(f"    - ì¸¡ì • ë°©ë²•: {measurement_method}")
            iteration_logger.info(f"    - ì§€í‘œ ìˆ˜: {n_indicators}")
            iteration_logger.info(f"    - zeta (ì²˜ìŒ 3ê°œ): {zeta[:min(3, len(zeta))]}")

        # LV ê°’ë“¤ì„ ë°°ì—´ë¡œ ë³€í™˜
        lv_values = np.array([lvs[lv_name] for lvs in lvs_list])
        lv_values_gpu = cp.asarray(lv_values)  # (n_draws,)
        zeta_gpu = cp.asarray(zeta)  # (n_indicators,)

        if iteration_logger and log_level == 'DETAILED' and lv_idx == 0:
            iteration_logger.info(f"    - LV ê°’ ë²”ìœ„: [{float(cp.min(lv_values_gpu)):.4f}, {float(cp.max(lv_values_gpu)):.4f}]")
            iteration_logger.info(f"    - LV ê°’ í‰ê· : {float(cp.mean(lv_values_gpu)):.4f}")

        # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™” (ê° drawë³„)
        grad_zeta_batch = cp.zeros((n_draws, n_indicators))

        if measurement_method == 'continuous_linear':
            # âœ… Continuous Linear ë°©ì‹
            sigma_sq = params[lv_name]['sigma_sq']
            sigma_sq_gpu = cp.asarray(sigma_sq)  # (n_indicators,)
            grad_sigma_sq_batch = cp.zeros((n_draws, n_indicators))
        else:
            # Ordered Probit ë°©ì‹ (ê¸°ì¡´)
            tau = params[lv_name]['tau']
            n_thresholds = tau.shape[1]
            tau_gpu = cp.asarray(tau)  # (n_indicators, n_thresholds)
            grad_tau_batch = cp.zeros((n_draws, n_indicators, n_thresholds))

        # âœ… ì¸¡ì •ëª¨ë¸ì€ ê°œì¸ ìˆ˜ì¤€ ë°ì´í„°ì´ë¯€ë¡œ ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©
        # (DCE long formatìœ¼ë¡œ ì¸í•´ ë™ì¼í•œ ê°’ì´ ì—¬ëŸ¬ í–‰ì— ë³µì œë˜ì–´ ìˆìŒ)
        row = ind_data.iloc[0]

        # ì§€í‘œë³„ë¡œ ì²˜ë¦¬
        for i, indicator in enumerate(config.indicators):
            if indicator not in row.index:
                continue

            y = row[indicator]
            if pd.isna(y):
                continue

            if measurement_method == 'continuous_linear':
                # âœ… Continuous Linear: Y = Î¶ * LV + Îµ, Îµ ~ N(0, ÏƒÂ²)
                # log L = -0.5 * log(2Ï€ * ÏƒÂ²) - 0.5 * (y - Î¶*LV)Â² / ÏƒÂ²

                # ì˜ˆì¸¡ê°’: y_pred = Î¶_i * LV
                y_pred = zeta_gpu[i] * lv_values_gpu  # (n_draws,)

                # ì”ì°¨: residual = y - y_pred
                residual = y - y_pred  # (n_draws,)

                # ìƒì„¸ ë¡œê¹… (ì²« ë²ˆì§¸ LV, ì²« ë²ˆì§¸ ì§€í‘œë§Œ)
                if iteration_logger and log_level == 'DETAILED' and lv_idx == 0 and i == 0:
                    iteration_logger.info(f"\n    [ì§€í‘œ {indicator} ê³„ì‚° ì˜ˆì‹œ]")
                    iteration_logger.info(f"      - ê´€ì¸¡ê°’ y: {y:.4f}")
                    iteration_logger.info(f"      - zeta[{i}]: {float(zeta_gpu[i]):.6f}")
                    iteration_logger.info(f"      - sigma_sq[{i}]: {float(sigma_sq_gpu[i]):.6f}")
                    iteration_logger.info(f"      - LV (draw 0): {float(lv_values_gpu[0]):.4f}")
                    iteration_logger.info(f"      - ì˜ˆì¸¡ê°’ (draw 0): {float(y_pred[0]):.4f}")
                    iteration_logger.info(f"      - ì”ì°¨ (draw 0): {float(residual[0]):.4f}")

                # âˆ‚ log L / âˆ‚Î¶_i = (y - Î¶*LV) * LV / ÏƒÂ²
                grad_zeta_batch[:, i] = residual * lv_values_gpu / sigma_sq_gpu[i]

                # âˆ‚ log L / âˆ‚ÏƒÂ²_i = -0.5 / ÏƒÂ² + 0.5 * (y - Î¶*LV)Â² / Ïƒâ´
                grad_sigma_sq_batch[:, i] = -0.5 / sigma_sq_gpu[i] + 0.5 * (residual ** 2) / (sigma_sq_gpu[i] ** 2)

            else:
                # Ordered Probit (ê¸°ì¡´ ë°©ì‹)
                k = int(y) - 1  # 1-5 â†’ 0-4

                # V = zeta_i * LV (broadcasting)
                V = zeta_gpu[i] * lv_values_gpu  # (n_draws,)

                # tau_i for this indicator
                tau_i = tau_gpu[i]  # (n_thresholds,)

                # P(Y=k) ê³„ì‚°
                if k == 0:
                    # P(Y=1) = Î¦(Ï„_1 - V)
                    prob = cp_ndtr(tau_i[0] - V)
                    phi_upper = cp_norm_pdf(tau_i[0] - V)
                    phi_lower = cp.zeros_like(V)
                elif k == config.n_categories - 1:
                    # P(Y=5) = 1 - Î¦(Ï„_4 - V)
                    prob = 1 - cp_ndtr(tau_i[-1] - V)
                    phi_upper = cp.zeros_like(V)
                    phi_lower = cp_norm_pdf(tau_i[-1] - V)
                else:
                    # P(Y=k) = Î¦(Ï„_k - V) - Î¦(Ï„_{k-1} - V)
                    prob = cp_ndtr(tau_i[k] - V) - cp_ndtr(tau_i[k-1] - V)
                    phi_upper = cp_norm_pdf(tau_i[k] - V)
                    phi_lower = cp_norm_pdf(tau_i[k-1] - V)

                # ìˆ˜ì¹˜ ì•ˆì •ì„±
                prob = cp.clip(prob, 1e-10, 1 - 1e-10)

                # âˆ‚ log L / âˆ‚Î¶_i = (Ï†_upper - Ï†_lower) / P * (-LV)
                grad_zeta_batch[:, i] = (phi_upper - phi_lower) / prob * (-lv_values_gpu)

                # âˆ‚ log L / âˆ‚Ï„_k
                if k == 0:
                    grad_tau_batch[:, i, 0] = phi_upper / prob
                elif k == config.n_categories - 1:
                    grad_tau_batch[:, i, -1] = -phi_lower / prob
                else:
                    grad_tau_batch[:, i, k] = phi_upper / prob
                    grad_tau_batch[:, i, k-1] = -phi_lower / prob

        # âœ… ìˆ˜ì •: ê°€ì¤‘í‰ê·  ì ìš© (ë‹¨ìˆœ í•©ì‚°ì´ ì•„ë‹˜)
        # grad_weighted = Î£_r w_r * grad_r
        grad_zeta_weighted = cp.sum(weights_gpu[:, None] * grad_zeta_batch, axis=0)

        if iteration_logger and log_level == 'DETAILED' and lv_idx == 0:
            iteration_logger.info(f"\n    [ê°€ì¤‘í‰ê·  ì ìš© ì „í›„]")
            iteration_logger.info(f"      - grad_zeta_batch (draw 0, ì²˜ìŒ 3ê°œ): {[float(x) for x in grad_zeta_batch[0, :min(3, n_indicators)]]}")
            iteration_logger.info(f"      - weights (ì²˜ìŒ 5ê°œ): {[float(x) for x in weights_gpu[:5]]}")
            iteration_logger.info(f"      - grad_zeta_weighted (ì²˜ìŒ 3ê°œ): {[float(x) for x in grad_zeta_weighted[:min(3, n_indicators)]]}")

        # NaN ì²´í¬
        if cp.any(cp.isnan(grad_zeta_weighted)):
            logger.warning(f"NaN detected in grad_zeta for {lv_name}")
            grad_zeta_weighted = cp.nan_to_num(grad_zeta_weighted, nan=0.0)

        if measurement_method == 'continuous_linear':
            grad_sigma_sq_weighted = cp.sum(weights_gpu[:, None] * grad_sigma_sq_batch, axis=0)

            if iteration_logger and log_level == 'DETAILED' and lv_idx == 0:
                iteration_logger.info(f"      - grad_sigma_sq_weighted (ì²˜ìŒ 3ê°œ): {[float(x) for x in grad_sigma_sq_weighted[:min(3, n_indicators)]]}")

            if cp.any(cp.isnan(grad_sigma_sq_weighted)):
                logger.warning(f"NaN detected in grad_sigma_sq for {lv_name}")
                grad_sigma_sq_weighted = cp.nan_to_num(grad_sigma_sq_weighted, nan=0.0)
        else:
            grad_tau_weighted = cp.sum(weights_gpu[:, None, None] * grad_tau_batch, axis=0)

            if cp.any(cp.isnan(grad_tau_weighted)):
                logger.warning(f"NaN detected in grad_tau for {lv_name}")
                grad_tau_weighted = cp.nan_to_num(grad_tau_weighted, nan=0.0)

        # Gradient clipping
        grad_zeta_weighted = cp.clip(grad_zeta_weighted, -1e6, 1e6)

        # âœ… fix_first_loading ê³ ë ¤: ì²« ë²ˆì§¸ loadingì´ ê³ ì •ë˜ë©´ gradient ì œì™¸
        fix_first_loading = getattr(config, 'fix_first_loading', True)
        if fix_first_loading:
            # ì²« ë²ˆì§¸ zetaëŠ” 1.0ìœ¼ë¡œ ê³ ì • (gradient ì œì™¸)
            grad_zeta_final = cp.asnumpy(grad_zeta_weighted[1:])
        else:
            grad_zeta_final = cp.asnumpy(grad_zeta_weighted)

        # GPUì—ì„œ CPUë¡œ ì „ì†¡
        if measurement_method == 'continuous_linear':
            grad_sigma_sq_weighted = cp.clip(grad_sigma_sq_weighted, -1e6, 1e6)
            gradients[lv_name] = {
                'grad_zeta': grad_zeta_final,
                'grad_sigma_sq': cp.asnumpy(grad_sigma_sq_weighted)
            }

            if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
                iteration_logger.info(f"\n  [{lv_name}] ìµœì¢… ê·¸ë˜ë””ì–¸íŠ¸:")
                iteration_logger.info(f"    - grad_zeta: ë²”ìœ„=[{float(cp.min(grad_zeta_weighted)):.4f}, {float(cp.max(grad_zeta_weighted)):.4f}], norm={float(cp.linalg.norm(grad_zeta_weighted)):.4f}")
                iteration_logger.info(f"    - grad_sigma_sq: ë²”ìœ„=[{float(cp.min(grad_sigma_sq_weighted)):.4f}, {float(cp.max(grad_sigma_sq_weighted)):.4f}], norm={float(cp.linalg.norm(grad_sigma_sq_weighted)):.4f}")
        else:
            grad_tau_weighted = cp.clip(grad_tau_weighted, -1e6, 1e6)
            gradients[lv_name] = {
                'grad_zeta': grad_zeta_final,
                'grad_tau': cp.asnumpy(grad_tau_weighted)
            }

            if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
                iteration_logger.info(f"\n  [{lv_name}] ìµœì¢… ê·¸ë˜ë””ì–¸íŠ¸:")
                iteration_logger.info(f"    - grad_zeta: ë²”ìœ„=[{float(cp.min(grad_zeta_weighted)):.4f}, {float(cp.max(grad_zeta_weighted)):.4f}], norm={float(cp.linalg.norm(grad_zeta_weighted)):.4f}")
                iteration_logger.info(f"    - grad_tau: ë²”ìœ„=[{float(cp.min(grad_tau_weighted)):.4f}, {float(cp.max(grad_tau_weighted)):.4f}], norm={float(cp.linalg.norm(grad_tau_weighted)):.4f}")

    return gradients


def compute_structural_gradient_batch_gpu(
    ind_data: pd.DataFrame,
    lvs_list: List[Dict[str, float]],
    exo_draws_list: List[np.ndarray],
    params: Dict,
    covariates: List[str],
    endogenous_lv: str,
    exogenous_lvs: List[str],
    weights: np.ndarray,
    error_variance: float = 1.0,
    is_hierarchical: bool = False,
    hierarchical_paths: List[Dict] = None,
    iteration_logger=None,
    log_level: str = 'DETAILED'
) -> Dict[str, np.ndarray]:
    """
    êµ¬ì¡°ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ GPU ë°°ì¹˜ë¡œ ê³„ì‚° (ê°€ì¤‘í‰ê·  ì ìš©)

    âœ… ê³„ì¸µì  êµ¬ì¡°ì™€ ë³‘ë ¬ êµ¬ì¡° ëª¨ë‘ ì§€ì›

    CPU êµ¬í˜„ (gradient_calculator.pyì˜ StructuralGradient)ì„ ë”°ë¥´ë©´ì„œ:
    1. Importance weighting ì ìš©
    2. GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ

    Args:
        ind_data: ê°œì¸ ë°ì´í„°
        lvs_list: ê° drawì˜ ì ì¬ë³€ìˆ˜ ê°’
        exo_draws_list: ê° drawì˜ ì™¸ìƒ draws
        params: êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        covariates: ê³µë³€ëŸ‰ ë¦¬ìŠ¤íŠ¸
        endogenous_lv: ë‚´ìƒ LV ì´ë¦„ (ë³‘ë ¬ êµ¬ì¡°ì—ì„œë§Œ ì‚¬ìš©)
        exogenous_lvs: ì™¸ìƒ LV ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ë³‘ë ¬ êµ¬ì¡°ì—ì„œë§Œ ì‚¬ìš©)
        weights: Importance weights (n_draws,)
        error_variance: ì˜¤ì°¨ ë¶„ì‚°
        is_hierarchical: ê³„ì¸µì  êµ¬ì¡° ì—¬ë¶€
        hierarchical_paths: ê³„ì¸µì  ê²½ë¡œ ì •ë³´
        iteration_logger: ë¡œê±° (optional)
        log_level: ë¡œê¹… ë ˆë²¨ ('MINIMAL', 'MODERATE', 'DETAILED')

    Returns:
        ë³‘ë ¬ êµ¬ì¡°: {'grad_gamma_lv': ..., 'grad_gamma_x': ...}
        ê³„ì¸µì  êµ¬ì¡°: {'grad_gamma_{pred}_to_{target}': ...}
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    n_draws = len(lvs_list)
    weights_gpu = cp.asarray(weights)  # (n_draws,)

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info("\n[êµ¬ì¡°ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°]")
        iteration_logger.info(f"  êµ¬ì¡° ìœ í˜•: {'ê³„ì¸µì ' if is_hierarchical else 'ë³‘ë ¬'}")

    if is_hierarchical:
        # âœ… ê³„ì¸µì  êµ¬ì¡°: ê° ê²½ë¡œë³„ë¡œ gradient ê³„ì‚°
        gradients = {}

        for path_idx, path in enumerate(hierarchical_paths):
            target = path['target']
            predictors = path['predictors']
            param_key = f"gamma_{predictors[0]}_to_{target}"

            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            gamma = params[param_key]

            if iteration_logger and log_level == 'DETAILED' and path_idx == 0:
                iteration_logger.info(f"\n  [ê²½ë¡œ {path_idx + 1}] {predictors[0]} â†’ {target}")
                iteration_logger.info(f"    - gamma: {gamma:.6f}")

            # LV ê°’ ì¶”ì¶œ
            target_values = np.array([lvs[target] for lvs in lvs_list])
            pred_values = np.array([lvs[predictors[0]] for lvs in lvs_list])

            # GPUë¡œ ì „ì†¡
            target_gpu = cp.asarray(target_values)  # (n_draws,)
            pred_gpu = cp.asarray(pred_values)  # (n_draws,)
            gamma_gpu = cp.asarray(gamma)  # ìŠ¤ì¹¼ë¼

            # ì˜ˆì¸¡ê°’ ê³„ì‚°: target = gamma * predictor + error
            mu = gamma_gpu * pred_gpu  # (n_draws,)

            # ì”ì°¨
            residual = target_gpu - mu  # (n_draws,)

            if iteration_logger and log_level == 'DETAILED' and path_idx == 0:
                iteration_logger.info(f"    - predictor (draw 0): {float(pred_gpu[0]):.4f}")
                iteration_logger.info(f"    - target (draw 0): {float(target_gpu[0]):.4f}")
                iteration_logger.info(f"    - ì˜ˆì¸¡ê°’ Î¼ (draw 0): {float(mu[0]):.4f}")
                iteration_logger.info(f"    - ì”ì°¨ (draw 0): {float(residual[0]):.4f}")
                iteration_logger.info(f"    - ì”ì°¨ ë²”ìœ„: [{float(cp.min(residual)):.4f}, {float(cp.max(residual)):.4f}]")
                # âœ… ì¶”ê°€ ë””ë²„ê¹…: ëª¨ë“  drawsì˜ target ê°’ í™•ì¸
                iteration_logger.info(f"    - target ê°’ (ì²˜ìŒ 5ê°œ draws): {target_values[:5]}")
                iteration_logger.info(f"    - predictor ê°’ (ì²˜ìŒ 5ê°œ draws): {pred_values[:5]}")
                iteration_logger.info(f"    - ì”ì°¨ (ì²˜ìŒ 5ê°œ draws): {cp.asnumpy(residual[:5])}")

            # âˆ‚ log L / âˆ‚Î³ = Î£_r w_r * (target - Î¼)_r / ÏƒÂ² * predictor_r
            weighted_residual = weights_gpu * residual / error_variance  # (n_draws,)
            grad_gamma = cp.sum(weighted_residual * pred_gpu)  # ìŠ¤ì¹¼ë¼

            # NaN ì²´í¬
            if cp.isnan(grad_gamma):
                logger.warning(f"NaN detected in grad_{param_key}")
                grad_gamma = cp.asarray(0.0)

            # Gradient clipping
            grad_gamma = cp.clip(grad_gamma, -1e6, 1e6)

            gradients[f'grad_{param_key}'] = cp.asnumpy(grad_gamma).item()

            if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
                iteration_logger.info(f"    - grad_{param_key}: {gradients[f'grad_{param_key}']:.6f}")

        return gradients

    else:
        # ë³‘ë ¬ êµ¬ì¡° (ê¸°ì¡´ ë°©ì‹)
        n_exo = len(exogenous_lvs)
        n_cov = len(covariates)

        gamma_lv = params['gamma_lv']
        gamma_x = params['gamma_x']

        # ë°°ì—´ë¡œ ë³€í™˜
        lv_endo_values = np.array([lvs[endogenous_lv] for lvs in lvs_list])
        exo_lv_matrix = np.array([[lvs[lv_name] for lv_name in exogenous_lvs] for lvs in lvs_list])

        # ê³µë³€ëŸ‰ (ëª¨ë“  drawì—ì„œ ë™ì¼)
        first_row = ind_data.iloc[0]
        X = np.array([first_row[cov] if cov in first_row.index and not pd.isna(first_row[cov]) else 0.0 for cov in covariates])

        # GPUë¡œ ì „ì†¡
        lv_endo_gpu = cp.asarray(lv_endo_values)  # (n_draws,)
        exo_lv_gpu = cp.asarray(exo_lv_matrix)  # (n_draws, n_exo)
        X_gpu = cp.asarray(X)  # (n_cov,)
        gamma_lv_gpu = cp.asarray(gamma_lv)  # (n_exo,)
        gamma_x_gpu = cp.asarray(gamma_x)  # (n_cov,)

        # ì˜ˆì¸¡ê°’ ê³„ì‚°
        mu = cp.dot(exo_lv_gpu, gamma_lv_gpu) + cp.dot(X_gpu, gamma_x_gpu)  # (n_draws,)

        # ì”ì°¨
        residual = lv_endo_gpu - mu  # (n_draws,)

        # âœ… ìˆ˜ì •: ê°€ì¤‘í‰ê·  ì ìš©
        # âˆ‚ log L / âˆ‚Î³_lv = Î£_r w_r * (LV_endo - Î¼)_r / ÏƒÂ² * LV_exo_r
        weighted_residual = weights_gpu * residual / error_variance  # (n_draws,)
        grad_gamma_lv = cp.dot(exo_lv_gpu.T, weighted_residual)  # (n_exo,)

        # âˆ‚ log L / âˆ‚Î³_x = Î£_r w_r * (LV_endo - Î¼)_r / ÏƒÂ² * X
        grad_gamma_x = cp.sum(weighted_residual) * X_gpu  # (n_cov,)

        # NaN ì²´í¬
        if cp.any(cp.isnan(grad_gamma_lv)):
            logger.warning("NaN detected in grad_gamma_lv")
            grad_gamma_lv = cp.nan_to_num(grad_gamma_lv, nan=0.0)

        if cp.any(cp.isnan(grad_gamma_x)):
            logger.warning("NaN detected in grad_gamma_x")
            grad_gamma_x = cp.nan_to_num(grad_gamma_x, nan=0.0)

        # Gradient clipping
        grad_gamma_lv = cp.clip(grad_gamma_lv, -1e6, 1e6)
        grad_gamma_x = cp.clip(grad_gamma_x, -1e6, 1e6)

        return {
            'grad_gamma_lv': cp.asnumpy(grad_gamma_lv),
            'grad_gamma_x': cp.asnumpy(grad_gamma_x)
        }


def compute_choice_gradient_batch_gpu(
    ind_data: pd.DataFrame,
    lvs_list: List[Dict[str, float]],
    params: Dict,
    endogenous_lv: str,
    choice_attributes: List[str],
    weights: np.ndarray,
    moderators: List[str] = None,
    iteration_logger=None,
    log_level: str = 'DETAILED'
) -> Dict[str, np.ndarray]:
    """
    ì„ íƒëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ GPU ë°°ì¹˜ë¡œ ê³„ì‚° (ê°€ì¤‘í‰ê·  + ë°°ì¹˜ ì²˜ë¦¬)

    âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì› ì¶”ê°€

    CPU êµ¬í˜„ (gradient_calculator.pyì˜ ChoiceGradient)ì„ ë”°ë¥´ë©´ì„œ:
    1. Importance weighting ì ìš©
    2. GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ (for loop ì œê±°)

    Args:
        ind_data: ê°œì¸ì˜ ì„ íƒ ë°ì´í„°
        lvs_list: ê° drawì˜ ì ì¬ë³€ìˆ˜ ê°’
        params: ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        endogenous_lv: ë‚´ìƒ LV ì´ë¦„ (main LV)
        choice_attributes: ì„ íƒ ì†ì„± ë¦¬ìŠ¤íŠ¸
        weights: Importance weights (n_draws,)
        moderators: ì¡°ì ˆë³€ìˆ˜ LV ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (optional)
        iteration_logger: ë¡œê±° (optional)
        log_level: ë¡œê¹… ë ˆë²¨ ('MINIMAL', 'MODERATE', 'DETAILED')

    Returns:
        ê¸°ë³¸: {'grad_intercept': ..., 'grad_beta': ..., 'grad_lambda': ...}
        ì¡°ì ˆíš¨ê³¼: {'grad_intercept': ..., 'grad_beta': ..., 'grad_lambda_main': ..., 'grad_lambda_mod_{moderator}': ...}
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    n_draws = len(lvs_list)
    n_choice_situations = len(ind_data)
    n_attributes = len(choice_attributes)

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info("\n[ì„ íƒëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°]")
        iteration_logger.info(f"  ì„ íƒ ìƒí™© ìˆ˜: {n_choice_situations}")

    intercept = params['intercept']
    beta = params['beta']

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: lambda_ íŒŒë¼ë¯¸í„° ìë™ ì¶”ì¶œ
    lambda_lvs = {}
    gamma_interactions = {}

    for key in params.keys():
        if key.startswith('lambda_'):
            lv_name = key.replace('lambda_', '')
            lambda_lvs[lv_name] = params[key]
        elif key.startswith('gamma_') and '_to_' not in key:
            # LV-Attribute ìƒí˜¸ì‘ìš©: gamma_{lv_name}_{attr_name}
            # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„° (gamma_{lv1}_to_{lv2})ëŠ” ì œì™¸
            gamma_interactions[key] = params[key]

    if iteration_logger and log_level == 'DETAILED':
        iteration_logger.info(f"  ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ëª¨ë¸:")
        iteration_logger.info(f"    - intercept: {intercept:.6f}")
        iteration_logger.info(f"    - beta: {beta[:min(3, len(beta))]}")
        if lambda_lvs:
            for lv_name, lambda_val in lambda_lvs.items():
                iteration_logger.info(f"    - lambda_{lv_name}: {lambda_val:.6f}")
        else:
            iteration_logger.info(f"    - lambda: ì—†ìŒ (Base Model)")
        if gamma_interactions:
            for gamma_key, gamma_val in gamma_interactions.items():
                iteration_logger.info(f"    - {gamma_key}: {gamma_val:.6f}")

    weights_gpu = cp.asarray(weights)  # (n_draws,)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: LV ê°’ë“¤ ìë™ ì¶”ì¶œ
    lv_values = {}
    for lv_name in lambda_lvs.keys():
        lv_values[lv_name] = np.array([lvs[lv_name] for lvs in lvs_list])

    # ì„ íƒ ë³€ìˆ˜ ì°¾ê¸°
    choice_var = None
    for col in ['choice', 'chosen', 'choice_binary']:
        if col in ind_data.columns:
            choice_var = col
            break

    if choice_var is None:
        raise ValueError("ì„ íƒ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ì†ì„± ë°ì´í„°ì™€ ì„ íƒ ì¤€ë¹„
    attributes_matrix = []
    choices = []

    for idx in range(n_choice_situations):
        row = ind_data.iloc[idx]
        attr_values = [row[attr] if attr in row.index and not pd.isna(row[attr]) else 0.0 for attr in choice_attributes]
        attributes_matrix.append(attr_values)
        choices.append(row[choice_var])

    attributes_matrix = np.array(attributes_matrix)  # (n_situations, n_attributes)
    choices = np.array(choices)  # (n_situations,)

    # GPUë¡œ ì „ì†¡
    attr_gpu = cp.asarray(attributes_matrix)  # (n_situations, n_attributes)
    choices_gpu = cp.asarray(choices)  # (n_situations,)
    beta_gpu = cp.asarray(beta)  # (n_attributes,)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: LV GPU ì „ì†¡
    lv_gpu = {}
    for lv_name, lv_vals in lv_values.items():
        lv_gpu[lv_name] = cp.asarray(lv_vals)  # (n_draws,)

    # âœ… ê°œì„ : ë°°ì¹˜ ì²˜ë¦¬ (for loop ì œê±°)
    # Broadcastingì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  drawsë¥¼ ë™ì‹œì— ì²˜ë¦¬

    # attr_batch: (1, n_situations, n_attributes)
    attr_batch = attr_gpu[None, :, :]

    # V_batch: (n_draws, n_situations)
    # V = intercept + Î²'X
    V_batch = intercept + cp.dot(attr_batch, beta_gpu[:, None]).squeeze(-1)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: V += Î£(Î»_i * LV_i)
    # lambda_lvsê°€ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë©´ ì•„ë¬´ê²ƒë„ ì¶”ê°€ ì•ˆ ë¨ (Base Model)
    for lv_name, lambda_val in lambda_lvs.items():
        lv_batch = lv_gpu[lv_name][:, None]  # (n_draws, 1)
        V_batch = V_batch + lambda_val * lv_batch

    # Î¦(V): (n_draws, n_situations)
    prob_batch = cp_ndtr(V_batch)
    prob_batch = cp.clip(prob_batch, 1e-10, 1 - 1e-10)

    # Ï†(V): (n_draws, n_situations)
    phi_batch = cp_norm_pdf(V_batch)

    # ì‹¤ì œ ì„ íƒì— ë”°ë¼: (n_draws, n_situations)
    prob_final_batch = cp.where(choices_gpu[None, :] == 1, prob_batch, 1 - prob_batch)

    # Mills ratio: (n_draws, n_situations)
    mills_batch = phi_batch / prob_final_batch

    # Sign: (n_draws, n_situations)
    sign_batch = cp.where(choices_gpu[None, :] == 1, 1.0, -1.0)

    if iteration_logger and log_level == 'DETAILED':
        iteration_logger.info(f"\n  [ì¤‘ê°„ ê³„ì‚° ê°’ (draw 0, situation 0)]")
        iteration_logger.info(f"    - V: {float(V_batch[0, 0]):.4f}")
        iteration_logger.info(f"    - Î¦(V): {float(prob_batch[0, 0]):.4f}")
        iteration_logger.info(f"    - Ï†(V): {float(phi_batch[0, 0]):.4f}")
        iteration_logger.info(f"    - choice: {int(choices_gpu[0])}")
        iteration_logger.info(f"    - Mills ratio: {float(mills_batch[0, 0]):.4f}")

    # Weighted mills: (n_draws, n_situations)
    weighted_mills = weights_gpu[:, None] * sign_batch * mills_batch

    # âœ… ìˆ˜ì •: ê°€ì¤‘í‰ê·  ì ìš©
    # âˆ‚V/âˆ‚intercept = 1
    grad_intercept = cp.sum(weighted_mills).item()

    # âˆ‚V/âˆ‚Î² = X
    # (n_situations, n_attributes).T @ (n_draws, n_situations).T
    # = (n_attributes, n_situations) @ (n_situations, n_draws)
    # = (n_attributes, n_draws) â†’ sum over draws
    grad_beta = cp.dot(attr_gpu.T, weighted_mills.T).sum(axis=1)  # (n_attributes,)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: Lambda gradient ê³„ì‚°
    # âˆ‚V/âˆ‚Î»_i = LV_i
    # lambda_lvsê°€ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë©´ ì•„ë¬´ê²ƒë„ ê³„ì‚° ì•ˆ ë¨ (Base Model)
    grad_lambda = {}
    for lv_name in lambda_lvs.keys():
        lv_batch = lv_gpu[lv_name][:, None]  # (n_draws, 1)
        grad_lambda[lv_name] = cp.sum(weighted_mills * lv_batch).item()

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: Gamma gradient ê³„ì‚° (LV-Attribute ìƒí˜¸ì‘ìš©)
    # âˆ‚V/âˆ‚Î³_ij = LV_i Ã— X_j
    grad_gamma = {}

    if iteration_logger and log_level == 'DETAILED':
        iteration_logger.info(f"\n  [Gamma Gradient ê³„ì‚°]")
        iteration_logger.info(f"    - gamma_interactions í‚¤: {list(gamma_interactions.keys())}")
        iteration_logger.info(f"    - lv_gpu í‚¤: {list(lv_gpu.keys())}")
        iteration_logger.info(f"    - choice_attributes: {choice_attributes}")

    for gamma_key in gamma_interactions.keys():
        # gamma_purchase_intention_health_label â†’ lv_name='purchase_intention', attr_name='health_label'
        parts = gamma_key.replace('gamma_', '').rsplit('_', 1)
        if iteration_logger and log_level == 'DETAILED':
            iteration_logger.info(f"    - {gamma_key}: parts={parts}")

        if len(parts) == 2:
            lv_name, attr_name = parts
            if iteration_logger and log_level == 'DETAILED':
                iteration_logger.info(f"      lv_name={lv_name}, attr_name={attr_name}")
                iteration_logger.info(f"      lv_name in lv_gpu: {lv_name in lv_gpu}")
                iteration_logger.info(f"      attr_name in choice_attributes: {attr_name in choice_attributes}")

            if lv_name in lv_gpu and attr_name in choice_attributes:
                lv_batch = lv_gpu[lv_name][:, None]  # (n_draws, 1)
                attr_idx = choice_attributes.index(attr_name)
                attr_values = attr_gpu[:, attr_idx]  # (n_situations,)
                # (n_draws, n_situations) * (n_draws, 1) * (1, n_situations)
                interaction_batch = lv_batch * attr_values[None, :]  # (n_draws, n_situations)
                grad_gamma[gamma_key] = cp.sum(weighted_mills * interaction_batch).item()

                if iteration_logger and log_level == 'DETAILED':
                    iteration_logger.info(f"      âœ… grad_{gamma_key} ê³„ì‚° ì™„ë£Œ: {grad_gamma[gamma_key]:.6f}")

    # NaN ì²´í¬
    if np.isnan(grad_intercept):
        logger.warning("NaN detected in grad_intercept")
        grad_intercept = 0.0

    if cp.any(cp.isnan(grad_beta)):
        logger.warning("NaN detected in grad_beta")
        grad_beta = cp.nan_to_num(grad_beta, nan=0.0)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: Lambda NaN ì²´í¬
    for lv_name in grad_lambda.keys():
        if np.isnan(grad_lambda[lv_name]):
            logger.warning(f"NaN detected in grad_lambda_{lv_name}")
            grad_lambda[lv_name] = 0.0

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: Gamma NaN ì²´í¬
    for gamma_key in grad_gamma.keys():
        if np.isnan(grad_gamma[gamma_key]):
            logger.warning(f"NaN detected in grad_{gamma_key}")
            grad_gamma[gamma_key] = 0.0

    # Gradient clipping
    grad_intercept = np.clip(grad_intercept, -1e6, 1e6)
    grad_beta = cp.clip(grad_beta, -1e6, 1e6)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: Lambda clipping
    for lv_name in grad_lambda.keys():
        grad_lambda[lv_name] = np.clip(grad_lambda[lv_name], -1e6, 1e6)

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: Gamma clipping
    for gamma_key in grad_gamma.keys():
        grad_gamma[gamma_key] = np.clip(grad_gamma[gamma_key], -1e6, 1e6)

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(f"\n  [ìµœì¢… ê·¸ë˜ë””ì–¸íŠ¸]")
        iteration_logger.info(f"    - grad_intercept: {grad_intercept:.6f}")
        iteration_logger.info(f"    - grad_beta: {cp.asnumpy(grad_beta)[:min(3, len(grad_beta))]}")
        if grad_lambda:
            for lv_name, grad_val in grad_lambda.items():
                iteration_logger.info(f"    - grad_lambda_{lv_name}: {grad_val:.6f}")
        else:
            iteration_logger.info(f"    - grad_lambda: ì—†ìŒ (Base Model)")
        if grad_gamma:
            for gamma_key, grad_val in grad_gamma.items():
                iteration_logger.info(f"    - grad_{gamma_key}: {grad_val:.6f}")

    # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: ê²°ê³¼ ë°˜í™˜
    result = {
        'grad_intercept': grad_intercept,
        'grad_beta': cp.asnumpy(grad_beta)
    }
    for lv_name, grad_val in grad_lambda.items():
        result[f'grad_lambda_{lv_name}'] = grad_val
    for gamma_key, grad_val in grad_gamma.items():
        result[f'grad_{gamma_key}'] = grad_val

    return result


def compute_all_individuals_gradients_batch_gpu(
    gpu_measurement_model,
    all_ind_data: List[pd.DataFrame],
    all_ind_draws: np.ndarray,
    params_dict: Dict,
    measurement_model,
    structural_model,
    choice_model,
    iteration_logger=None,
    log_level: str = 'MINIMAL'
) -> List[Dict]:
    """
    ëª¨ë“  ê°œì¸ì˜ gradientë¥¼ GPU batchë¡œ ë™ì‹œ ê³„ì‚° (ê°œì¸ë³„ ìˆœì°¨ + draws GPU batch)

    âš ï¸ ì´ í•¨ìˆ˜ëŠ” ê°œì¸ë³„ ìˆœì°¨ ì²˜ë¦¬ì…ë‹ˆë‹¤.
    ì™„ì „ GPU BatchëŠ” compute_all_individuals_gradients_full_batch_gpu ì‚¬ìš©

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        all_ind_data: ëª¨ë“  ê°œì¸ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [DataFrame_1, ..., DataFrame_N]
        all_ind_draws: ëª¨ë“  ê°œì¸ì˜ draws (N, n_draws, n_dims)
        params_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        measurement_model: ì¸¡ì •ëª¨ë¸
        structural_model: êµ¬ì¡°ëª¨ë¸
        choice_model: ì„ íƒëª¨ë¸
        iteration_logger: ë¡œê±°
        log_level: ë¡œê¹… ë ˆë²¨

    Returns:
        ê°œì¸ë³„ gradient ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ [grad_dict_1, ..., grad_dict_N]
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    n_individuals = len(all_ind_data)
    n_draws = all_ind_draws.shape[1]

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"\n{'='*80}\n"
            f"GPU Batch Gradient ê³„ì‚° (ê°œì¸ë³„ ìˆœì°¨)\n"
            f"{'='*80}\n"
            f"  ê°œì¸ ìˆ˜: {n_individuals}ëª…\n"
            f"  Draws per individual: {n_draws}ê°œ\n"
            f"  ì´ ê³„ì‚°: {n_individuals} Ã— {n_draws} = {n_individuals * n_draws}ê°œ\n"
            f"{'='*80}"
        )

    # ê³„ì¸µì  êµ¬ì¡° ì§€ì›
    is_hierarchical = hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical

    if is_hierarchical:
        n_first_order = len(structural_model.exogenous_lvs)
        n_higher_order = len(structural_model.get_higher_order_lvs())
    else:
        n_exo = structural_model.n_exo

    # ëª¨ë“  ê°œì¸ì˜ gradient ì €ì¥
    all_individual_gradients = []

    # ê°œì¸ë³„ë¡œ ì²˜ë¦¬ (ê° ê°œì¸ ë‚´ë¶€ëŠ” GPU batch)
    for ind_idx, (ind_data, ind_draws) in enumerate(zip(all_ind_data, all_ind_draws)):
        # ëª¨ë“  drawsì˜ LV ê°’ ë¯¸ë¦¬ ê³„ì‚°
        lvs_list = []
        exo_draws_list = []

        for draw_idx in range(n_draws):
            if is_hierarchical:
                # ê³„ì¸µì  êµ¬ì¡°
                first_order_draws = ind_draws[draw_idx, :n_first_order]
                higher_order_errors = ind_draws[draw_idx, n_first_order:]

                higher_order_lvs = structural_model.get_higher_order_lvs()
                error_dict = {lv_name: higher_order_errors[i] for i, lv_name in enumerate(higher_order_lvs)}

                latent_vars = structural_model.predict(
                    ind_data, first_order_draws, params_dict['structural'],
                    endo_draw=None, higher_order_draws=error_dict
                )
                exo_draws_list.append(first_order_draws)
            else:
                # ë³‘ë ¬ êµ¬ì¡°
                exo_draws = ind_draws[draw_idx, :n_exo]
                endo_draw = ind_draws[draw_idx, n_exo]

                latent_vars = structural_model.predict(
                    ind_data, exo_draws, params_dict['structural'], endo_draw
                )
                exo_draws_list.append(exo_draws)

            lvs_list.append(latent_vars)

        # 1. ê²°í•© likelihood ê³„ì‚° (GPU batch)
        ll_batch = compute_joint_likelihood_batch_gpu(
            gpu_measurement_model,
            ind_data,
            lvs_list,
            ind_draws,
            params_dict,
            structural_model,
            choice_model
        )

        # 2. Importance weights ê³„ì‚° (GPU)
        weights = compute_importance_weights_gpu(ll_batch, individual_id=ind_idx)

        # 3. ê°€ì¤‘í‰ê·  gradient ê³„ì‚° (GPU batch)
        grad_meas = compute_measurement_gradient_batch_gpu(
            gpu_measurement_model,
            ind_data,
            lvs_list,
            params_dict['measurement'],
            weights,
            iteration_logger=None,  # ê°œë³„ ë¡œê¹… ë¹„í™œì„±í™”
            log_level='MINIMAL'
        )

        grad_struct = compute_structural_gradient_batch_gpu(
            ind_data,
            lvs_list,
            exo_draws_list,
            params_dict['structural'],
            structural_model.covariates,
            structural_model.endogenous_lv if not is_hierarchical else None,
            structural_model.exogenous_lvs if not is_hierarchical else None,
            weights,
            error_variance=1.0,
            is_hierarchical=is_hierarchical,
            hierarchical_paths=structural_model.hierarchical_paths if is_hierarchical else None,
            iteration_logger=None,
            log_level='MINIMAL'
        )

        # ì„ íƒëª¨ë¸ gradient
        if hasattr(choice_model.config, 'moderators') and choice_model.config.moderators:
            # ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
            grad_choice = compute_choice_gradient_batch_gpu(
                ind_data,
                lvs_list,
                params_dict['choice'],
                choice_model.config.main_lv,
                choice_model.config.choice_attributes,
                weights,
                moderators=choice_model.config.moderators,
                iteration_logger=None,
                log_level='MINIMAL'
            )
        else:
            # ê¸°ë³¸ ëª¨ë¸
            grad_choice = compute_choice_gradient_batch_gpu(
                ind_data,
                lvs_list,
                params_dict['choice'],
                structural_model.endogenous_lv,
                choice_model.config.choice_attributes,
                weights,
                moderators=None,
                iteration_logger=None,
                log_level='MINIMAL'
            )

        # ê°œì¸ë³„ gradient ì €ì¥
        ind_grad_dict = {
            'measurement': grad_meas,
            'structural': grad_struct,
            'choice': grad_choice
        }

        all_individual_gradients.append(ind_grad_dict)

        # ì§„í–‰ ìƒí™© ë¡œê¹… (10% ë‹¨ìœ„)
        if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
            if (ind_idx + 1) % max(1, n_individuals // 10) == 0:
                progress = (ind_idx + 1) / n_individuals * 100
                iteration_logger.info(f"  ì§„í–‰: {ind_idx + 1}/{n_individuals} ({progress:.0f}%)")

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"{'='*80}\n"
            f"ì™„ì „ GPU Batch Gradient ê³„ì‚° ì™„ë£Œ: {n_individuals}ëª…\n"
            f"{'='*80}"
        )

    return all_individual_gradients

def compute_all_individuals_gradients_full_batch_gpu(
    gpu_measurement_model,
    all_ind_data: List[pd.DataFrame],
    all_ind_draws: np.ndarray,
    params_dict: Dict,
    measurement_model,
    structural_model,
    choice_model,
    iteration_logger=None,
    log_level: str = 'MINIMAL'
) -> List[Dict]:
    """
    ëª¨ë“  ê°œì¸ì˜ gradientë¥¼ ì™„ì „ GPU batchë¡œ ë™ì‹œ ê³„ì‚°

    ğŸš€ ì™„ì „ GPU Batch: 326ëª… Ã— 100 draws Ã— 80 params = 2,608,000ê°œ ë™ì‹œ ê³„ì‚°

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        all_ind_data: ëª¨ë“  ê°œì¸ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [DataFrame_1, ..., DataFrame_N]
        all_ind_draws: ëª¨ë“  ê°œì¸ì˜ draws (N, n_draws, n_dims)
        params_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        measurement_model: ì¸¡ì •ëª¨ë¸
        structural_model: êµ¬ì¡°ëª¨ë¸
        choice_model: ì„ íƒëª¨ë¸
        iteration_logger: ë¡œê±°
        log_level: ë¡œê¹… ë ˆë²¨

    Returns:
        ê°œì¸ë³„ gradient ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ [grad_dict_1, ..., grad_dict_N]
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")

    import time

    n_individuals = len(all_ind_data)
    n_draws = all_ind_draws.shape[1]

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"\n{'='*80}\n"
            f"ğŸš€ ì™„ì „ GPU Batch Gradient ê³„ì‚°\n"
            f"{'='*80}\n"
            f"  ê°œì¸ ìˆ˜: {n_individuals}ëª…\n"
            f"  Draws per individual: {n_draws}ê°œ\n"
            f"  ì´ ê³„ì‚°: {n_individuals} Ã— {n_draws} = {n_individuals * n_draws}ê°œ ë™ì‹œ ì²˜ë¦¬\n"
            f"{'='*80}"
        )

    total_start = time.time()

    # Step 1: ë°ì´í„° ì¤€ë¹„ - ëª¨ë“  ê°œì¸ ë°ì´í„°ë¥¼ 3D ë°°ì—´ë¡œ ë³€í™˜
    prep_start = time.time()

    # ëª¨ë“  ê°œì¸ì´ ë™ì¼í•œ í–‰ ìˆ˜ë¥¼ ê°€ì§„ë‹¤ê³  ê°€ì • (18í–‰)
    n_rows = len(all_ind_data[0])

    # í•„ìš”í•œ ì»¬ëŸ¼ ì¶”ì¶œ (ì„ íƒ ë°ì´í„°ë§Œ)
    # choice_columnì€ estimatorì˜ configì— ìˆìŒ
    # ì—¬ê¸°ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°

    prep_time = time.time() - prep_start

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ({prep_time:.3f}ì´ˆ):\n"
            f"    - all_ind_draws shape: {all_ind_draws.shape}"
        )

    # Step 2: GPUë¡œ ë°ì´í„° ì „ì†¡
    transfer_start = time.time()

    all_draws_gpu = cp.asarray(all_ind_draws)

    transfer_time = time.time() - transfer_start

    # Step 3: ì™„ì „ GPU Batchë¡œ ëª¨ë“  ê°œì¸ Ã— ëª¨ë“  drawsì˜ LV ê³„ì‚°
    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  Step 3: ëª¨ë“  ê°œì¸ Ã— ëª¨ë“  drawsì˜ LV ê³„ì‚° ì¤‘..."
        )

    lv_start = time.time()

    # ëª¨ë“  ê°œì¸ Ã— ëª¨ë“  drawsì˜ LV ê³„ì‚°
    # Shape: (326, 100, n_lvs)
    all_lvs_list = []  # List of List[Dict]: (326, 100)

    is_hierarchical = hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical

    for ind_idx, (ind_data, ind_draws) in enumerate(zip(all_ind_data, all_ind_draws)):
        ind_lvs_list = []

        for draw_idx in range(n_draws):
            draw = ind_draws[draw_idx]

            # LV ê³„ì‚° (CPU - structural_model.predict)
            latent_vars = structural_model.predict(
                ind_data.iloc[0],
                draw,
                params_dict['structural']
            )

            ind_lvs_list.append(latent_vars)

        all_lvs_list.append(ind_lvs_list)

    lv_time = time.time() - lv_start

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  LV ê³„ì‚° ì™„ë£Œ ({lv_time:.3f}ì´ˆ)"
        )

    # Step 4: LVë¥¼ 3D ë°°ì—´ë¡œ ë³€í™˜ (326, 100, 5)
    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  Step 4: LVë¥¼ 3D ë°°ì—´ë¡œ ë³€í™˜ ì¤‘..."
        )

    convert_start = time.time()

    # LV ì´ë¦„ ìˆœì„œ ì •ì˜
    lv_names = list(params_dict['measurement'].keys())
    n_lvs = len(lv_names)

    # 3D ë°°ì—´ ìƒì„±: (326, 100, 5)
    all_lvs_array = np.zeros((n_individuals, n_draws, n_lvs))

    for ind_idx, ind_lvs_list in enumerate(all_lvs_list):
        for draw_idx, lvs_dict in enumerate(ind_lvs_list):
            for lv_idx, lv_name in enumerate(lv_names):
                all_lvs_array[ind_idx, draw_idx, lv_idx] = lvs_dict[lv_name]

    convert_time = time.time() - convert_start

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  LV ë°°ì—´ ë³€í™˜ ì™„ë£Œ ({convert_time:.3f}ì´ˆ): shape = {all_lvs_array.shape}"
        )

    # Step 5: ì™„ì „ GPU Batchë¡œ ëª¨ë“  ê°œì¸ Ã— ëª¨ë“  drawsì˜ gradient ê³„ì‚°
    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  Step 5: ì™„ì „ GPU Batch gradient ê³„ì‚° ì¤‘ (1ë²ˆì˜ GPU í˜¸ì¶œ)..."
        )

    grad_start = time.time()

    # ê· ë“± ê°€ì¤‘ì¹˜ (326, 100)
    all_weights = np.ones((n_individuals, n_draws)) / n_draws

    # ğŸš€ ì™„ì „ GPU Batch: 326ëª… Ã— 100 draws Ã— 80 params = 2,608,000ê°œ ë™ì‹œ ê³„ì‚°
    # ì¸¡ì •ëª¨ë¸, êµ¬ì¡°ëª¨ë¸, ì„ íƒëª¨ë¸ gradientë¥¼ í•œ ë²ˆì— ê³„ì‚°
    all_individual_gradients = compute_full_batch_gradients_gpu(
        gpu_measurement_model,
        all_ind_data,
        all_lvs_array,
        all_ind_draws,
        params_dict,
        all_weights,
        structural_model,
        choice_model,
        lv_names,
        iteration_logger=iteration_logger,
        log_level=log_level
    )

    grad_time = time.time() - grad_start

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  Gradient ê³„ì‚° ì™„ë£Œ ({grad_time:.3f}ì´ˆ)"
        )

    total_time = time.time() - total_start

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"\nì™„ì „ GPU Batch ê³„ì‚° ì™„ë£Œ:\n"
            f"  ì´ ì‹œê°„: {total_time:.3f}ì´ˆ\n"
            f"    - ë°ì´í„° ì¤€ë¹„: {prep_time:.3f}ì´ˆ\n"
            f"    - ë°ì´í„° ì „ì†¡ (GPU): {transfer_time:.3f}ì´ˆ\n"
            f"    - LV ê³„ì‚°: {lv_time:.3f}ì´ˆ\n"
            f"    - Gradient ê³„ì‚°: {grad_time:.3f}ì´ˆ\n"
            f"  ê°œì¸ë‹¹ ì‹œê°„: {total_time / n_individuals * 1000:.2f}ms\n"
            f"  ì²˜ë¦¬ëŸ‰: {n_individuals / total_time:.1f} ê°œì¸/ì´ˆ"
        )

    return all_individual_gradients


def compute_full_batch_gradients_gpu(
    gpu_measurement_model,
    all_ind_data: List[pd.DataFrame],
    all_lvs_array: np.ndarray,  # (326, 100, 5)
    all_ind_draws: np.ndarray,  # (326, 100, 6)
    params_dict: Dict,
    all_weights: np.ndarray,  # (326, 100)
    structural_model,
    choice_model,
    lv_names: List[str],
    iteration_logger=None,
    log_level: str = 'MINIMAL'
) -> List[Dict]:
    """
    ì™„ì „ GPU Batch: 326ëª… Ã— 100 draws Ã— 80 params = 2,608,000ê°œ gradient ë™ì‹œ ê³„ì‚°

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        all_ind_data: ëª¨ë“  ê°œì¸ ë°ì´í„° (326ê°œ)
        all_lvs_array: ëª¨ë“  LV ê°’ (326, 100, 5)
        all_ind_draws: ëª¨ë“  draws (326, 100, 6)
        params_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        all_weights: ê°€ì¤‘ì¹˜ (326, 100)
        structural_model: êµ¬ì¡°ëª¨ë¸
        choice_model: ì„ íƒëª¨ë¸
        lv_names: LV ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        iteration_logger: ë¡œê±°
        log_level: ë¡œê¹… ë ˆë²¨

    Returns:
        ê°œì¸ë³„ gradient ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (326ê°œ)
    """
    n_individuals, n_draws, n_lvs = all_lvs_array.shape

    # GPUë¡œ ì „ì†¡
    all_lvs_gpu = cp.asarray(all_lvs_array)  # (326, 100, 5)
    all_weights_gpu = cp.asarray(all_weights)  # (326, 100)

    # 1. ì¸¡ì •ëª¨ë¸ Gradient (ì™„ì „ Batch)
    meas_grads = compute_measurement_full_batch_gpu(
        gpu_measurement_model,
        all_ind_data,
        all_lvs_gpu,
        params_dict['measurement'],
        all_weights_gpu,
        lv_names,
        iteration_logger,
        log_level
    )

    # 2. êµ¬ì¡°ëª¨ë¸ Gradient (ì™„ì „ Batch)
    struct_grads = compute_structural_full_batch_gpu(
        all_lvs_gpu,
        params_dict['structural'],
        all_weights_gpu,
        structural_model,
        lv_names,
        iteration_logger,
        log_level
    )

    # 3. ì„ íƒëª¨ë¸ Gradient (ì™„ì „ Batch)
    choice_grads = compute_choice_full_batch_gpu(
        all_ind_data,
        all_lvs_gpu,
        params_dict['choice'],
        all_weights_gpu,
        choice_model,
        lv_names,
        iteration_logger,
        log_level
    )

    # ê°œì¸ë³„ gradient ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    all_individual_gradients = []
    for ind_idx in range(n_individuals):
        # ì¸¡ì •ëª¨ë¸: {lv_name: {'grad_zeta': array, 'grad_sigma_sq': array}}
        meas_dict = {}
        for lv_name in meas_grads:
            meas_dict[lv_name] = {
                'grad_zeta': meas_grads[lv_name]['grad_zeta'][ind_idx],
                'grad_sigma_sq': meas_grads[lv_name]['grad_sigma_sq'][ind_idx]
            }

        # êµ¬ì¡°ëª¨ë¸: {param_name: scalar}
        struct_dict = {key: struct_grads[key][ind_idx].item() if hasattr(struct_grads[key][ind_idx], 'item') else struct_grads[key][ind_idx] for key in struct_grads}

        # ì„ íƒëª¨ë¸: {'grad_intercept': scalar, 'grad_beta': array, ...}
        choice_dict = {}
        for key in choice_grads:
            val = choice_grads[key][ind_idx]
            # grad_betaëŠ” ë°°ì—´ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€
            if key == 'grad_beta':
                choice_dict[key] = val
            elif hasattr(val, 'item'):
                choice_dict[key] = val.item()
            else:
                choice_dict[key] = val

        ind_grad_dict = {
            'measurement': meas_dict,
            'structural': struct_dict,
            'choice': choice_dict
        }
        all_individual_gradients.append(ind_grad_dict)

    return all_individual_gradients


def compute_measurement_full_batch_gpu(
    gpu_measurement_model,
    all_ind_data: List[pd.DataFrame],
    all_lvs_gpu,  # CuPy array (326, 100, 5)
    params: Dict,
    all_weights_gpu,  # CuPy array (326, 100)
    lv_names: List[str],
    iteration_logger=None,
    log_level: str = 'MINIMAL'
) -> Dict:
    """
    ì¸¡ì •ëª¨ë¸ Gradient - ì™„ì „ GPU Batch

    Returns:
        {lv_name: {'grad_zeta': (326, n_indicators), 'grad_sigma_sq': (326, n_indicators)}}
    """
    n_individuals, n_draws, n_lvs = all_lvs_gpu.shape

    gradients = {}

    for lv_idx, lv_name in enumerate(lv_names):
        zeta = params[lv_name]['zeta']
        sigma_sq = params[lv_name]['sigma_sq']
        n_indicators = len(zeta)

        config = gpu_measurement_model.models[lv_name].config

        # ëª¨ë“  ê°œì¸ì˜ ê´€ì¸¡ê°’ ì¶”ì¶œ (326, n_indicators)
        all_y = np.zeros((n_individuals, n_indicators))
        for ind_idx, ind_data in enumerate(all_ind_data):
            row = ind_data.iloc[0]
            for i, indicator in enumerate(config.indicators):
                if indicator in row.index and not pd.isna(row[indicator]):
                    all_y[ind_idx, i] = row[indicator]

        all_y_gpu = cp.asarray(all_y)  # (326, n_indicators)
        zeta_gpu = cp.asarray(zeta)  # (n_indicators,)
        sigma_sq_gpu = cp.asarray(sigma_sq)  # (n_indicators,)

        # LV ê°’ ì¶”ì¶œ: (326, 100)
        lv_values_gpu = all_lvs_gpu[:, :, lv_idx]

        # Gradient ì´ˆê¸°í™”
        grad_zeta_all = cp.zeros((n_individuals, n_indicators))
        grad_sigma_sq_all = cp.zeros((n_individuals, n_indicators))

        # ê° ì§€í‘œë³„ë¡œ ê³„ì‚°
        for i in range(n_indicators):
            # ì˜ˆì¸¡ê°’: (326, 100)
            y_pred = zeta_gpu[i] * lv_values_gpu

            # ì”ì°¨: (326, 100)
            residual = all_y_gpu[:, i:i+1] - y_pred

            # Gradient (ê° draw): (326, 100)
            grad_zeta_batch = residual * lv_values_gpu / sigma_sq_gpu[i]
            grad_sigma_sq_batch = -0.5 / sigma_sq_gpu[i] + 0.5 * (residual ** 2) / (sigma_sq_gpu[i] ** 2)

            # ê°€ì¤‘í‰ê· : (326,)
            grad_zeta_all[:, i] = cp.sum(all_weights_gpu * grad_zeta_batch, axis=1)
            grad_sigma_sq_all[:, i] = cp.sum(all_weights_gpu * grad_sigma_sq_batch, axis=1)

        # âœ… fix_first_loading ê³ ë ¤: ì²« ë²ˆì§¸ loadingì´ ê³ ì •ë˜ë©´ gradient ì œì™¸
        fix_first_loading = getattr(config, 'fix_first_loading', True)
        if fix_first_loading:
            # ì²« ë²ˆì§¸ zetaëŠ” 1.0ìœ¼ë¡œ ê³ ì • (gradient ì œì™¸)
            grad_zeta_final = cp.asnumpy(grad_zeta_all[:, 1:])  # (326, n_indicators-1)
        else:
            grad_zeta_final = cp.asnumpy(grad_zeta_all)  # (326, n_indicators)

        gradients[lv_name] = {
            'zeta': grad_zeta_final,
            'sigma_sq': cp.asnumpy(grad_sigma_sq_all)
        }

    return gradients


def compute_structural_full_batch_gpu(
    all_lvs_gpu,  # CuPy array (326, 100, 5)
    params: Dict,
    all_weights_gpu,  # CuPy array (326, 100)
    structural_model,
    lv_names: List[str],
    iteration_logger=None,
    log_level: str = 'MINIMAL'
) -> Dict:
    """
    êµ¬ì¡°ëª¨ë¸ Gradient - ì™„ì „ GPU Batch

    Returns:
        {param_name: (326,)}
    """
    n_individuals, n_draws, n_lvs = all_lvs_gpu.shape

    gradients = {}

    # ê³„ì¸µì  êµ¬ì¡°ì¸ ê²½ìš°
    if hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical:
        error_variance = 1.0

        for path in structural_model.hierarchical_paths:
            target = path['target']
            predictor = path['predictors'][0]  # ë‹¨ì¼ predictor ê°€ì •
            param_key = f"gamma_{predictor}_to_{target}"
            gamma = params[param_key]

            # LV ì¸ë±ìŠ¤ ì°¾ê¸°
            target_idx = lv_names.index(target)
            pred_idx = lv_names.index(predictor)

            # LV ê°’ ì¶”ì¶œ: (326, 100)
            target_values = all_lvs_gpu[:, :, target_idx]
            pred_values = all_lvs_gpu[:, :, pred_idx]

            # ì˜ˆì¸¡ê°’: (326, 100)
            mu = gamma * pred_values

            # ì”ì°¨: (326, 100)
            residual = target_values - mu

            # Gradient: (326, 100)
            weighted_residual = all_weights_gpu * residual / error_variance

            # ê°€ì¤‘í•©: (326,)
            grad_gamma = cp.sum(weighted_residual * pred_values, axis=1)

            # ì ‘ë‘ì‚¬ ì—†ì´ ì €ì¥
            gradients[param_key] = cp.asnumpy(grad_gamma)

    return gradients


def compute_choice_full_batch_gpu(
    all_ind_data: List[pd.DataFrame],
    all_lvs_gpu,  # CuPy array (326, 100, 5)
    params: Dict,
    all_weights_gpu,  # CuPy array (326, 100)
    choice_model,
    lv_names: List[str],
    iteration_logger=None,
    log_level: str = 'MINIMAL'
) -> Dict:
    """
    ì„ íƒëª¨ë¸ Gradient - ì™„ì „ GPU Batch

    Returns:
        {'grad_intercept': (326,), 'grad_beta': (326, 3), 'grad_lambda_main': (326,), ...}
    """
    n_individuals, n_draws, n_lvs = all_lvs_gpu.shape

    # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    intercept = params['intercept']
    beta = params['beta']
    n_attributes = len(beta)

    # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ vs ì¡°ì ˆíš¨ê³¼ vs ê¸°ë³¸ ëª¨ë¸ í™•ì¸
    lambda_lv_keys = [key for key in params.keys() if key.startswith('lambda_') and key not in ['lambda_main']]

    all_lvs_as_main = len(lambda_lv_keys) > 1
    moderation_enabled = 'lambda_main' in params

    # ğŸ” ë””ë²„ê¹…: params í‚¤ í™•ì¸
    if iteration_logger:
        iteration_logger.info(f"[GPU Choice Gradient] params í‚¤: {list(params.keys())}")
        iteration_logger.info(f"[GPU Choice Gradient] lambda_lv_keys: {lambda_lv_keys}")
        iteration_logger.info(f"[GPU Choice Gradient] all_lvs_as_main: {all_lvs_as_main}")

    if all_lvs_as_main:
        # ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸
        lambda_lvs = {}
        for key in lambda_lv_keys:
            lv_name = key.replace('lambda_', '')
            lambda_lvs[lv_name] = params[key]
    elif moderation_enabled:
        # ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
        lambda_main = params['lambda_main']
        lambda_mod = {}
        for key in params:
            if key.startswith('lambda_mod_'):
                mod_lv_name = key.replace('lambda_mod_', '')
                lambda_mod[mod_lv_name] = params[key]
        main_lv = choice_model.config.main_lv
    else:
        # ê¸°ë³¸ ëª¨ë¸
        lambda_lv = params['lambda']
        # main_lv ì°¾ê¸°
        if hasattr(choice_model.config, 'main_lv'):
            main_lv = choice_model.config.main_lv
        else:
            main_lv = 'purchase_intention'  # ê¸°ë³¸ê°’

    choice_attributes = choice_model.config.choice_attributes

    # ëª¨ë“  ê°œì¸ì˜ ì„ íƒ ë°ì´í„° ì¶”ì¶œ
    n_situations = len(all_ind_data[0])
    all_choices = np.zeros((n_individuals, n_situations))
    all_attributes = np.zeros((n_individuals, n_situations, n_attributes))

    # ì„ íƒ ë³€ìˆ˜ ì°¾ê¸°
    choice_var = None
    for col in ['choice', 'chosen', 'choice_binary']:
        if col in all_ind_data[0].columns:
            choice_var = col
            break

    for ind_idx, ind_data in enumerate(all_ind_data):
        for sit_idx in range(n_situations):
            row = ind_data.iloc[sit_idx]
            all_choices[ind_idx, sit_idx] = row[choice_var]
            for attr_idx, attr in enumerate(choice_attributes):
                if attr in row.index and not pd.isna(row[attr]):
                    all_attributes[ind_idx, sit_idx, attr_idx] = row[attr]

    # GPUë¡œ ì „ì†¡
    all_choices_gpu = cp.asarray(all_choices)  # (326, 18)
    all_attr_gpu = cp.asarray(all_attributes)  # (326, 18, 3)
    beta_gpu = cp.asarray(beta)  # (3,)

    # ì†ì„± ë°°ì¹˜: (326, 1, 18, 3)
    attr_batch = all_attr_gpu[:, None, :, :]

    # íš¨ìš© ê³„ì‚°: (326, 100, 18)
    # V = intercept + Î²'X
    V_batch = intercept + cp.sum(attr_batch * beta_gpu[None, None, None, :], axis=-1)

    if all_lvs_as_main:
        # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼: V += Î£(Î»_i * LV_i)
        for lv_name, lambda_val in lambda_lvs.items():
            lv_idx = lv_names.index(lv_name)
            lv_batch = all_lvs_gpu[:, :, lv_idx:lv_idx+1]  # (326, 100, 1)
            V_batch = V_batch + lambda_val * lv_batch
    elif moderation_enabled:
        # ì¡°ì ˆíš¨ê³¼: V += Î»_main * PI + Î£ Î»_mod_k * (PI Ã— LV_k)
        main_lv_idx = lv_names.index(main_lv)
        main_lv_gpu = all_lvs_gpu[:, :, main_lv_idx]
        main_lv_batch = main_lv_gpu[:, :, None]  # (326, 100, 1)

        V_batch = V_batch + lambda_main * main_lv_batch

        for mod_lv_name, lambda_mod_val in lambda_mod.items():
            mod_lv_idx = lv_names.index(mod_lv_name)
            mod_lv_batch = all_lvs_gpu[:, :, mod_lv_idx:mod_lv_idx+1]  # (326, 100, 1)
            interaction = main_lv_batch * mod_lv_batch  # (326, 100, 1)
            V_batch = V_batch + lambda_mod_val * interaction
    else:
        # ê¸°ë³¸ ëª¨ë¸: V += Î» * LV
        main_lv_idx = lv_names.index(main_lv)
        main_lv_gpu = all_lvs_gpu[:, :, main_lv_idx]
        main_lv_batch = main_lv_gpu[:, :, None]  # (326, 100, 1)
        V_batch = V_batch + lambda_lv * main_lv_batch

    # í™•ë¥  ê³„ì‚°: (326, 100, 18)
    prob_batch = cp_ndtr(V_batch)
    prob_batch = cp.clip(prob_batch, 1e-10, 1 - 1e-10)
    phi_batch = cp_norm_pdf(V_batch)

    # ì‹¤ì œ ì„ íƒì— ë”°ë¼: (326, 100, 18)
    choices_batch = all_choices_gpu[:, None, :]  # (326, 1, 18)
    prob_final = cp.where(choices_batch == 1, prob_batch, 1 - prob_batch)

    # Mills ratio: (326, 100, 18)
    mills_batch = phi_batch / prob_final
    sign_batch = cp.where(choices_batch == 1, 1.0, -1.0)

    # Weighted mills: (326, 100, 18)
    weighted_mills = all_weights_gpu[:, :, None] * sign_batch * mills_batch

    # Gradient ê³„ì‚°
    gradients = {}

    # intercept: (326,)
    gradients['intercept'] = cp.asnumpy(cp.sum(weighted_mills, axis=(1, 2)))

    # beta: (326, 3)
    grad_beta = cp.sum(weighted_mills[:, :, :, None] * attr_batch, axis=(1, 2))
    gradients['beta'] = cp.asnumpy(grad_beta)

    if all_lvs_as_main:
        # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼: lambda_{lv_name}
        for lv_name in lambda_lvs.keys():
            lv_idx = lv_names.index(lv_name)
            lv_batch = all_lvs_gpu[:, :, lv_idx:lv_idx+1]  # (326, 100, 1)
            grad_lambda_lv = cp.sum(weighted_mills * lv_batch, axis=(1, 2))
            gradients[f'lambda_{lv_name}'] = cp.asnumpy(grad_lambda_lv)

        # âœ… LV-Attribute ìƒí˜¸ì‘ìš©: gamma_{lv_name}_{attr_name}
        # paramsì—ì„œ gamma_ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        for key in params.keys():
            if key.startswith('gamma_') and '_to_' not in key:
                # gamma_purchase_intention_health_label â†’ lv_name='purchase_intention', attr_name='health_label'
                # choice_attributesë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì‹±
                gamma_str = key.replace('gamma_', '')
                lv_name = None
                attr_name = None

                # ê° ì†ì„± ì´ë¦„ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
                for attr in choice_attributes:
                    if gamma_str.endswith('_' + attr):
                        attr_name = attr
                        lv_name = gamma_str[:-(len(attr) + 1)]  # '_attr' ì œê±°
                        break

                if lv_name and attr_name and lv_name in lv_names:
                    lv_idx = lv_names.index(lv_name)
                    attr_idx = choice_attributes.index(attr_name)
                    lv_batch = all_lvs_gpu[:, :, lv_idx]  # (326, 100)
                    attr_values = all_attr_gpu[:, :, attr_idx]  # (326, 18)
                    # (326, 100, 18) = (326, 100, 1) * (326, 1, 18)
                    interaction = lv_batch[:, :, None] * attr_values[:, None, :]  # (326, 100, 18)
                    grad_gamma = cp.sum(weighted_mills * interaction, axis=(1, 2))
                    gradients[key] = cp.asnumpy(grad_gamma)
    elif moderation_enabled:
        # ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
        main_lv_idx = lv_names.index(main_lv)
        main_lv_gpu = all_lvs_gpu[:, :, main_lv_idx]
        main_lv_batch = main_lv_gpu[:, :, None]  # (326, 100, 1)

        # lambda_main: (326,)
        gradients['lambda_main'] = cp.asnumpy(cp.sum(weighted_mills * main_lv_batch, axis=(1, 2)))

        # lambda_mod: (326,) for each moderator
        for mod_lv_name in lambda_mod.keys():
            mod_lv_idx = lv_names.index(mod_lv_name)
            mod_lv_batch = all_lvs_gpu[:, :, mod_lv_idx:mod_lv_idx+1]  # (326, 100, 1)
            interaction = main_lv_batch * mod_lv_batch  # (326, 100, 1)
            grad_lambda_mod = cp.sum(weighted_mills * interaction, axis=(1, 2))
            gradients[f'lambda_mod_{mod_lv_name}'] = cp.asnumpy(grad_lambda_mod)
    else:
        # ê¸°ë³¸ ëª¨ë¸
        main_lv_idx = lv_names.index(main_lv)
        main_lv_gpu = all_lvs_gpu[:, :, main_lv_idx]
        main_lv_batch = main_lv_gpu[:, :, None]  # (326, 100, 1)

        # lambda: (326,)
        gradients['lambda'] = cp.asnumpy(cp.sum(weighted_mills * main_lv_batch, axis=(1, 2)))

    return gradients


