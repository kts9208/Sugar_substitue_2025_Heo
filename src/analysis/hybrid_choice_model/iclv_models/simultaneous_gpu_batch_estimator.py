"""
ë™ì‹œì¶”ì • GPU ë°°ì¹˜ ì²˜ë¦¬ ICLV Estimator

SimultaneousEstimatorë¥¼ ìƒì†í•˜ì—¬ GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ê°€ì†í•©ë‹ˆë‹¤.
ê°œì¸ë³„ ìš°ë„ ê³„ì‚° ë¶€ë¶„ë§Œ GPU ë°°ì¹˜ë¡œ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤.

ì£¼ì˜: ì´ í´ë˜ìŠ¤ëŠ” ë™ì‹œì¶”ì •(Simultaneous Estimation) ì „ìš©ì…ë‹ˆë‹¤.
ìˆœì°¨ì¶”ì •(Sequential Estimation)ì—ëŠ” SequentialEstimatorë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

import numpy as np
import pandas as pd
from typing import Dict, Optional
from scipy.special import logsumexp
import logging
import gc

from .simultaneous_estimator_fixed import SimultaneousEstimator
from .gpu_measurement_equations import GPUMultiLatentMeasurement
from . import gpu_batch_utils
from scipy.stats import qmc, norm
from .memory_monitor import MemoryMonitor, cleanup_arrays

logger = logging.getLogger(__name__)


class MultiDimensionalHaltonDrawGenerator:
    """
    ë‹¤ì¤‘ ì°¨ì› Halton ì‹œí€€ìŠ¤ ìƒì„±ê¸°

    ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ëª¨ë¸ì„ ìœ„í•œ ë‹¤ì°¨ì› Halton drawsë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def __init__(self, n_draws: int, n_individuals: int, n_dimensions: int,
                 scramble: bool = True, seed: Optional[int] = None):
        """
        Args:
            n_draws: ê°œì¸ë‹¹ draw ìˆ˜
            n_individuals: ê°œì¸ ìˆ˜
            n_dimensions: ì°¨ì› ìˆ˜ (ì ì¬ë³€ìˆ˜ ê°œìˆ˜)
            scramble: ìŠ¤í¬ë¨ë¸” ì—¬ë¶€
            seed: ë‚œìˆ˜ ì‹œë“œ
        """
        self.n_draws = n_draws
        self.n_individuals = n_individuals
        self.n_dimensions = n_dimensions
        self.scramble = scramble
        self.seed = seed

        self.draws = None
        self._generate_draws()

    def _generate_draws(self):
        """ë‹¤ì°¨ì› Halton ì‹œí€€ìŠ¤ ìƒì„±"""
        logger.info(f"ë‹¤ì°¨ì› Halton draws ìƒì„±: {self.n_individuals} ê°œì¸ Ã— {self.n_draws} draws Ã— {self.n_dimensions} ì°¨ì›")

        # scipyì˜ Halton ì‹œí€€ìŠ¤ ìƒì„±ê¸° ì‚¬ìš© (ë‹¤ì°¨ì›)
        sampler = qmc.Halton(d=self.n_dimensions, scramble=self.scramble, seed=self.seed)

        # ê· ë“±ë¶„í¬ [0,1] ìƒ˜í”Œ ìƒì„±
        # (n_individuals * n_draws, n_dimensions)
        uniform_draws = sampler.random(n=self.n_individuals * self.n_draws)

        # í‘œì¤€ì •ê·œë¶„í¬ë¡œ ë³€í™˜ (ì—­ëˆ„ì ë¶„í¬í•¨ìˆ˜)
        normal_draws = norm.ppf(uniform_draws)

        # (n_individuals, n_draws, n_dimensions) í˜•íƒœë¡œ ì¬êµ¬ì„±
        self.draws = normal_draws.reshape(self.n_individuals, self.n_draws, self.n_dimensions)

        logger.info(f"ë‹¤ì°¨ì› Halton draws ìƒì„± ì™„ë£Œ: shape={self.draws.shape}")

    def get_draws(self) -> np.ndarray:
        """ìƒì„±ëœ draws ë°˜í™˜"""
        return self.draws


class SimultaneousGPUBatchEstimator(SimultaneousEstimator):
    """
    ë™ì‹œì¶”ì • GPU ë°°ì¹˜ ì²˜ë¦¬ ICLV Estimator

    SimultaneousEstimatorë¥¼ ìƒì†í•˜ì—¬ GPU ë°°ì¹˜ ì²˜ë¦¬ë¡œ ê°€ì†í•©ë‹ˆë‹¤.
    ê°œì¸ë³„ ìš°ë„ ê³„ì‚° ë¶€ë¶„ë§Œ GPU ë°°ì¹˜ë¡œ ì˜¤ë²„ë¼ì´ë“œí•©ë‹ˆë‹¤.

    ì£¼ì˜: ì´ í´ë˜ìŠ¤ëŠ” ë™ì‹œì¶”ì •(Simultaneous Estimation) ì „ìš©ì…ë‹ˆë‹¤.
    ìˆœì°¨ì¶”ì •(Sequential Estimation)ì—ëŠ” SequentialEstimatorë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    
    def __init__(self, config, use_gpu: bool = True,
                 memory_monitor_cpu_threshold_mb: float = 2000,
                 memory_monitor_gpu_threshold_mb: float = 1500,
                 use_full_parallel: bool = True):
        """
        Args:
            config: MultiLatentConfig ë˜ëŠ” ICLVConfig
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
            memory_monitor_cpu_threshold_mb: CPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
            memory_monitor_gpu_threshold_mb: GPU ë©”ëª¨ë¦¬ ì„ê³„ê°’ (MB)
            use_full_parallel: ì™„ì „ ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš© ì—¬ë¶€ (Advanced Indexing, ê¸°ë³¸ê°’: True)
        """
        super().__init__(config)
        self.use_gpu = use_gpu and gpu_batch_utils.CUPY_AVAILABLE
        self.use_full_parallel = use_full_parallel
        self.gpu_measurement_model = None

        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ì„ê³„ê°’ ì €ì¥ (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
        self.memory_monitor_cpu_threshold_mb = memory_monitor_cpu_threshold_mb
        self.memory_monitor_gpu_threshold_mb = memory_monitor_gpu_threshold_mb
        self.memory_monitor = None  # estimate()ì—ì„œ ì´ˆê¸°í™”

        # ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°ê°’ ì €ì¥
        self.user_initial_params = None

        if self.use_gpu:
            if self.use_full_parallel:
                logger.info("âœ¨ GPU ì™„ì „ ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™” (Advanced Indexing)")
            else:
                logger.info("GPU ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™”")
        else:
            logger.info("GPU ë°°ì¹˜ ì²˜ë¦¬ ë¹„í™œì„±í™” (CPU ëª¨ë“œ)")
    
    def estimate(self, data: pd.DataFrame,
                measurement_model,
                structural_model,
                choice_model,
                log_file: Optional[str] = None,
                initial_params: Optional[np.ndarray] = None) -> Dict:
        """
        ICLV ëª¨ë¸ ì¶”ì • (GPU ë°°ì¹˜ ê°€ì†)

        Args:
            data: ì „ì²´ ë°ì´í„°
            measurement_model: ì¸¡ì •ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            structural_model: êµ¬ì¡°ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            choice_model: ì„ íƒëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            log_file: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            initial_params: ì‚¬ìš©ì ì •ì˜ ì´ˆê¸° íŒŒë¼ë¯¸í„° (ì„ íƒì‚¬í•­)

        Returns:
            ì¶”ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°ê°’ ì €ì¥
        self.user_initial_params = initial_params
        # GPU ì¸¡ì •ëª¨ë¸ ìƒì„±
        if self.use_gpu:
            if hasattr(self.config, 'measurement_configs'):
                # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜
                self.gpu_measurement_model = GPUMultiLatentMeasurement(
                    self.config.measurement_configs,
                    use_gpu=True
                )
                logger.info("GPU ì¸¡ì •ëª¨ë¸ ìƒì„± ì™„ë£Œ (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜)")

                # ë‹¤ì¤‘ ì°¨ì› Halton draws ìƒì„±ì„ ìœ„í•´ structural_model ì €ì¥
                self.structural_model_ref = structural_model
                self.use_multi_dimensional_draws = True
            else:
                # ë‹¨ì¼ ì ì¬ë³€ìˆ˜ - GPU ë°°ì¹˜ ì²˜ë¦¬ ë¯¸ì§€ì›
                logger.warning("ë‹¨ì¼ ì ì¬ë³€ìˆ˜ëŠ” GPU ë°°ì¹˜ ì²˜ë¦¬ ë¯¸ì§€ì›. CPU ëª¨ë“œë¡œ ì „í™˜.")
                self.use_gpu = False
                self.use_multi_dimensional_draws = False
        else:
            self.use_multi_dimensional_draws = False

        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ estimate í˜¸ì¶œ ì „ì— ë°ì´í„° ì €ì¥
        self.data = data

        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„° ì´ˆê¸°í™” (iteration_logger ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œì )
        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ estimate()ì—ì„œ iteration_loggerê°€ ì„¤ì •ë˜ë¯€ë¡œ,
        # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ logger ì‚¬ìš©
        if self.memory_monitor is None:
            self.memory_monitor = MemoryMonitor(
                cpu_threshold_mb=self.memory_monitor_cpu_threshold_mb,
                gpu_threshold_mb=self.memory_monitor_gpu_threshold_mb,
                auto_cleanup=True,
                logger=logger  # ì„ì‹œë¡œ ëª¨ë“ˆ logger ì‚¬ìš©
            )

        # ë‹¤ì¤‘ ì°¨ì› Halton draws ìƒì„± (ë¶€ëª¨ í´ë˜ìŠ¤ í˜¸ì¶œ ì „ì—)
        if self.use_multi_dimensional_draws:
            n_individuals = data[self.config.individual_id_column].nunique()

            # âœ… ê³„ì¸µì  êµ¬ì¡° ì§€ì›
            if structural_model.is_hierarchical:
                # 1ì°¨ LV + 2ì°¨+ LV ì˜¤ì°¨í•­
                n_first_order = len(structural_model.exogenous_lvs)
                n_higher_order = len(structural_model.get_higher_order_lvs())
                n_dimensions = n_first_order + n_higher_order

                logger.info(f"ê³„ì¸µì  êµ¬ì¡°: 1ì°¨ LV={n_first_order}, 2ì°¨+ LV={n_higher_order}, ì´ ì°¨ì›={n_dimensions}")
            else:
                # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
                n_dimensions = structural_model.n_exo + 1  # ì™¸ìƒ LV + ë‚´ìƒ LV ì˜¤ì°¨í•­

            logger.info(f"ë‹¤ì°¨ì› Halton draws ìƒì„± ì‹œì‘... (n_draws={self.config.estimation.n_draws}, n_individuals={n_individuals}, n_dimensions={n_dimensions})")

            self.halton_generator = MultiDimensionalHaltonDrawGenerator(
                n_draws=self.config.estimation.n_draws,
                n_individuals=n_individuals,
                n_dimensions=n_dimensions,
                scramble=self.config.estimation.scramble_halton
            )

            logger.info("ë‹¤ì°¨ì› Halton draws ìƒì„± ì™„ë£Œ")

        # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ estimate í˜¸ì¶œ
        return super().estimate(data, measurement_model, structural_model, choice_model, log_file)
    
    def _log_parameters(self, param_dict: Dict, iteration: int):
        """
        íŒŒë¼ë¯¸í„° ê°’ ë¡œê¹…

        Args:
            param_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            iteration: í˜„ì¬ iteration ë²ˆí˜¸
        """
        if not hasattr(self, 'iteration_logger') or self.iteration_logger is None:
            return

        # ë¡œê¹… ë ˆë²¨ í™•ì¸
        log_level = getattr(self.config.estimation, 'gradient_log_level', 'DETAILED')

        if log_level not in ['MODERATE', 'DETAILED']:
            return

        self.iteration_logger.info("\n" + "="*80)
        self.iteration_logger.info(f"Iteration {iteration} - íŒŒë¼ë¯¸í„° ê°’")
        self.iteration_logger.info("="*80)

        # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        self.iteration_logger.info("\n[ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°]")
        for lv_idx, (lv_name, lv_params) in enumerate(param_dict['measurement'].items()):
            if log_level == 'DETAILED' or lv_idx == 0:
                self.iteration_logger.info(f"  {lv_name}:")
                zeta = lv_params['zeta']
                # ì „ì²´ íŒŒë¼ë¯¸í„° ì¶œë ¥ (ì´ˆê¸°ê°’ ì„¤ì •ìš©)
                self.iteration_logger.info(f"    - zeta: {zeta}")

                if 'sigma_sq' in lv_params:
                    sigma_sq = lv_params['sigma_sq']
                    self.iteration_logger.info(f"    - sigma_sq: {sigma_sq}")
                elif 'tau' in lv_params:
                    tau = lv_params['tau']
                    self.iteration_logger.info(f"    - tau shape: {tau.shape}")

        # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        self.iteration_logger.info("\n[êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°]")
        if hasattr(self.config.structural, 'is_hierarchical') and self.config.structural.is_hierarchical:
            # ê³„ì¸µì  êµ¬ì¡°
            for key, value in param_dict['structural'].items():
                if key.startswith('gamma_'):
                    self.iteration_logger.info(f"  {key}: {value:.6f}")
        else:
            # ë³‘ë ¬ êµ¬ì¡°
            if 'gamma_lv' in param_dict['structural']:
                self.iteration_logger.info(f"  gamma_lv: {param_dict['structural']['gamma_lv']}")
            if 'gamma_x' in param_dict['structural']:
                self.iteration_logger.info(f"  gamma_x: {param_dict['structural']['gamma_x']}")

        # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        self.iteration_logger.info("\n[ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°]")
        choice_params = param_dict['choice']
        self.iteration_logger.info(f"  intercept: {choice_params['intercept']:.6f}")
        self.iteration_logger.info(f"  beta: {choice_params['beta']}")

        if 'lambda_main' in choice_params:
            # ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
            self.iteration_logger.info(f"  lambda_main: {choice_params['lambda_main']:.6f}")
            for key in choice_params:
                if key.startswith('lambda_mod_'):
                    self.iteration_logger.info(f"  {key}: {choice_params[key]:.6f}")
        else:
            # ê¸°ë³¸ ëª¨ë¸
            self.iteration_logger.info(f"  lambda: {choice_params['lambda']:.6f}")

        self.iteration_logger.info("="*80)

    def _joint_log_likelihood(self, params: np.ndarray,
                             measurement_model,
                             structural_model,
                             choice_model) -> float:
        """
        ê²°í•© ë¡œê·¸ìš°ë„ ê³„ì‚° (ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¶”ê°€)

        ë¶€ëª¨ í´ë˜ìŠ¤ì˜ _joint_log_likelihoodë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬
        Halton draws ê°€ì ¸ì˜¤ê¸° ì „í›„ ë©”ëª¨ë¦¬ ë¡œê·¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        # í˜„ì¬ iteration ë²ˆí˜¸ ì €ì¥ (ê°œì¸ë³„ ìš°ë„ ê³„ì‚° ë¡œê·¸ì— ì‚¬ìš©)
        if not hasattr(self, '_current_iteration'):
            self._current_iteration = 0
        self._current_iteration += 1

        # ê° iteration ì‹œì‘ ì‹œ ê°œì¸ë³„ ì¹´ìš´í„° ë¦¬ì…‹
        self._individual_likelihood_count = 0

        # íŒŒë¼ë¯¸í„° ë¶„í•´
        param_dict = self._unpack_parameters(
            params, measurement_model, structural_model, choice_model
        )

        # íŒŒë¼ë¯¸í„° ë¡œê¹… (ì²˜ìŒ 3ë²ˆ ë˜ëŠ” 10ì˜ ë°°ìˆ˜ iteration)
        if self._current_iteration <= 3 or self._current_iteration % 10 == 0:
            self._log_parameters(param_dict, self._current_iteration)

        # ë©”ëª¨ë¦¬ ì²´í¬ (Halton draws ê°€ì ¸ì˜¤ê¸° ì „) - ë¹„í™œì„±í™”
        # if hasattr(self, 'memory_monitor') and hasattr(self, '_likelihood_call_count'):
        #     self.memory_monitor.log_memory_stats(f"Halton draws ê°€ì ¸ì˜¤ê¸° ì „ (Iter {self._current_iteration})")

        draws = self.halton_generator.get_draws()

        # ë©”ëª¨ë¦¬ ì²´í¬ (Halton draws ê°€ì ¸ì˜¨ í›„) - ë¹„í™œì„±í™”
        # if hasattr(self, 'memory_monitor') and hasattr(self, '_likelihood_call_count'):
        #     self.memory_monitor.log_memory_stats(f"Halton draws ê°€ì ¸ì˜¨ í›„ (Iter {self._current_iteration})")

        individual_ids = self.data[self.config.individual_id_column].unique()

        # ìˆœì°¨ì²˜ë¦¬ (GPU ë°°ì¹˜ëŠ” _compute_individual_likelihoodì—ì„œ ì²˜ë¦¬)
        total_ll = 0.0
        for i, ind_id in enumerate(individual_ids):
            ind_data = self.data[self.data[self.config.individual_id_column] == ind_id]
            ind_draws = draws[i, :]

            person_ll = self._compute_individual_likelihood(
                ind_id, ind_data, ind_draws, param_dict,
                measurement_model, structural_model, choice_model
            )
            total_ll += person_ll

        return total_ll

    def _compute_individual_likelihood(self, ind_id, ind_data, ind_draws,
                                       param_dict, measurement_model,
                                       structural_model, choice_model) -> float:
        """
        ê°œì¸ë³„ ìš°ë„ ê³„ì‚° (GPU ë°°ì¹˜ ê°€ì† ë²„ì „)

        SimultaneousEstimatorì˜ ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ GPU ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        n_draws = len(ind_draws)

        # ë©”ëª¨ë¦¬ ì²´í¬ (ìš°ë„ ê³„ì‚° ì „)
        mem_info = self.memory_monitor.check_and_cleanup(f"ìš°ë„ ê³„ì‚° - ê°œì¸ {ind_id}")

        if self.use_gpu and self.gpu_measurement_model is not None:
            # GPU ë°°ì¹˜ ì²˜ë¦¬
            draw_lls = self._compute_draws_batch_gpu(
                ind_data, ind_draws, param_dict,
                structural_model, choice_model
            )
        else:
            # CPU ìˆœì°¨ ì²˜ë¦¬ (ë¶€ëª¨ í´ë˜ìŠ¤ì™€ ë™ì¼)
            draw_lls = []

            for j in range(n_draws):
                draw = ind_draws[j]

                # êµ¬ì¡°ëª¨ë¸: LV ì˜ˆì¸¡
                if hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical:
                    # âœ… ê³„ì¸µì  êµ¬ì¡°
                    n_first_order = len(structural_model.exogenous_lvs)
                    exo_draws = draw[:n_first_order]

                    # 2ì°¨+ LV ì˜¤ì°¨í•­
                    higher_order_draws = {}
                    higher_order_lvs = structural_model.get_higher_order_lvs()
                    for i, lv_name in enumerate(higher_order_lvs):
                        higher_order_draws[lv_name] = draw[n_first_order + i]

                    lv = structural_model.predict(
                        ind_data, exo_draws, param_dict['structural'],
                        higher_order_draws=higher_order_draws
                    )

                elif hasattr(structural_model, 'endogenous_lv'):
                    # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
                    n_exo = structural_model.n_exo
                    exo_draws = draw[:n_exo]
                    endo_draw = draw[n_exo]
                    lv = structural_model.predict(ind_data, exo_draws, param_dict['structural'], endo_draw)
                else:
                    # ë‹¨ì¼ ì ì¬ë³€ìˆ˜
                    lv = structural_model.predict(ind_data, param_dict['structural'], draw)

                # ì¸¡ì •ëª¨ë¸ ìš°ë„
                ll_measurement = measurement_model.log_likelihood(
                    ind_data, lv, param_dict['measurement']
                )

                # ì„ íƒëª¨ë¸ ìš°ë„ (Panel Product)
                choice_set_lls = []
                for idx in range(len(ind_data)):
                    ll_choice_t = choice_model.log_likelihood(
                        ind_data.iloc[idx:idx+1],
                        lv,
                        param_dict['choice']
                    )
                    choice_set_lls.append(ll_choice_t)

                ll_choice = sum(choice_set_lls)

                # êµ¬ì¡°ëª¨ë¸ ìš°ë„
                if hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical:
                    # âœ… ê³„ì¸µì  êµ¬ì¡°
                    ll_structural = structural_model.log_likelihood(
                        ind_data, lv, exo_draws, param_dict['structural'],
                        higher_order_draws=higher_order_draws
                    )
                elif hasattr(structural_model, 'endogenous_lv'):
                    # ë³‘ë ¬ êµ¬ì¡°
                    ll_structural = structural_model.log_likelihood(
                        ind_data, lv, exo_draws, param_dict['structural'], endo_draw
                    )
                else:
                    # ë‹¨ì¼ ì ì¬ë³€ìˆ˜
                    ll_structural = structural_model.log_likelihood(
                        ind_data, lv, param_dict['structural'], draw
                    )

                # ê²°í•© ë¡œê·¸ìš°ë„
                draw_ll = ll_measurement + ll_choice + ll_structural

                # ğŸ” ë””ë²„ê¹…: ì²« ë²ˆì§¸ drawì˜ ìš°ë„ ë¶„í•´
                if j == 0 and not hasattr(self, '_ll_debug_logged'):
                    self._ll_debug_logged = True
                    print(f"[DEBUG LL Components] Measurement={ll_measurement:.4f}, Choice={ll_choice:.4f}, Structural={ll_structural:.4f}, Total={draw_ll:.4f}")

                if not np.isfinite(draw_ll):
                    draw_ll = -1e10

                draw_lls.append(draw_ll)
        
        # ê°œì¸ ìš°ë„: log(1/R * sum(exp(draw_lls)))
        person_ll = logsumexp(draw_lls) - np.log(n_draws)
        
        return person_ll
    
    def _compute_draws_batch_gpu(self, ind_data, ind_draws, param_dict,
                                 structural_model, choice_model):
        """
        ê°œì¸ì˜ ëª¨ë“  drawsì— ëŒ€í•œ ìš°ë„ë¥¼ GPU ë°°ì¹˜ë¡œ ê³„ì‚°

        Args:
            ind_data: ê°œì¸ ë°ì´í„°
            ind_draws: ê°œì¸ì˜ draws (n_draws, n_dimensions)
            param_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            structural_model: êµ¬ì¡°ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
            choice_model: ì„ íƒëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

        Returns:
            ê° drawì˜ ë¡œê·¸ìš°ë„ ë¦¬ìŠ¤íŠ¸
        """
        # ë©”ëª¨ë¦¬ ì²´í¬ (GPU ë°°ì¹˜ ìš°ë„ ê³„ì‚° ì „) - ë¡œê¹… ì—†ì´ ì„ê³„ê°’ë§Œ ì²´í¬
        if hasattr(self, 'memory_monitor'):
            # ê°œì¸ë³„ ì¹´ìš´í„° ì¦ê°€
            self._individual_likelihood_count += 1

            # ì„ê³„ê°’ ì²´í¬ ë° í•„ìš”ì‹œ ì •ë¦¬ (ë¡œê¹… ì—†ìŒ)
            mem_info = self.memory_monitor.check_and_cleanup("GPU ë°°ì¹˜ ìš°ë„ ê³„ì‚°")

        n_draws = len(ind_draws)

        # ì²« ë²ˆì§¸ ê°œì¸ì˜ ì²« ë²ˆì§¸ drawì— ëŒ€í•´ì„œë§Œ ìƒì„¸ ë¡œê¹…
        log_detail = not hasattr(self, '_first_draw_logged')

        # if log_detail:
        #     self.iteration_logger.info("=" * 80)
        #     self.iteration_logger.info("ì²« ë²ˆì§¸ ê°œì¸ì˜ ì²« ë²ˆì§¸ draw ìƒì„¸ ë¡œê¹…")
        #     self.iteration_logger.info("=" * 80)
        #     self.iteration_logger.info(f"[íŒŒë¼ë¯¸í„° í™•ì¸]")
        #     self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ zeta (health_concern ì²˜ìŒ 3ê°œ): {param_dict['measurement']['health_concern']['zeta'][:3]}")
        #     self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ gamma_lv: {param_dict['structural']['gamma_lv']}")
        #     self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ gamma_x: {param_dict['structural']['gamma_x']}")
        #     self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ intercept: {param_dict['choice']['intercept']}")
        #     self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ beta: {param_dict['choice']['beta']}")
        #     self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ lambda: {param_dict['choice']['lambda']}")

        # 1. ëª¨ë“  drawsì— ëŒ€í•œ ì ì¬ë³€ìˆ˜ ì˜ˆì¸¡
        lvs_list = []
        for j in range(n_draws):
            draw = ind_draws[j]

            if hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical:
                # âœ… ê³„ì¸µì  êµ¬ì¡°
                n_first_order = len(structural_model.exogenous_lvs)
                exo_draws = draw[:n_first_order]

                # 2ì°¨+ LV ì˜¤ì°¨í•­
                higher_order_draws = {}
                higher_order_lvs = structural_model.get_higher_order_lvs()
                for i, lv_name in enumerate(higher_order_lvs):
                    higher_order_draws[lv_name] = draw[n_first_order + i]

                lv = structural_model.predict(
                    ind_data, exo_draws, param_dict['structural'],
                    higher_order_draws=higher_order_draws
                )

                if log_detail and j == 0:
                    self.iteration_logger.info(f"[êµ¬ì¡°ëª¨ë¸ ì˜ˆì¸¡ - ê³„ì¸µì ] Draw 0:")
                    self.iteration_logger.info(f"  1ì°¨ LV draws: {exo_draws}")
                    self.iteration_logger.info(f"  2ì°¨+ LV ì˜¤ì°¨í•­: {higher_order_draws}")
                    self.iteration_logger.info(f"  ì˜ˆì¸¡ëœ LV: {lv}")

            elif hasattr(structural_model, 'endogenous_lv'):
                # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
                n_exo = structural_model.n_exo
                exo_draws = draw[:n_exo]
                endo_draw = draw[n_exo]
                lv = structural_model.predict(ind_data, exo_draws, param_dict['structural'], endo_draw)

                if log_detail and j == 0:
                    self.iteration_logger.info(f"[êµ¬ì¡°ëª¨ë¸ ì˜ˆì¸¡ - ë³‘ë ¬] Draw 0:")
                    self.iteration_logger.info(f"  ì™¸ìƒ draws: {exo_draws}")
                    self.iteration_logger.info(f"  ë‚´ìƒ draw: {endo_draw}")
                    self.iteration_logger.info(f"  ì˜ˆì¸¡ëœ LV: {lv}")
            else:
                # ë‹¨ì¼ ì ì¬ë³€ìˆ˜
                lv = structural_model.predict(ind_data, param_dict['structural'], draw)

            lvs_list.append(lv)
        
        # 2. ì¸¡ì •ëª¨ë¸ ìš°ë„ (GPU ë°°ì¹˜)
        if log_detail:
            self.iteration_logger.info("\n[ì¸¡ì •ëª¨ë¸ ìš°ë„ ê³„ì‚° ì‹œì‘]")
            self.iteration_logger.info(f"  ê°œì¸ ë°ì´í„° shape: {ind_data.shape}")
            self.iteration_logger.info(f"  LV ê°œìˆ˜: {len(lvs_list)}")

        ll_measurement_batch = gpu_batch_utils.compute_measurement_batch_gpu(
            self.gpu_measurement_model,
            ind_data,
            lvs_list,
            param_dict['measurement'],
            self.iteration_logger if log_detail else None
        )

        if log_detail:
            self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ ìš°ë„ (ì²˜ìŒ 5ê°œ): {ll_measurement_batch[:5]}")
            self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ ìš°ë„ ë²”ìœ„: [{np.min(ll_measurement_batch):.2f}, {np.max(ll_measurement_batch):.2f}]")
            self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ ìš°ë„ í‰ê· : {np.mean(ll_measurement_batch):.2f}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì¸¡ì •ëª¨ë¸ ê³„ì‚° í›„)
        gc.collect()

        # 3. ì„ íƒëª¨ë¸ ìš°ë„ (GPU ë°°ì¹˜)
        if log_detail:
            self.iteration_logger.info("\n[ì„ íƒëª¨ë¸ ìš°ë„ ê³„ì‚° ì‹œì‘]")
            self.iteration_logger.info(f"  ì„ íƒ ìƒí™© ìˆ˜: {len(ind_data)}")

        ll_choice_batch = gpu_batch_utils.compute_choice_batch_gpu(
            ind_data,
            lvs_list,
            param_dict['choice'],
            choice_model,
            self.iteration_logger if log_detail else None
        )

        if log_detail:
            self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ ìš°ë„ (ì²˜ìŒ 5ê°œ): {ll_choice_batch[:5]}")
            self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ ìš°ë„ ë²”ìœ„: [{np.min(ll_choice_batch):.2f}, {np.max(ll_choice_batch):.2f}]")
            self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ ìš°ë„ í‰ê· : {np.mean(ll_choice_batch):.2f}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì„ íƒëª¨ë¸ ê³„ì‚° í›„)
        gc.collect()

        # 4. êµ¬ì¡°ëª¨ë¸ ìš°ë„ (GPU ë°°ì¹˜)
        if log_detail:
            self.iteration_logger.info("\n[êµ¬ì¡°ëª¨ë¸ ìš°ë„ ê³„ì‚° ì‹œì‘]")

        ll_structural_batch = gpu_batch_utils.compute_structural_batch_gpu(
            ind_data,
            lvs_list,
            param_dict['structural'],
            ind_draws,
            structural_model,
            self.iteration_logger if log_detail else None
        )

        if log_detail:
            self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ ìš°ë„ (ì²˜ìŒ 5ê°œ): {ll_structural_batch[:5]}")
            self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ ìš°ë„ ë²”ìœ„: [{np.min(ll_structural_batch):.2f}, {np.max(ll_structural_batch):.2f}]")
            self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ ìš°ë„ í‰ê· : {np.mean(ll_structural_batch):.2f}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬ (êµ¬ì¡°ëª¨ë¸ ê³„ì‚° í›„)
        gc.collect()

        # 5. ê²°í•© ë¡œê·¸ìš°ë„
        draw_lls = []
        for j in range(n_draws):
            draw_ll = ll_measurement_batch[j] + ll_choice_batch[j] + ll_structural_batch[j]

            if log_detail and j == 0:
                self.iteration_logger.info("\n[ê²°í•© ìš°ë„ ê³„ì‚°] Draw 0:")
                self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸: {ll_measurement_batch[j]:.4f}")
                self.iteration_logger.info(f"  ì„ íƒëª¨ë¸: {ll_choice_batch[j]:.4f}")
                self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸: {ll_structural_batch[j]:.4f}")
                self.iteration_logger.info(f"  í•©ê³„: {draw_ll:.4f}")

            if not np.isfinite(draw_ll):
                if log_detail and j == 0:
                    self.iteration_logger.warning(f"  âš ï¸ Draw {j}: ë¹„ìœ í•œ ê°’ ê°ì§€, -1e10ìœ¼ë¡œ ëŒ€ì²´")
                draw_ll = -1e10

            draw_lls.append(draw_ll)

        if log_detail:
            self.iteration_logger.info("\n[ì „ì²´ draws í†µê³„]")
            self.iteration_logger.info(f"  Draw ìš°ë„ ë²”ìœ„: [{np.min(draw_lls):.2f}, {np.max(draw_lls):.2f}]")
            self.iteration_logger.info(f"  Draw ìš°ë„ í‰ê· : {np.mean(draw_lls):.2f}")
            self.iteration_logger.info("=" * 80)
            self._first_draw_logged = True

        # ë‘ ë²ˆì§¸ í•¨ìˆ˜ í˜¸ì¶œì—ì„œ íŒŒë¼ë¯¸í„° ë³€í™” í™•ì¸
        if hasattr(self, '_first_draw_logged') and not hasattr(self, '_second_draw_logged'):
            self.iteration_logger.info("=" * 80)
            self.iteration_logger.info("ë‘ ë²ˆì§¸ í•¨ìˆ˜ í˜¸ì¶œ - íŒŒë¼ë¯¸í„° ë³€í™” í™•ì¸")
            self.iteration_logger.info("=" * 80)
            self.iteration_logger.info(f"[íŒŒë¼ë¯¸í„° í™•ì¸]")
            self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ zeta (health_concern ì²˜ìŒ 3ê°œ): {param_dict['measurement']['health_concern']['zeta'][:3]}")

            # âœ… ê³„ì¸µì  êµ¬ì¡° ì§€ì›
            if hasattr(self.config.structural, 'is_hierarchical') and self.config.structural.is_hierarchical:
                # ê³„ì¸µì  êµ¬ì¡°: ê°œë³„ ê²½ë¡œ íŒŒë¼ë¯¸í„°
                first_param = list(param_dict['structural'].keys())[0]
                self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ (ê³„ì¸µì ) {first_param}: {param_dict['structural'][first_param]}")
            else:
                # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
                self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ gamma_lv: {param_dict['structural']['gamma_lv']}")
                self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ gamma_x: {param_dict['structural']['gamma_x']}")

            self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ intercept: {param_dict['choice']['intercept']}")
            self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ beta: {param_dict['choice']['beta']}")

            # âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›
            if 'lambda_main' in param_dict['choice']:
                self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ lambda_main: {param_dict['choice']['lambda_main']}")
                for key in param_dict['choice']:
                    if key.startswith('lambda_mod_'):
                        self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ {key}: {param_dict['choice'][key]}")
            else:
                self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ lambda: {param_dict['choice']['lambda']}")

            self.iteration_logger.info("=" * 80)
            self._second_draw_logged = True

        return draw_lls

    def _get_initial_parameters(self, measurement_model,
                                structural_model, choice_model) -> np.ndarray:
        """
        ì´ˆê¸° íŒŒë¼ë¯¸í„° ì„¤ì • (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì§€ì›)

        âœ… ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°ê°’ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        âœ… ì—†ìœ¼ë©´ ìµœì¢… ìˆ˜ë ´ê°’ (Iteration 24) ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
        """
        # ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°ê°’ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        if self.user_initial_params is not None:
            logger.info(f"ì‚¬ìš©ì ì •ì˜ ì´ˆê¸°ê°’ ì‚¬ìš© (íŒŒë¼ë¯¸í„° ìˆ˜: {len(self.user_initial_params)})")
            return self.user_initial_params

        from .initial_values_final import (
            get_zeta_initial_value,
            get_sigma_sq_initial_value,
            ZETA_INITIAL_VALUES,
            SIGMA_SQ_INITIAL_VALUES
        )

        params = []

        # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        if hasattr(self.config, 'measurement_configs'):
            # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜
            for lv_name, config in self.config.measurement_configs.items():
                # measurement_method í™•ì¸
                method = getattr(config, 'measurement_method', 'continuous_linear')

                if method == 'continuous_linear':
                    # ContinuousLinearMeasurement
                    n_indicators = len(config.indicators)

                    # ìš”ì¸ì ì¬ëŸ‰ (zeta)
                    # âœ… Iteration 40 ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
                    if lv_name in ZETA_INITIAL_VALUES:
                        zeta_values = ZETA_INITIAL_VALUES[lv_name]['values']
                        if config.fix_first_loading:
                            # ì²« ë²ˆì§¸ëŠ” 1.0ìœ¼ë¡œ ê³ ì • (íŒŒë¼ë¯¸í„° ë²¡í„°ì— í¬í•¨í•˜ì§€ ì•ŠìŒ)
                            params.extend(zeta_values)
                        else:
                            # ì²« ë²ˆì§¸ë„ í¬í•¨
                            params.extend([1.0] + zeta_values)
                    else:
                        # ê¸°ë³¸ê°’ (ì´ì „ ë°©ì‹)
                        zeta_init = get_zeta_initial_value(lv_name, default=0.05)
                        if config.fix_first_loading:
                            params.extend([zeta_init] * (n_indicators - 1))
                        else:
                            params.extend([zeta_init] * n_indicators)

                    # ì˜¤ì°¨ë¶„ì‚° (sigma_sq)
                    # âœ… Iteration 40 ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
                    if lv_name in SIGMA_SQ_INITIAL_VALUES:
                        sigma_sq_values = SIGMA_SQ_INITIAL_VALUES[lv_name]['values']
                        if not config.fix_error_variance:
                            params.extend(sigma_sq_values)
                    else:
                        # ê¸°ë³¸ê°’ (ì´ì „ ë°©ì‹)
                        sigma_sq_init = get_sigma_sq_initial_value(lv_name, default=0.03)
                        if not config.fix_error_variance:
                            params.extend([sigma_sq_init] * n_indicators)

                elif method == 'ordered_probit':
                    # OrderedProbitMeasurement
                    n_indicators = len(config.indicators)
                    n_thresholds = config.n_categories - 1

                    # ìš”ì¸ì ì¬ëŸ‰ (zeta)
                    params.extend([1.0] * n_indicators)

                    # ì„ê³„ê°’ (tau)
                    for _ in range(n_indicators):
                        if n_thresholds == 4:
                            params.extend([-2, -1, 1, 2])  # 5ì  ì²™ë„
                        elif n_thresholds == 1:
                            params.extend([0.0])  # 2ì  ì²™ë„
                        else:
                            # ì¼ë°˜ì ì¸ ê²½ìš°
                            params.extend(list(range(-n_thresholds//2 + 1, n_thresholds//2 + 1)))

                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸¡ì • ë°©ë²•: {method}")
        else:
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜
            n_indicators = len(self.config.measurement.indicators)
            params.extend([1.0] * n_indicators)

            n_thresholds = self.config.measurement.n_categories - 1
            for _ in range(n_indicators):
                params.extend([-2, -1, 1, 2])

        # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        if hasattr(self.config.structural, 'is_hierarchical') and self.config.structural.is_hierarchical:
            # âœ… ê³„ì¸µì  êµ¬ì¡°
            from .initial_values_final import get_gamma_initial_value

            for path in self.config.structural.hierarchical_paths:
                target = path['target']
                predictors = path['predictors']

                for pred in predictors:
                    # âœ… ìµœì¢… ìˆ˜ë ´ê°’ ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
                    path_name = f'{pred}_to_{target}'
                    gamma_init = get_gamma_initial_value(path_name, default=0.5)
                    params.append(gamma_init)
        elif hasattr(self.config.structural, 'n_exo'):
            # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
            n_exo = self.config.structural.n_exo
            n_cov = self.config.structural.n_cov

            # gamma_lv (ì™¸ìƒ LV â†’ ë‚´ìƒ LV)
            params.extend([0.0] * n_exo)

            # gamma_x (ê³µë³€ëŸ‰ â†’ ë‚´ìƒ LV)
            params.extend([0.0] * n_cov)
        else:
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜ êµ¬ì¡°ëª¨ë¸
            n_sociodem = len(self.config.structural.sociodemographics)
            params.extend([0.0] * n_sociodem)

        # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        from .initial_values_final import get_choice_initial_value

        # - ì ˆí¸
        # âœ… ìµœì¢… ìˆ˜ë ´ê°’ ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
        params.append(get_choice_initial_value('intercept', default=0.0))

        # - ì†ì„± ê³„ìˆ˜ (beta)
        # âœ… ìµœì¢… ìˆ˜ë ´ê°’ ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
        n_attributes = len(self.config.choice.choice_attributes)
        for attr in self.config.choice.choice_attributes:
            if 'price' in attr.lower():
                params.append(get_choice_initial_value('beta_price', default=-0.26))
            elif 'sugar' in attr.lower():
                params.append(get_choice_initial_value('beta_sugar_free', default=0.23))
            elif 'health' in attr.lower():
                params.append(get_choice_initial_value('beta_health_label', default=0.23))
            else:
                # ê¸°íƒ€ ì†ì„±
                params.append(0.2)

        # - ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
        # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ì§€ì›
        if hasattr(self.config.choice, 'all_lvs_as_main') and self.config.choice.all_lvs_as_main:
            # ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸: lambda_{lv_name}
            if hasattr(self.config.choice, 'main_lvs'):
                for lv_name in self.config.choice.main_lvs:
                    # ê° LVë³„ ì´ˆê¸°ê°’ (1.0)
                    params.append(1.0)
        elif hasattr(self.config.choice, 'moderation_enabled') and self.config.choice.moderation_enabled:
            # âœ… ì¡°ì ˆíš¨ê³¼ ëª¨ë¸ - ìµœì¢… ìˆ˜ë ´ê°’ ê¸°ë°˜ ì´ˆê¸°ê°’ ì‚¬ìš©
            params.append(get_choice_initial_value('lambda_main', default=0.45))

            # lambda_mod (ì¡°ì ˆíš¨ê³¼ ê³„ìˆ˜)
            for mod_lv in self.config.choice.moderator_lvs:
                if 'price' in mod_lv.lower():
                    params.append(get_choice_initial_value('lambda_mod_perceived_price', default=-1.50))
                elif 'knowledge' in mod_lv.lower():
                    params.append(get_choice_initial_value('lambda_mod_nutrition_knowledge', default=1.05))
                else:
                    params.append(0.0)
        else:
            # ê¸°ë³¸ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
            params.append(1.0)

        return np.array(params)

    def _get_parameter_bounds(self, measurement_model,
                              structural_model, choice_model) -> list:
        """
        íŒŒë¼ë¯¸í„° bounds ì„¤ì • (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì§€ì›)
        """
        bounds = []

        # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        if hasattr(self.config, 'measurement_configs'):
            # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜
            for lv_name, config in self.config.measurement_configs.items():
                # measurement_method í™•ì¸
                method = getattr(config, 'measurement_method', 'continuous_linear')

                if method == 'continuous_linear':
                    # ContinuousLinearMeasurement
                    n_indicators = len(config.indicators)

                    # ìš”ì¸ì ì¬ëŸ‰ (zeta): [-10, 10]
                    if config.fix_first_loading:
                        # ì²« ë²ˆì§¸ëŠ” ê³ ì • (íŒŒë¼ë¯¸í„° ë²¡í„°ì— í¬í•¨í•˜ì§€ ì•ŠìŒ)
                        bounds.extend([(-10.0, 10.0)] * (n_indicators - 1))
                    else:
                        bounds.extend([(-10.0, 10.0)] * n_indicators)

                    # ì˜¤ì°¨ë¶„ì‚° (sigma_sq): [0.01, 100]
                    if not config.fix_error_variance:
                        bounds.extend([(0.01, 100.0)] * n_indicators)

                elif method == 'ordered_probit':
                    # OrderedProbitMeasurement
                    n_indicators = len(config.indicators)
                    n_thresholds = config.n_categories - 1

                    # ìš”ì¸ì ì¬ëŸ‰ (zeta): [0.1, 10]
                    bounds.extend([(0.1, 10.0)] * n_indicators)

                    # ì„ê³„ê°’ (tau): [-10, 10]
                    for _ in range(n_indicators):
                        bounds.extend([(-10.0, 10.0)] * n_thresholds)

                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸¡ì • ë°©ë²•: {method}")
        else:
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜
            n_indicators = len(self.config.measurement.indicators)
            bounds.extend([(0.1, 10.0)] * n_indicators)

            n_thresholds = self.config.measurement.n_categories - 1
            for _ in range(n_indicators):
                bounds.extend([(-10.0, 10.0)] * n_thresholds)

        # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        if hasattr(self.config.structural, 'is_hierarchical') and self.config.structural.is_hierarchical:
            # âœ… ê³„ì¸µì  êµ¬ì¡°
            for path in self.config.structural.hierarchical_paths:
                predictors = path['predictors']

                for pred in predictors:
                    # gamma: unbounded
                    bounds.append((None, None))
        elif hasattr(self.config.structural, 'n_exo'):
            # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
            n_exo = self.config.structural.n_exo
            n_cov = self.config.structural.n_cov

            # gamma_lv: unbounded
            bounds.extend([(None, None)] * n_exo)

            # gamma_x: unbounded
            bounds.extend([(None, None)] * n_cov)
        else:
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜ êµ¬ì¡°ëª¨ë¸
            n_sociodem = len(self.config.structural.sociodemographics)
            bounds.extend([(None, None)] * n_sociodem)

        # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        # - ì ˆí¸: unbounded
        bounds.append((None, None))

        # - ì†ì„± ê³„ìˆ˜ (beta): unbounded
        n_attributes = len(self.config.choice.choice_attributes)
        bounds.extend([(None, None)] * n_attributes)

        # - ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
        if hasattr(self.config.choice, 'moderation_enabled') and self.config.choice.moderation_enabled:
            # âœ… ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
            # lambda_main: unbounded
            bounds.append((None, None))

            # lambda_mod: unbounded
            for mod_lv in self.config.choice.moderator_lvs:
                bounds.append((None, None))
        else:
            # ê¸°ë³¸ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
            bounds.append((None, None))

        return bounds

    def _unpack_parameters(self, params: np.ndarray,
                          measurement_model,
                          structural_model,
                          choice_model) -> Dict[str, Dict]:
        """
        íŒŒë¼ë¯¸í„° ë²¡í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì§€ì›)
        """
        # ë””ë²„ê¹…: íŒŒë¼ë¯¸í„° ì–¸íŒ© í˜¸ì¶œ í™•ì¸ (ê°„ì†Œí™”)
        if hasattr(self, 'iteration_logger') and self.iteration_logger is not None:
            if not hasattr(self, '_unpack_count'):
                self._unpack_count = 0
            self._unpack_count += 1
            # âœ… íŒŒë¼ë¯¸í„° ì–¸íŒ© ë¡œê¹… ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ë¡œê¹… í¬í•¨)
            # ì²˜ìŒ 3ë²ˆë§Œ ë¡œê¹…
            # if self._unpack_count <= 3:
            #     self.iteration_logger.info(f"[íŒŒë¼ë¯¸í„° ì–¸íŒ© #{self._unpack_count}] ì²˜ìŒ 5ê°œ: {params[:5]}, ë§ˆì§€ë§‰ 5ê°œ: {params[-5:]}")

            # ë©”ëª¨ë¦¬ ì²´í¬ (íŒŒë¼ë¯¸í„° ì–¸íŒ© ì‹œ) - ë¹„í™œì„±í™”
            # if hasattr(self, 'memory_monitor'):
            #     self.memory_monitor.log_memory_stats(f"íŒŒë¼ë¯¸í„° ì–¸íŒ© #{self._unpack_count}")
            #
            #     # í•­ìƒ ì„ê³„ê°’ ì²´í¬ ë° í•„ìš”ì‹œ ì •ë¦¬
            #     mem_info = self.memory_monitor.check_and_cleanup(f"íŒŒë¼ë¯¸í„° ì–¸íŒ© #{self._unpack_count}")

        idx = 0
        param_dict = {
            'measurement': {},
            'structural': {},
            'choice': {}
        }

        # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        if hasattr(self.config, 'measurement_configs'):
            # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜
            for lv_idx, (lv_name, config) in enumerate(self.config.measurement_configs.items()):
                # measurement_method í™•ì¸
                method = getattr(config, 'measurement_method', 'continuous_linear')

                if method == 'continuous_linear':
                    # ContinuousLinearMeasurement
                    n_indicators = len(config.indicators)

                    # ìš”ì¸ì ì¬ëŸ‰ (zeta)
                    if config.fix_first_loading:
                        zeta = np.ones(n_indicators)
                        zeta[0] = 1.0  # ê³ ì •
                        zeta[1:] = params[idx:idx + n_indicators - 1]
                        idx += n_indicators - 1
                    else:
                        zeta = params[idx:idx + n_indicators]
                        idx += n_indicators

                    # ì˜¤ì°¨ë¶„ì‚° (sigma_sq)
                    if config.fix_error_variance:
                        sigma_sq = np.ones(n_indicators) * config.initial_error_variance
                    else:
                        sigma_sq = params[idx:idx + n_indicators]
                        idx += n_indicators

                    param_dict['measurement'][lv_name] = {'zeta': zeta, 'sigma_sq': sigma_sq}

                    # ì²« ë²ˆì§¸ LVì— ëŒ€í•´ì„œë§Œ ìƒì„¸ ë¡œê¹…
                    if hasattr(self, 'iteration_logger') and hasattr(self, '_unpack_count'):
                        if self._unpack_count <= 3 and lv_idx == 0:
                            self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ {lv_name}: zeta[0]={zeta[0]:.4f}, sigma_sq[0]={sigma_sq[0]:.4f}")

                elif method == 'ordered_probit':
                    # OrderedProbitMeasurement
                    n_indicators = len(config.indicators)
                    n_thresholds = config.n_categories - 1

                    # ìš”ì¸ì ì¬ëŸ‰ (zeta)
                    zeta = params[idx:idx+n_indicators]
                    idx += n_indicators

                    # ì„ê³„ê°’ (tau)
                    tau_list = []
                    for i in range(n_indicators):
                        tau_list.append(params[idx:idx+n_thresholds])
                        idx += n_thresholds
                    tau = np.array(tau_list)

                    param_dict['measurement'][lv_name] = {'zeta': zeta, 'tau': tau}

                    # ì²« ë²ˆì§¸ LVì— ëŒ€í•´ì„œë§Œ ìƒì„¸ ë¡œê¹…
                    if hasattr(self, 'iteration_logger') and hasattr(self, '_unpack_count'):
                        if self._unpack_count <= 3 and lv_idx == 0:
                            self.iteration_logger.info(f"  ì¸¡ì •ëª¨ë¸ {lv_name}: zeta[0]={zeta[0]:.4f}, tau[0,0]={tau[0,0]:.4f}")

                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¸¡ì • ë°©ë²•: {method}")
        else:
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜
            n_indicators = len(self.config.measurement.indicators)
            zeta = params[idx:idx+n_indicators]
            idx += n_indicators

            n_thresholds = self.config.measurement.n_categories - 1
            tau_list = []
            for i in range(n_indicators):
                tau_list.append(params[idx:idx+n_thresholds])
                idx += n_thresholds
            tau = np.array(tau_list)

            param_dict['measurement'] = {'zeta': zeta, 'tau': tau}

        # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        if hasattr(self.config.structural, 'is_hierarchical') and self.config.structural.is_hierarchical:
            # âœ… ê³„ì¸µì  êµ¬ì¡°
            for path in self.config.structural.hierarchical_paths:
                target = path['target']
                predictors = path['predictors']

                for pred in predictors:
                    param_name = f'gamma_{pred}_to_{target}'
                    param_dict['structural'][param_name] = params[idx]
                    idx += 1

            # ìƒì„¸ ë¡œê¹…
            if hasattr(self, 'iteration_logger') and hasattr(self, '_unpack_count'):
                if self._unpack_count <= 3:
                    first_param = list(param_dict['structural'].keys())[0]
                    self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸ (ê³„ì¸µì ): {first_param}={param_dict['structural'][first_param]:.6f}")

        elif hasattr(self.config.structural, 'n_exo'):
            # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
            n_exo = self.config.structural.n_exo
            n_cov = self.config.structural.n_cov

            # gamma_lv (ì™¸ìƒ LV â†’ ë‚´ìƒ LV)
            gamma_lv = params[idx:idx+n_exo]
            idx += n_exo

            # gamma_x (ê³µë³€ëŸ‰ â†’ ë‚´ìƒ LV)
            gamma_x = params[idx:idx+n_cov]
            idx += n_cov

            param_dict['structural'] = {'gamma_lv': gamma_lv, 'gamma_x': gamma_x}

            # ìƒì„¸ ë¡œê¹… (ê°„ì†Œí™”)
            if hasattr(self, 'iteration_logger') and hasattr(self, '_unpack_count'):
                if self._unpack_count <= 3:
                    gamma_lv_str = f"gamma_lv[0]={gamma_lv[0]:.6f}" if len(gamma_lv) > 0 else "gamma_lv=[]"
                    gamma_x_str = f"gamma_x[0]={gamma_x[0]:.6f}" if len(gamma_x) > 0 else "gamma_x=[]"
                    self.iteration_logger.info(f"  êµ¬ì¡°ëª¨ë¸: {gamma_lv_str}, {gamma_x_str}")
        else:
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜ êµ¬ì¡°ëª¨ë¸
            n_sociodem = len(self.config.structural.sociodemographics)
            gamma = params[idx:idx+n_sociodem]
            idx += n_sociodem

            param_dict['structural'] = {'gamma': gamma}

        # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        intercept = params[idx]
        idx += 1

        n_attributes = len(self.config.choice.choice_attributes)
        beta = params[idx:idx+n_attributes]
        idx += n_attributes

        # ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
        if hasattr(self.config.choice, 'moderation_enabled') and self.config.choice.moderation_enabled:
            # âœ… ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
            lambda_main = params[idx]
            idx += 1

            param_dict['choice'] = {
                'intercept': intercept,
                'beta': beta,
                'lambda_main': lambda_main
            }

            # ì¡°ì ˆíš¨ê³¼ ê³„ìˆ˜
            for mod_lv in self.config.choice.moderator_lvs:
                param_name = f'lambda_mod_{mod_lv}'
                param_dict['choice'][param_name] = params[idx]
                idx += 1

            # ìƒì„¸ ë¡œê¹…
            if hasattr(self, 'iteration_logger') and hasattr(self, '_unpack_count'):
                if self._unpack_count <= 3:
                    first_mod = self.config.choice.moderator_lvs[0]
                    self.iteration_logger.info(f"  ì„ íƒëª¨ë¸ (ì¡°ì ˆ): intercept={intercept:.6f}, lambda_main={lambda_main:.6f}, lambda_mod_{first_mod}={param_dict['choice'][f'lambda_mod_{first_mod}']:.6f}")
        else:
            # ê¸°ë³¸ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
            lambda_lv = params[idx]
            idx += 1

            param_dict['choice'] = {
                'intercept': intercept,
                'beta': beta,
                'lambda': lambda_lv
            }

            # ìƒì„¸ ë¡œê¹… (ê°„ì†Œí™”)
            if hasattr(self, 'iteration_logger') and hasattr(self, '_unpack_count'):
                if self._unpack_count <= 3:
                    self.iteration_logger.info(f"  ì„ íƒëª¨ë¸: intercept={intercept:.6f}, beta[0]={beta[0]:.6f}, lambda={lambda_lv:.6f}")

        return param_dict

    def _structure_statistics(self, estimates, std_errors, t_stats, p_values,
                              measurement_model, structural_model, choice_model):
        """
        íŒŒë¼ë¯¸í„°ë³„ í†µê³„ëŸ‰ì„ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì§€ì›)

        Args:
            estimates: ì¶”ì •ê°’ ë²¡í„°
            std_errors: í‘œì¤€ì˜¤ì°¨ ë²¡í„°
            t_stats: t-í†µê³„ëŸ‰ ë²¡í„°
            p_values: p-value ë²¡í„°
            measurement_model: ì¸¡ì •ëª¨ë¸
            structural_model: êµ¬ì¡°ëª¨ë¸
            choice_model: ì„ íƒëª¨ë¸

        Returns:
            êµ¬ì¡°í™”ëœ í†µê³„ëŸ‰ ë”•ì…”ë„ˆë¦¬
            {
                'measurement': {
                    'lv_name1': {'zeta': {...}, 'sigma_sq': {...}},
                    'lv_name2': {'zeta': {...}, 'sigma_sq': {...}},
                    ...
                },
                'structural': {'gamma_pred_to_target': {...}, ...},
                'choice': {'intercept': {...}, 'beta': {...}, 'lambda_main': {...}, ...}
            }
        """
        # íŒŒë¼ë¯¸í„° ì–¸íŒ© (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì§€ì›)
        param_dict = self._unpack_parameters(
            estimates, measurement_model, structural_model, choice_model
        )

        # ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í‘œì¤€ì˜¤ì°¨, t-í†µê³„ëŸ‰, p-value ì–¸íŒ©
        se_dict = self._unpack_parameters(
            std_errors, measurement_model, structural_model, choice_model
        )
        t_dict = self._unpack_parameters(
            t_stats, measurement_model, structural_model, choice_model
        )
        p_dict = self._unpack_parameters(
            p_values, measurement_model, structural_model, choice_model
        )

        # êµ¬ì¡°í™”ëœ ê²°ê³¼ ìƒì„±
        structured = {
            'measurement': {},
            'structural': {},
            'choice': {}
        }

        # ì¸¡ì •ëª¨ë¸ (ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ì§€ì›)
        if 'measurement' in param_dict:
            if hasattr(self.config, 'measurement_configs'):
                # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜
                for lv_name in param_dict['measurement'].keys():
                    structured['measurement'][lv_name] = {}

                    # zeta (ìš”ì¸ì ì¬ëŸ‰)
                    if 'zeta' in param_dict['measurement'][lv_name]:
                        structured['measurement'][lv_name]['zeta'] = {
                            'estimate': param_dict['measurement'][lv_name]['zeta'],
                            'std_error': se_dict['measurement'][lv_name]['zeta'],
                            't_statistic': t_dict['measurement'][lv_name]['zeta'],
                            'p_value': p_dict['measurement'][lv_name]['zeta']
                        }

                    # sigma_sq (ì˜¤ì°¨ë¶„ì‚°) - continuous_linear ë°©ì‹
                    if 'sigma_sq' in param_dict['measurement'][lv_name]:
                        structured['measurement'][lv_name]['sigma_sq'] = {
                            'estimate': param_dict['measurement'][lv_name]['sigma_sq'],
                            'std_error': se_dict['measurement'][lv_name]['sigma_sq'],
                            't_statistic': t_dict['measurement'][lv_name]['sigma_sq'],
                            'p_value': p_dict['measurement'][lv_name]['sigma_sq']
                        }

                    # tau (ì„ê³„ê°’) - ordered_probit ë°©ì‹
                    if 'tau' in param_dict['measurement'][lv_name]:
                        structured['measurement'][lv_name]['tau'] = {
                            'estimate': param_dict['measurement'][lv_name]['tau'],
                            'std_error': se_dict['measurement'][lv_name]['tau'],
                            't_statistic': t_dict['measurement'][lv_name]['tau'],
                            'p_value': p_dict['measurement'][lv_name]['tau']
                        }
            else:
                # ë‹¨ì¼ ì ì¬ë³€ìˆ˜ (í•˜ìœ„ í˜¸í™˜)
                for key in param_dict['measurement']:
                    structured['measurement'][key] = {
                        'estimate': param_dict['measurement'][key],
                        'std_error': se_dict['measurement'][key],
                        't_statistic': t_dict['measurement'][key],
                        'p_value': p_dict['measurement'][key]
                    }

        # êµ¬ì¡°ëª¨ë¸ (ê³„ì¸µì  êµ¬ì¡° ì§€ì›)
        if 'structural' in param_dict:
            for key in param_dict['structural']:
                structured['structural'][key] = {
                    'estimate': param_dict['structural'][key],
                    'std_error': se_dict['structural'][key],
                    't_statistic': t_dict['structural'][key],
                    'p_value': p_dict['structural'][key]
                }

        # ì„ íƒëª¨ë¸ (ì¡°ì ˆíš¨ê³¼ ì§€ì›)
        if 'choice' in param_dict:
            for key in param_dict['choice']:
                structured['choice'][key] = {
                    'estimate': param_dict['choice'][key],
                    'std_error': se_dict['choice'][key],
                    't_statistic': t_dict['choice'][key],
                    'p_value': p_dict['choice'][key]
                }

        return structured

