"""
Multi-Latent Variable Simultaneous Estimator

ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ICLV ëª¨ë¸ì˜ ë™ì‹œì¶”ì • ì—”ì§„ì…ë‹ˆë‹¤.
ê¸°ì¡´ SimultaneousEstimatorì˜ ë¡œì§ì„ í™•ì¥í•˜ì—¬ 5ê°œ ì ì¬ë³€ìˆ˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

Author: Sugar Substitute Research Team
Date: 2025-11-09
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from scipy import optimize
from scipy.stats import norm, qmc
from scipy.special import logsumexp
import logging
import multiprocessing
from concurrent.futures import ProcessPoolExecutor
import time

from .multi_latent_measurement import MultiLatentMeasurement
from .multi_latent_structural import MultiLatentStructural
from .choice_equations import BinaryProbitChoice
from .multi_latent_config import MultiLatentConfig

logger = logging.getLogger(__name__)


# ============================================================================
# ë³‘ë ¬ì²˜ë¦¬ë¥¼ ìœ„í•œ ì „ì—­ í•¨ìˆ˜ (pickle ê°€ëŠ¥)
# ============================================================================

def _compute_multi_lv_individual_likelihood_parallel(args):
    """
    ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ê°œì¸ë³„ ìš°ë„ ê³„ì‚° (ë³‘ë ¬ì²˜ë¦¬ìš© ì „ì—­ í•¨ìˆ˜)

    Args:
        args: (ind_data_dict, ind_draws, param_dict, config_dict)

    Returns:
        ê°œì¸ì˜ ë¡œê·¸ìš°ë„
    """
    # ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì–µì œ
    import logging
    logging.getLogger('root').setLevel(logging.CRITICAL)

    from .multi_latent_measurement import MultiLatentMeasurement
    from .multi_latent_structural import MultiLatentStructural
    from .choice_equations import BinaryProbitChoice
    from .multi_latent_config import MultiLatentConfig, MultiLatentStructuralConfig
    from .iclv_config import MeasurementConfig, ChoiceConfig, EstimationConfig

    ind_id, ind_data_dict, ind_draws, param_dict, config_dict = args

    # DataFrame ë³µì›
    ind_data = pd.DataFrame(ind_data_dict)

    # ì„¤ì • ë³µì›
    measurement_configs = {}
    for lv_name, lv_config_dict in config_dict['measurement'].items():
        measurement_configs[lv_name] = MeasurementConfig(**lv_config_dict)

    structural_config = MultiLatentStructuralConfig(**config_dict['structural'])
    choice_config = ChoiceConfig(**config_dict['choice'])

    # ëª¨ë¸ ì¬ìƒì„±
    measurement_model = MultiLatentMeasurement(measurement_configs)
    structural_model = MultiLatentStructural(structural_config)
    choice_model = BinaryProbitChoice(choice_config)

    # ìš°ë„ ê³„ì‚°
    draw_lls = []
    n_exo = structural_config.n_exo
    endogenous_lv = structural_config.endogenous_lv

    for draw_idx in range(len(ind_draws)):
        # Draws ë¶„ë¦¬
        exo_draws = ind_draws[draw_idx, :n_exo]
        endo_draw = ind_draws[draw_idx, n_exo]

        # êµ¬ì¡°ëª¨ë¸: ëª¨ë“  LV ì˜ˆì¸¡
        latent_vars = structural_model.predict(
            ind_data, exo_draws, param_dict['structural'], endo_draw
        )

        # ì¸¡ì •ëª¨ë¸ ìš°ë„
        ll_measurement = measurement_model.log_likelihood(
            ind_data, latent_vars, param_dict['measurement']
        )

        # ì„ íƒëª¨ë¸ ìš°ë„ (ë‚´ìƒ LVë§Œ ì‚¬ìš©)
        lv_endo = latent_vars[endogenous_lv]
        ll_choice = 0.0
        for idx in range(len(ind_data)):
            ll_choice += choice_model.log_likelihood(
                ind_data.iloc[idx:idx+1],
                lv_endo,
                param_dict['choice']
            )

        # êµ¬ì¡°ëª¨ë¸ ìš°ë„
        ll_structural = structural_model.log_likelihood(
            ind_data, latent_vars, exo_draws, param_dict['structural'], endo_draw
        )

        # ê²°í•© ë¡œê·¸ìš°ë„
        draw_ll = ll_measurement + ll_choice + ll_structural

        if not np.isfinite(draw_ll):
            draw_ll = -1e10

        draw_lls.append(draw_ll)

    # logsumexp
    person_ll = logsumexp(draw_lls) - np.log(len(draw_lls))
    return (ind_id, person_ll)


class HaltonDrawGenerator:
    """Halton ì‹œí€€ìŠ¤ ìƒì„±ê¸° (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)"""
    
    def __init__(self, n_individuals: int, n_draws: int, n_dimensions: int, seed: int = 42):
        """
        Args:
            n_individuals: ê°œì¸ ìˆ˜
            n_draws: ê°œì¸ë‹¹ draws ìˆ˜
            n_dimensions: ì°¨ì› ìˆ˜ (ì™¸ìƒ LV ìˆ˜ + 1)
        """
        self.n_individuals = n_individuals
        self.n_draws = n_draws
        self.n_dimensions = n_dimensions
        self.seed = seed
        
        # Halton ì‹œí€€ìŠ¤ ìƒì„±
        sampler = qmc.Halton(d=n_dimensions, scramble=True, seed=seed)
        uniform_draws = sampler.random(n=n_individuals * n_draws)
        
        # í‘œì¤€ì •ê·œë¶„í¬ë¡œ ë³€í™˜
        self.draws = norm.ppf(uniform_draws)
        
        # (n_individuals, n_draws, n_dimensions) í˜•íƒœë¡œ reshape
        self.draws = self.draws.reshape(n_individuals, n_draws, n_dimensions)
        
        logger.info(f"Halton draws ìƒì„±: {n_individuals}ëª… Ã— {n_draws}draws Ã— {n_dimensions}ì°¨ì›")
    
    def get_draws(self) -> np.ndarray:
        """Draws ë°˜í™˜"""
        return self.draws


class MultiLatentSimultaneousEstimator:
    """
    ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ë™ì‹œì¶”ì • ì—”ì§„
    
    ê²°í•© ë¡œê·¸ìš°ë„:
    LL = Î£_i log[(1/R) Î£_r P(Choice_i|LV5_r) 
                        Ã— P(Indicators1_i|LV1_r) 
                        Ã— P(Indicators2_i|LV2_r)
                        Ã— P(Indicators3_i|LV3_r)
                        Ã— P(Indicators4_i|LV4_r)
                        Ã— P(Indicators5_i|LV5_r)
                        Ã— P(LV5_r|LV1_r,LV2_r,LV3_r,LV4_r,X_i)
                        Ã— P(LV1_r)
                        Ã— P(LV2_r)
                        Ã— P(LV3_r)
                        Ã— P(LV4_r)]
    """
    
    def __init__(self, config: MultiLatentConfig, data: pd.DataFrame):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: ë‹¤ì¤‘ LV ICLV ì„¤ì •
            data: í†µí•© ë°ì´í„°
        """
        self.config = config
        self.data = data
        
        # ëª¨ë¸ ìƒì„±
        self.measurement_model = MultiLatentMeasurement(config.measurement_configs)
        self.structural_model = MultiLatentStructural(config.structural)
        self.choice_model = BinaryProbitChoice(config.choice)
        
        # Halton draws ìƒì„±
        individual_ids = data[config.individual_id_column].unique()
        n_individuals = len(individual_ids)
        n_draws = config.estimation.n_draws
        n_dimensions = config.structural.n_exo + 1  # ì™¸ìƒ LV + ë‚´ìƒ LV ì˜¤ì°¨í•­
        
        self.halton_generator = HaltonDrawGenerator(
            n_individuals=n_individuals,
            n_draws=n_draws,
            n_dimensions=n_dimensions,
            seed=42  # ê³ ì • seed
        )
        
        # íŒŒë¼ë¯¸í„° ê°œìˆ˜ ê³„ì‚°
        n_measurement_params = self.measurement_model.get_n_parameters()
        n_structural_params = config.structural.n_exo + config.structural.n_cov  # gamma_lv + gamma_x
        n_choice_params = 1 + len(config.choice.choice_attributes) + 1  # intercept + beta + lambda
        total_params = n_measurement_params + n_structural_params + n_choice_params

        # ë¡œê¹…
        logger.info("=" * 70)
        logger.info("MultiLatentSimultaneousEstimator ì´ˆê¸°í™”")
        logger.info(f"  ê°œì¸ ìˆ˜: {n_individuals:,}")
        logger.info(f"  ê´€ì¸¡ì¹˜ ìˆ˜: {len(data):,}")
        logger.info(f"  ê°œì¸ë‹¹ ì„ íƒ ìƒí™©: {len(data) / n_individuals:.1f}")
        logger.info(f"  Halton draws: {n_draws}")
        logger.info(f"  ì°¨ì›: {n_dimensions} (ì™¸ìƒ LV {config.structural.n_exo} + ë‚´ìƒ LV ì˜¤ì°¨ 1)")
        logger.info(f"  ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°: {n_measurement_params}")
        logger.info(f"  êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°: {n_structural_params}")
        logger.info(f"  ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°: {n_choice_params}")
        logger.info(f"  ì´ íŒŒë¼ë¯¸í„°: {total_params}")
        logger.info(f"  ì´ ì‹œë®¬ë ˆì´ì…˜: {n_individuals:,} Ã— {n_draws} = {n_individuals * n_draws:,}")
        logger.info("=" * 70)
        
        # ì¶”ì • ê²°ê³¼ ì €ì¥
        self.results = None
    
    def _compute_individual_likelihood(self, ind_id, ind_data, ind_draws, param_dict) -> float:
        """
        ê°œì¸ë³„ ìš°ë„ ê³„ì‚°
        
        Args:
            ind_id: ê°œì¸ ID
            ind_data: ê°œì¸ ë°ì´í„° (ì—¬ëŸ¬ ì„ íƒ ìƒí™©)
            ind_draws: ê°œì¸ì˜ Halton draws (n_draws, n_dimensions)
            param_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        
        Returns:
            ê°œì¸ì˜ ë¡œê·¸ìš°ë„
        """
        draw_lls = []
        
        n_exo = self.config.structural.n_exo
        
        for draw_idx in range(len(ind_draws)):
            # 1. Draws ë¶„ë¦¬
            exo_draws = ind_draws[draw_idx, :n_exo]  # ì™¸ìƒ LV (4ê°œ)
            endo_draw = ind_draws[draw_idx, n_exo]   # ë‚´ìƒ LV ì˜¤ì°¨í•­ (1ê°œ)
            
            # 2. êµ¬ì¡°ëª¨ë¸: ëª¨ë“  LV ì˜ˆì¸¡
            latent_vars = self.structural_model.predict(
                ind_data, exo_draws, param_dict['structural'], endo_draw
            )
            
            # 3. ì¸¡ì •ëª¨ë¸ ìš°ë„ (5ê°œ LV)
            ll_measurement = self.measurement_model.log_likelihood(
                ind_data, latent_vars, param_dict['measurement']
            )
            
            # 4. ì„ íƒëª¨ë¸ ìš°ë„ (ë‚´ìƒ LVë§Œ ì‚¬ìš©)
            lv_endo = latent_vars[self.config.structural.endogenous_lv]
            ll_choice = 0.0
            for idx in range(len(ind_data)):
                ll_choice += self.choice_model.log_likelihood(
                    ind_data.iloc[idx:idx+1],
                    lv_endo,
                    param_dict['choice']
                )
            
            # 5. êµ¬ì¡°ëª¨ë¸ ìš°ë„
            ll_structural = self.structural_model.log_likelihood(
                ind_data, latent_vars, exo_draws, param_dict['structural'], endo_draw
            )
            
            # 6. ê²°í•© ë¡œê·¸ìš°ë„
            draw_ll = ll_measurement + ll_choice + ll_structural
            
            # -inf ì²˜ë¦¬
            if not np.isfinite(draw_ll):
                draw_ll = -1e10
            
            draw_lls.append(draw_ll)
        
        # logsumexp
        person_ll = logsumexp(draw_lls) - np.log(len(draw_lls))
        return person_ll
    
    def _joint_log_likelihood(self, params: np.ndarray) -> float:
        """
        ê²°í•© ë¡œê·¸ìš°ë„ ê³„ì‚° (ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›)

        Args:
            params: íŒŒë¼ë¯¸í„° ë²¡í„° (1D array)

        Returns:
            ì „ì²´ ë¡œê·¸ìš°ë„
        """
        # íŒŒë¼ë¯¸í„° ë¶„í•´
        param_dict = self._unpack_parameters(params)

        # Halton draws
        draws = self.halton_generator.get_draws()
        individual_ids = self.data[self.config.individual_id_column].unique()

        # ë³‘ë ¬ì²˜ë¦¬ ì—¬ë¶€ í™•ì¸
        use_parallel = getattr(self.config.estimation, 'use_parallel', False)

        if use_parallel:
            # ë³‘ë ¬ì²˜ë¦¬ ì‚¬ìš©
            n_cores = getattr(self.config.estimation, 'n_cores', None)
            if n_cores is None:
                n_cores = max(1, multiprocessing.cpu_count() - 1)

            # ì„¤ì • ì •ë³´ë¥¼ dictë¡œ ë³€í™˜ (pickle ê°€ëŠ¥)
            config_dict = {
                'measurement': {},
                'structural': {
                    'endogenous_lv': self.config.structural.endogenous_lv,
                    'exogenous_lvs': self.config.structural.exogenous_lvs,
                    'covariates': self.config.structural.covariates,
                    'error_variance': self.config.structural.error_variance
                },
                'choice': {
                    'choice_attributes': self.config.choice.choice_attributes
                }
            }

            # ì¸¡ì •ëª¨ë¸ ì„¤ì • ë³€í™˜
            for lv_name, lv_config in self.config.measurement_configs.items():
                config_dict['measurement'][lv_name] = {
                    'latent_variable': lv_config.latent_variable,
                    'indicators': lv_config.indicators,
                    'n_categories': lv_config.n_categories
                }

            # ê°œì¸ë³„ ë°ì´í„° ì¤€ë¹„
            args_list = []
            for i, ind_id in enumerate(individual_ids):
                ind_data = self.data[self.data[self.config.individual_id_column] == ind_id]
                ind_data_dict = ind_data.to_dict('list')
                ind_draws = draws[i, :, :]
                args_list.append((ind_id, ind_data_dict, ind_draws, param_dict, config_dict))

            # ë³‘ë ¬ ê³„ì‚°
            with ProcessPoolExecutor(max_workers=n_cores) as executor:
                results = list(executor.map(_compute_multi_lv_individual_likelihood_parallel, args_list))

            # ê²°ê³¼ ì •ë¦¬ (ind_id, person_ll)
            person_lls = [ll for _, ll in results]
            total_ll = sum(person_lls)
        else:
            # ìˆœì°¨ì²˜ë¦¬
            total_ll = 0.0
            for i, ind_id in enumerate(individual_ids):
                ind_data = self.data[self.data[self.config.individual_id_column] == ind_id]
                ind_draws = draws[i, :, :]

                person_ll = self._compute_individual_likelihood(
                    ind_id, ind_data, ind_draws, param_dict
                )
                total_ll += person_ll

        return total_ll
    
    def _unpack_parameters(self, params: np.ndarray) -> Dict:
        """
        íŒŒë¼ë¯¸í„° ë²¡í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´
        
        íŒŒë¼ë¯¸í„° ìˆœì„œ:
        1. ì¸¡ì •ëª¨ë¸ (5ê°œ LV)
        2. êµ¬ì¡°ëª¨ë¸ (gamma_lv, gamma_x)
        3. ì„ íƒëª¨ë¸ (beta, lambda)
        
        Args:
            params: íŒŒë¼ë¯¸í„° ë²¡í„°
        
        Returns:
            {
                'measurement': {...},
                'structural': {...},
                'choice': {...}
            }
        """
        idx = 0
        param_dict = {}
        
        # 1. ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        measurement_params = {}
        for lv_name, model in self.measurement_model.models.items():
            n_indicators = model.n_indicators
            n_thresholds = model.n_thresholds
            
            # zeta
            zeta = params[idx:idx+n_indicators]
            idx += n_indicators
            
            # tau
            tau = params[idx:idx+n_indicators*n_thresholds].reshape(n_indicators, n_thresholds)
            idx += n_indicators * n_thresholds
            
            measurement_params[lv_name] = {'zeta': zeta, 'tau': tau}
        
        param_dict['measurement'] = measurement_params
        
        # 2. êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        n_exo = self.structural_model.n_exo
        n_cov = self.structural_model.n_cov
        
        gamma_lv = params[idx:idx+n_exo]
        idx += n_exo
        
        gamma_x = params[idx:idx+n_cov]
        idx += n_cov
        
        param_dict['structural'] = {
            'gamma_lv': gamma_lv,
            'gamma_x': gamma_x
        }
        
        # 3. ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        n_choice_attrs = len(self.config.choice.choice_attributes)
        
        beta_intercept = params[idx]
        idx += 1
        
        beta = params[idx:idx+n_choice_attrs]
        idx += n_choice_attrs
        
        lambda_lv = params[idx]
        idx += 1
        
        param_dict['choice'] = {
            'intercept': beta_intercept,  # BinaryProbitChoice expects 'intercept'
            'beta': beta,
            'lambda': lambda_lv
        }
        
        return param_dict

    def _pack_parameters(self, param_dict: Dict) -> np.ndarray:
        """
        íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜

        Args:
            param_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            íŒŒë¼ë¯¸í„° ë²¡í„°
        """
        params_list = []

        # 1. ì¸¡ì •ëª¨ë¸
        for lv_name in self.measurement_model.get_latent_variable_names():
            lv_params = param_dict['measurement'][lv_name]
            params_list.append(lv_params['zeta'])
            params_list.append(lv_params['tau'].flatten())

        # 2. êµ¬ì¡°ëª¨ë¸
        params_list.append(param_dict['structural']['gamma_lv'])
        params_list.append(param_dict['structural']['gamma_x'])

        # 3. ì„ íƒëª¨ë¸
        params_list.append(np.array([param_dict['choice']['intercept']]))
        params_list.append(param_dict['choice']['beta'])
        params_list.append(np.array([param_dict['choice']['lambda']]))

        return np.concatenate(params_list)

    def _initialize_parameters(self) -> np.ndarray:
        """
        íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”

        Returns:
            ì´ˆê¸° íŒŒë¼ë¯¸í„° ë²¡í„°
        """
        param_dict = {}

        # 1. ì¸¡ì •ëª¨ë¸
        param_dict['measurement'] = self.measurement_model.initialize_parameters()

        # 2. êµ¬ì¡°ëª¨ë¸
        param_dict['structural'] = self.structural_model.initialize_parameters()

        # 3. ì„ íƒëª¨ë¸
        n_choice_attrs = len(self.config.choice.choice_attributes)
        param_dict['choice'] = {
            'intercept': 0.0,
            'beta': np.zeros(n_choice_attrs),
            'lambda': 1.0
        }

        return self._pack_parameters(param_dict)

    def estimate(self) -> Dict:
        """
        ëª¨ë¸ ì¶”ì •

        Returns:
            ì¶”ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("=" * 70)
        logger.info("ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ICLV ëª¨ë¸ ì¶”ì • ì‹œì‘")
        logger.info("=" * 70)

        # ë³‘ë ¬ì²˜ë¦¬ ì„¤ì • ë¡œê¹…
        use_parallel = getattr(self.config.estimation, 'use_parallel', False)
        n_individuals = len(self.data[self.config.individual_id_column].unique())

        if use_parallel:
            n_cores = getattr(self.config.estimation, 'n_cores', None)
            if n_cores is None:
                n_cores = max(1, multiprocessing.cpu_count() - 1)
            logger.info(f"ğŸš€ ë³‘ë ¬ì²˜ë¦¬ í™œì„±í™”")
            logger.info(f"   - ì‚¬ìš© ì½”ì–´: {n_cores}/{multiprocessing.cpu_count()}ê°œ ({n_cores/multiprocessing.cpu_count()*100:.1f}%)")
            logger.info(f"   - ê°œì¸ë‹¹ ì½”ì–´: {n_individuals/n_cores:.1f}ëª…/ì½”ì–´")
            logger.info(f"   - ì˜ˆìƒ ì†ë„ í–¥ìƒ: ~{n_cores}ë°°")
        else:
            logger.info("âš ï¸  ìˆœì°¨ì²˜ë¦¬ ì‚¬ìš© (ë³‘ë ¬ì²˜ë¦¬ ë¹„í™œì„±í™”)")
            logger.info(f"   - ì‚¬ìš© ê°€ëŠ¥í•œ ì½”ì–´: {multiprocessing.cpu_count()}ê°œ")
            logger.info(f"   - ë³‘ë ¬ì²˜ë¦¬ë¥¼ í™œì„±í™”í•˜ë ¤ë©´ config.estimation.use_parallel=True ì„¤ì •")
            logger.info(f"   - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ìˆœì°¨ ì²˜ë¦¬ë¡œ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤")

        start_time = time.time()

        # ì´ˆê¸° íŒŒë¼ë¯¸í„°
        initial_params = self._initialize_parameters()
        logger.info(f"ì´ˆê¸° íŒŒë¼ë¯¸í„° ìˆ˜: {len(initial_params)}")

        # ì´ˆê¸° ë¡œê·¸ìš°ë„
        logger.info("ì´ˆê¸° ë¡œê·¸ìš°ë„ ê³„ì‚° ì¤‘...")
        ll_start_time = time.time()
        initial_ll = self._joint_log_likelihood(initial_params)
        ll_elapsed = time.time() - ll_start_time
        logger.info(f"ì´ˆê¸° ë¡œê·¸ìš°ë„: {initial_ll:.4f} (ì†Œìš”: {ll_elapsed:.1f}ì´ˆ)")
        logger.info(f"  â†’ 1íšŒ ìš°ë„ ê³„ì‚° ì‹œê°„: {ll_elapsed:.1f}ì´ˆ")
        logger.info(f"  â†’ ì˜ˆìƒ ì´ ì†Œìš” ì‹œê°„: {ll_elapsed * self.config.estimation.max_iterations / 60:.1f}ë¶„ (ìµœëŒ€ ë°˜ë³µ ê¸°ì¤€)")

        # ëª©ì  í•¨ìˆ˜ (negative log-likelihood)
        def objective(params):
            ll = self._joint_log_likelihood(params)
            return -ll

        # ìµœì í™”
        logger.info(f"\nìµœì í™” ì‹œì‘: {self.config.estimation.optimizer}")
        logger.info(f"  ìµœëŒ€ ë°˜ë³µ: {self.config.estimation.max_iterations}")
        logger.info(f"  ì´ˆê¸° LL: {initial_ll:.4f}")
        logger.info("  ì§„í–‰ ìƒí™©ì€ ì•„ë˜ì— í‘œì‹œë©ë‹ˆë‹¤...\n")

        # ë°˜ë³µ ì¹´ìš´í„°
        iteration_count = [0]
        last_log_time = [time.time()]
        best_ll = [-np.inf]
        ll_history = []

        def callback(xk):
            """ìµœì í™” ì§„í–‰ ìƒí™© ë¡œê¹…"""
            iteration_count[0] += 1
            current_time = time.time()

            # ë§¤ ë°˜ë³µë§ˆë‹¤ LL ê³„ì‚° (ë¡œê¹…ì€ ì¡°ê±´ë¶€)
            ll = -objective(xk)
            ll_history.append(ll)

            # ê°œì„  ì—¬ë¶€ í™•ì¸
            is_improvement = ll > best_ll[0]
            if is_improvement:
                best_ll[0] = ll

            # 5ì´ˆë§ˆë‹¤ ë˜ëŠ” 5 ë°˜ë³µë§ˆë‹¤ ë˜ëŠ” ê°œì„  ì‹œ ë¡œê¹…
            should_log = (current_time - last_log_time[0] > 5 or
                         iteration_count[0] % 5 == 0 or
                         is_improvement)

            if should_log:
                elapsed = current_time - start_time
                iter_per_sec = iteration_count[0] / elapsed if elapsed > 0 else 0
                remaining_iters = self.config.estimation.max_iterations - iteration_count[0]
                eta_sec = remaining_iters / iter_per_sec if iter_per_sec > 0 else 0

                improvement_str = " [âœ¨ NEW BEST]" if is_improvement else ""
                logger.info(f"  ë°˜ë³µ {iteration_count[0]:3d}: LL = {ll:12.4f} (Best: {best_ll[0]:12.4f}){improvement_str}")
                logger.info(f"         ê²½ê³¼: {elapsed:.1f}ì´ˆ | ì†ë„: {iter_per_sec:.2f} iter/s | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {eta_sec/60:.1f}ë¶„")
                last_log_time[0] = current_time

        result = optimize.minimize(
            objective,
            initial_params,
            method=self.config.estimation.optimizer,
            callback=callback,
            options={
                'maxiter': self.config.estimation.max_iterations,
                'disp': False  # callbackìœ¼ë¡œ ì§ì ‘ ë¡œê¹…
            }
        )

        # ê²°ê³¼ ì²˜ë¦¬
        elapsed_time = time.time() - start_time

        final_params = result.x
        final_ll = -result.fun

        logger.info("\n" + "=" * 70)
        logger.info("âœ… ì¶”ì • ì™„ë£Œ")
        logger.info("=" * 70)
        logger.info(f"  ìµœì¢… ë¡œê·¸ìš°ë„: {final_ll:.4f}")
        logger.info(f"  ì´ˆê¸° ë¡œê·¸ìš°ë„: {initial_ll:.4f}")
        logger.info(f"  LL ê°œì„ : {final_ll - initial_ll:.4f} ({(final_ll - initial_ll)/abs(initial_ll)*100:.2f}%)")
        logger.info(f"  ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ ({elapsed_time/60:.1f}ë¶„)")
        logger.info(f"  ë°˜ë³µ íšŸìˆ˜: {result.nit}")
        logger.info(f"  ìˆ˜ë ´ ì—¬ë¶€: {'âœ… ì„±ê³µ' if result.success else 'âŒ ì‹¤íŒ¨'}")
        if use_parallel:
            logger.info(f"  ë³‘ë ¬ ì²˜ë¦¬: {n_cores}ê°œ ì½”ì–´ ì‚¬ìš©")
            logger.info(f"  ì˜ˆìƒ ìˆœì°¨ ì‹œê°„: ~{elapsed_time * n_cores / 60:.0f}ë¶„")
        logger.info("=" * 70)

        # íŒŒë¼ë¯¸í„° ë¶„í•´
        param_dict = self._unpack_parameters(final_params)

        # ê²°ê³¼ ì €ì¥
        self.results = {
            'params': param_dict,
            'log_likelihood': final_ll,
            'n_parameters': len(final_params),
            'n_observations': len(self.data),
            'n_individuals': len(self.data[self.config.individual_id_column].unique()),
            'convergence': result.success,
            'iterations': result.nit,
            'elapsed_time': elapsed_time,
            'optimizer_result': result
        }

        return self.results

    def print_results(self):
        """ì¶”ì • ê²°ê³¼ ì¶œë ¥"""
        if self.results is None:
            logger.error("ì¶”ì • ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. estimate()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return

        print("\n" + "=" * 70)
        print("ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ICLV ëª¨ë¸ ì¶”ì • ê²°ê³¼")
        print("=" * 70)

        # ëª¨ë¸ ì í•©ë„
        print("\n[ëª¨ë¸ ì í•©ë„]")
        print(f"  ë¡œê·¸ìš°ë„: {self.results['log_likelihood']:.4f}")
        print(f"  íŒŒë¼ë¯¸í„° ìˆ˜: {self.results['n_parameters']}")
        print(f"  ê´€ì¸¡ì¹˜ ìˆ˜: {self.results['n_observations']}")
        print(f"  ê°œì¸ ìˆ˜: {self.results['n_individuals']}")

        # ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°
        print("\n[ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„°]")
        for lv_name, lv_params in self.results['params']['measurement'].items():
            print(f"\n  {lv_name}:")
            print(f"    zeta: {lv_params['zeta']}")

        # êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°
        print("\n[êµ¬ì¡°ëª¨ë¸ íŒŒë¼ë¯¸í„°]")
        structural_params = self.results['params']['structural']

        print("\n  ì™¸ìƒ LV â†’ ë‚´ìƒ LV:")
        for i, lv_name in enumerate(self.structural_model.exogenous_lvs):
            print(f"    gamma_{lv_name}: {structural_params['gamma_lv'][i]:.4f}")

        print("\n  ê³µë³€ëŸ‰ â†’ ë‚´ìƒ LV:")
        for i, var in enumerate(self.structural_model.covariates):
            print(f"    gamma_{var}: {structural_params['gamma_x'][i]:.4f}")

        # ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°
        print("\n[ì„ íƒëª¨ë¸ íŒŒë¼ë¯¸í„°]")
        choice_params = self.results['params']['choice']
        print(f"  beta_intercept: {choice_params['beta_intercept']:.4f}")
        for i, attr in enumerate(self.config.choice.choice_attributes):
            print(f"  beta_{attr}: {choice_params['beta'][i]:.4f}")
        print(f"  lambda (LV â†’ Choice): {choice_params['lambda']:.4f}")

        print("\n" + "=" * 70)

