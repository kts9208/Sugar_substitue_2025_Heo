"""
ì™„ì „ ë³‘ë ¬ GPU Gradient ê³„ì‚° - Advanced Indexing ì‚¬ìš©

ì¸¡ì •ëª¨ë¸ì˜ ëª¨ë“  ì§€í‘œ(38ê°œ)ë¥¼ í•œ ë²ˆì— ê³„ì‚°í•˜ëŠ” ì™„ì „ ë³‘ë ¬ êµ¬í˜„
Zero-padding ì—†ì´ Advanced Indexingìœ¼ë¡œ ê° ì§€í‘œì— ë§ëŠ” LVë¥¼ ìë™ ì„ íƒ

ì„±ëŠ¥:
- GPU ì»¤ë„ í˜¸ì¶œ: 1ë²ˆ (ê¸°ì¡´ 38ë²ˆ â†’ 38ë°° ê°œì„ )
- ë©”ëª¨ë¦¬: 9.45 MB (Zero-padding 24.87 MB ëŒ€ë¹„ 62% ì ˆì•½)
"""

import numpy as np
import pandas as pd
from typing import List, Dict
import time

try:
    import cupy as cp
    CUPY_AVAILABLE = True
except ImportError:
    CUPY_AVAILABLE = False
    cp = None


def compute_measurement_full_parallel_gpu(
    gpu_measurement_model,
    all_ind_data: List[pd.DataFrame],
    all_lvs_gpu,  # CuPy array (326, 100, 5)
    params_dict: Dict,
    all_weights_gpu,  # CuPy array (326, 100)
    lv_names: List[str],
    iteration_logger=None,
    log_level: str = 'MINIMAL',
    measurement_params_fixed: bool = False
) -> Dict:
    """
    ì¸¡ì •ëª¨ë¸ Gradient - ì™„ì „ ë³‘ë ¬ (ëª¨ë“  ì§€í‘œ í•œ ë²ˆì—)

    âš ï¸ ì£¼ì˜: ë™ì‹œì¶”ì •ì—ì„œëŠ” ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì¸¡ì •ëª¨ë¸ ê³ ì •)
    ì´ í•¨ìˆ˜ëŠ” ìˆœì°¨ì¶”ì • ë˜ëŠ” CFAì—ì„œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

    Advanced Indexingì„ ì‚¬ìš©í•˜ì—¬ 38ê°œ ì§€í‘œë¥¼ 1ë²ˆì˜ GPU ì»¤ë„ í˜¸ì¶œë¡œ ê³„ì‚°

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        all_ind_data: ëª¨ë“  ê°œì¸ ë°ì´í„° (326ê°œ)
        all_lvs_gpu: ëª¨ë“  LV ê°’ (326, 100, 5)
        params_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        all_weights_gpu: ê°€ì¤‘ì¹˜ (326, 100)
        lv_names: LV ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        iteration_logger: ë¡œê±°
        log_level: ë¡œê¹… ë ˆë²¨
        measurement_params_fixed: ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ê³ ì • ì—¬ë¶€ (ìˆœì°¨ì¶”ì •ìš©)

    Returns:
        {lv_name: {'zeta': (326, n_indicators), 'sigma_sq': (326, n_indicators)}}
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available for full parallel computation")

    # âœ… ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ê³ ì • ì‹œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ 0ìœ¼ë¡œ ë°˜í™˜ (ìˆœì°¨ì¶”ì •ìš©)
    if measurement_params_fixed:
        gradients = {}
        for lv_name in lv_names:
            config = gpu_measurement_model.models[lv_name].config
            n_ind = len(config.indicators)
            n_individuals = len(all_ind_data)

            # fix_first_loading ê³ ë ¤
            fix_first_loading = getattr(config, 'fix_first_loading', True)
            n_zeta = n_ind - 1 if fix_first_loading else n_ind

            gradients[lv_name] = {
                'zeta': np.zeros((n_individuals, n_zeta)),
                'sigma_sq': np.zeros((n_individuals, n_ind))
            }

        if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
            iteration_logger.info("  âœ… ì¸¡ì •ëª¨ë¸ íŒŒë¼ë¯¸í„° ê³ ì •: ê·¸ë˜ë””ì–¸íŠ¸ = 0")

        return gradients
    
    start_time = time.time()
    
    n_individuals, n_draws, n_lvs = all_lvs_gpu.shape
    
    # 1. ì§€í‘œ-LV ë§¤í•‘ ë°°ì—´ ìƒì„±
    indicator_to_lv = []
    indicator_names = []
    lv_for_indicator = []  # ê° ì§€í‘œê°€ ì†í•œ LV ì´ë¦„
    
    for lv_idx, lv_name in enumerate(lv_names):
        config = gpu_measurement_model.models[lv_name].config
        n_indicators = len(config.indicators)
        
        indicator_to_lv.extend([lv_idx] * n_indicators)
        indicator_names.extend(config.indicators)
        lv_for_indicator.extend([lv_name] * n_indicators)
    
    n_total_indicators = len(indicator_names)

    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚° (fix_first_loading ê³ ë ¤)
    n_zeta_params = sum(len(gpu_measurement_model.models[lv].config.indicators) - 1
                        for lv in lv_names)  # ê° LVì˜ ì²« ë²ˆì§¸ ì œì™¸
    n_sigma_sq_params = n_total_indicators  # ëª¨ë“  sigma_sq
    n_total_params = n_zeta_params + n_sigma_sq_params

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  ì™„ì „ ë³‘ë ¬ ì¸¡ì •ëª¨ë¸ Gradient ê³„ì‚° ì‹œì‘\n"
            f"    - ì´ ì§€í‘œ ìˆ˜: {n_total_indicators}ê°œ\n"
            f"    - ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {n_total_params}ê°œ ({n_zeta_params} zeta + {n_sigma_sq_params} sigma_sq)\n"
            f"    - LV ìˆ˜: {n_lvs}ê°œ\n"
            f"    - ë§¤í•‘: {dict(zip(lv_names, [indicator_to_lv.count(i) for i in range(n_lvs)]))}"
        )
    
    # 2. ëª¨ë“  ê´€ì¸¡ê°’ ìˆ˜ì§‘ (326, 38)
    all_y = np.zeros((n_individuals, n_total_indicators))
    
    for ind_idx, ind_data in enumerate(all_ind_data):
        row = ind_data.iloc[0]
        for i, indicator in enumerate(indicator_names):
            if indicator in row.index and not pd.isna(row[indicator]):
                all_y[ind_idx, i] = row[indicator]
    
    # 3. ëª¨ë“  íŒŒë¼ë¯¸í„° ìˆ˜ì§‘ (38,)
    all_zeta = []
    all_sigma_sq = []
    
    for lv_name in lv_names:
        all_zeta.extend(params_dict['measurement'][lv_name]['zeta'])
        all_sigma_sq.extend(params_dict['measurement'][lv_name]['sigma_sq'])
    
    all_zeta = np.array(all_zeta)
    all_sigma_sq = np.array(all_sigma_sq)
    
    # 4. GPUë¡œ ì „ì†¡
    all_y_gpu = cp.asarray(all_y)  # (326, 38)
    all_zeta_gpu = cp.asarray(all_zeta)  # (38,)
    all_sigma_sq_gpu = cp.asarray(all_sigma_sq)  # (38,)
    indicator_to_lv_gpu = cp.asarray(indicator_to_lv)  # (38,)
    
    if iteration_logger and log_level == 'DETAILED':
        iteration_logger.info(
            f"  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n"
            f"    - all_y: {all_y_gpu.shape}\n"
            f"    - all_zeta: {all_zeta_gpu.shape}\n"
            f"    - all_sigma_sq: {all_sigma_sq_gpu.shape}\n"
            f"    - indicator_to_lv: {indicator_to_lv_gpu.shape}"
        )
    
    # 5. âœ¨ Advanced Indexing: ê° ì§€í‘œì— ë§ëŠ” LV ì„ íƒ
    # all_lvs_gpu: (326, 100, 5)
    # indicator_to_lv: [0,0,0,0,0,0,1,1,1,1,1,1,2,2,2,3,3,...,3,4,4,4]
    # â†’ lv_for_indicators: (326, 100, 38)
    lv_for_indicators = all_lvs_gpu[:, :, indicator_to_lv_gpu]
    
    if iteration_logger and log_level == 'DETAILED':
        iteration_logger.info(
            f"  Advanced Indexing ì™„ë£Œ\n"
            f"    - lv_for_indicators: {lv_for_indicators.shape}\n"
            f"    - ê° ì§€í‘œë§ˆë‹¤ í•´ë‹¹ LV ê°’ì´ ìë™ ì„ íƒë¨"
        )
    
    # 6. ì™„ì „ ë³‘ë ¬ Gradient ê³„ì‚°
    # ì˜ˆì¸¡ê°’: (326, 100, 38)
    y_pred_all = all_zeta_gpu[None, None, :] * lv_for_indicators
    
    # ì”ì°¨: (326, 100, 38)
    residual_all = all_y_gpu[:, None, :] - y_pred_all
    
    # Gradient (ê° draw): (326, 100, 38)
    grad_zeta_batch = (residual_all * lv_for_indicators / 
                       all_sigma_sq_gpu[None, None, :])
    
    grad_sigma_sq_batch = (-0.5 / all_sigma_sq_gpu[None, None, :] + 
                           0.5 * (residual_all ** 2) / (all_sigma_sq_gpu[None, None, :] ** 2))
    
    # ê°€ì¤‘í‰ê· : (326, 38)
    grad_zeta_all = cp.sum(all_weights_gpu[:, :, None] * grad_zeta_batch, axis=1)
    grad_sigma_sq_all = cp.sum(all_weights_gpu[:, :, None] * grad_sigma_sq_batch, axis=1)
    
    if iteration_logger and log_level == 'DETAILED':
        iteration_logger.info(
            f"  Gradient ê³„ì‚° ì™„ë£Œ\n"
            f"    - grad_zeta_all: {grad_zeta_all.shape}\n"
            f"    - grad_sigma_sq_all: {grad_sigma_sq_all.shape}"
        )
    
    # 7. LVë³„ë¡œ ë¶„ë¦¬
    gradients = {}
    idx = 0
    
    for lv_name in lv_names:
        config = gpu_measurement_model.models[lv_name].config
        n_ind = len(config.indicators)
        
        # fix_first_loading ê³ ë ¤
        fix_first_loading = getattr(config, 'fix_first_loading', True)
        
        if fix_first_loading:
            # ì²« ë²ˆì§¸ zetaëŠ” 1.0ìœ¼ë¡œ ê³ ì • (gradient ì œì™¸)
            grad_zeta_lv = cp.asnumpy(grad_zeta_all[:, idx+1:idx+n_ind])
        else:
            grad_zeta_lv = cp.asnumpy(grad_zeta_all[:, idx:idx+n_ind])
        
        gradients[lv_name] = {
            'zeta': grad_zeta_lv,
            'sigma_sq': cp.asnumpy(grad_sigma_sq_all[:, idx:idx+n_ind])
        }
        
        idx += n_ind
    
    elapsed = time.time() - start_time

    # ì‹¤ì œ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚° (fix_first_loading ê³ ë ¤)
    n_zeta_params = sum(len(gpu_measurement_model.models[lv].config.indicators) - 1
                        for lv in lv_names)  # ê° LVì˜ ì²« ë²ˆì§¸ ì œì™¸
    n_sigma_sq_params = n_total_indicators  # ëª¨ë“  sigma_sq
    n_total_params = n_zeta_params + n_sigma_sq_params

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  âœ… ì™„ì „ ë³‘ë ¬ ì¸¡ì •ëª¨ë¸ Gradient ê³„ì‚° ì™„ë£Œ ({elapsed:.4f}ì´ˆ)\n"
            f"    - GPU ì»¤ë„ í˜¸ì¶œ: 1ë²ˆ\n"
            f"    - ì§€í‘œ ìˆ˜: {n_total_indicators}ê°œ\n"
            f"    - íŒŒë¼ë¯¸í„° ìˆ˜: {n_total_params}ê°œ ({n_zeta_params} zeta + {n_sigma_sq_params} sigma_sq)\n"
            f"    - ê³„ì‚°ëŸ‰: {n_individuals} Ã— {n_draws} Ã— {n_total_indicators} Ã— 2 = "
            f"{n_individuals * n_draws * n_total_indicators * 2:,}ê°œ (zeta + sigma_sq)"
        )

    return gradients


def compute_all_individuals_gradients_full_parallel_gpu(
    gpu_measurement_model,
    all_ind_data: List[pd.DataFrame],
    all_ind_draws: np.ndarray,
    params_dict: Dict,
    measurement_model,
    structural_model,
    choice_model,
    iteration_logger=None,
    log_level: str = 'MINIMAL',
    use_scaling: bool = False  # âœ… ì¸¡ì •ëª¨ë¸ ìš°ë„ ìŠ¤ì¼€ì¼ë§ ì‚¬ìš© ì—¬ë¶€
) -> List[Dict]:
    """
    ëª¨ë“  ê°œì¸ì˜ gradientë¥¼ ì™„ì „ ë³‘ë ¬ë¡œ ê³„ì‚° (Advanced Indexing ì‚¬ìš©)

    âœ… ë™ì‹œì¶”ì • ì „ìš©: ì¸¡ì •ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ê³„ì‚°í•˜ì§€ ì•ŠìŒ (ê³ ì • íŒŒë¼ë¯¸í„°)

    êµ¬ì¡°ëª¨ë¸: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
    ì„ íƒëª¨ë¸: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©

    Args:
        gpu_measurement_model: GPU ì¸¡ì •ëª¨ë¸
        all_ind_data: ëª¨ë“  ê°œì¸ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        all_ind_draws: ëª¨ë“  ê°œì¸ì˜ draws (N, n_draws, n_dims)
        params_dict: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        measurement_model: ì¸¡ì •ëª¨ë¸
        structural_model: êµ¬ì¡°ëª¨ë¸
        choice_model: ì„ íƒëª¨ë¸
        iteration_logger: ë¡œê±°
        log_level: ë¡œê¹… ë ˆë²¨

    Returns:
        ê°œì¸ë³„ gradient ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
    """
    if not CUPY_AVAILABLE:
        raise RuntimeError("CuPy not available")
    
    start_time = time.time()
    
    n_individuals, n_draws, n_dims = all_ind_draws.shape
    
    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"\n{'='*70}\n"
            f"ì™„ì „ ë³‘ë ¬ Gradient ê³„ì‚° (Advanced Indexing)\n"
            f"{'='*70}\n"
            f"  ê°œì¸ ìˆ˜: {n_individuals}\n"
            f"  Draws: {n_draws}\n"
            f"  ì°¨ì›: {n_dims}"
        )
    
    # LV ì´ë¦„ ì¶”ì¶œ
    lv_names = list(params_dict['measurement'].keys())
    
    # 1. ëª¨ë“  ê°œì¸ì˜ LV ê°’ ê³„ì‚° (326, 100, 5)
    lv_start = time.time()
    all_lvs_list = []

    is_hierarchical = hasattr(structural_model, 'is_hierarchical') and structural_model.is_hierarchical

    for ind_idx, ind_data in enumerate(all_ind_data):
        ind_draws = all_ind_draws[ind_idx]  # (100, 6)

        # ê° drawì— ëŒ€í•œ LV ê°’ ê³„ì‚°
        lvs_for_draws = []
        for draw_idx in range(n_draws):
            draw = ind_draws[draw_idx]

            if is_hierarchical:
                # ê³„ì¸µì  êµ¬ì¡°: exo_drawsì™€ higher_order_draws ë¶„ë¦¬
                n_first_order = len(structural_model.exogenous_lvs)
                exo_draws = draw[:n_first_order]

                # 2ì°¨+ LV ì˜¤ì°¨í•­
                higher_order_draws = {}
                higher_order_lvs = structural_model.get_higher_order_lvs()
                for i, lv_name in enumerate(higher_order_lvs):
                    higher_order_draws[lv_name] = draw[n_first_order + i]

                lv_values = structural_model.predict(
                    ind_data, exo_draws, params_dict['structural'],
                    higher_order_draws=higher_order_draws
                )
            else:
                # ë³‘ë ¬ êµ¬ì¡° (í•˜ìœ„ í˜¸í™˜)
                lv_values = structural_model.predict(ind_data, draw, params_dict['structural'])

            lvs_for_draws.append([lv_values[lv_name] for lv_name in lv_names])

        all_lvs_list.append(lvs_for_draws)

    all_lvs_array = np.array(all_lvs_list)  # (326, 100, 5)
    all_lvs_gpu = cp.asarray(all_lvs_array)

    lv_time = time.time() - lv_start

    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"  LV ê³„ì‚° ì™„ë£Œ ({lv_time:.3f}ì´ˆ)\n"
            f"    - all_lvs shape: {all_lvs_array.shape}"
        )
        # ì²« ë²ˆì§¸ ê°œì¸ì˜ ì²« ë²ˆì§¸ draw LV ê°’ ì¶œë ¥ (ë””ë²„ê¹…)
        if len(all_lvs_list) > 0 and len(all_lvs_list[0]) > 0:
            first_lv_values = all_lvs_list[0][0]
            iteration_logger.info(f"  [ë””ë²„ê¹…] ì²« ë²ˆì§¸ ê°œì¸, ì²« ë²ˆì§¸ draw LV ê°’:")
            for lv_idx, lv_name in enumerate(lv_names):
                iteration_logger.info(f"    {lv_name}: {first_lv_values[lv_idx]:.6f}")
    
    # 2. ê°€ì¤‘ì¹˜ ê³„ì‚° (ê· ë“± ê°€ì¤‘ì¹˜)
    all_weights = np.ones((n_individuals, n_draws)) / n_draws
    all_weights_gpu = cp.asarray(all_weights)

    # âœ… ì¸¡ì •ëª¨ë¸ ìš°ë„ ìŠ¤ì¼€ì¼ë§ ê°€ì¤‘ì¹˜ ê³„ì‚°
    # Forward passì™€ ë™ì¼í•œ ìŠ¤ì¼€ì¼ë§ì„ Backward passì—ë„ ì ìš©
    measurement_weight = 1.0
    if use_scaling:
        n_measurement_indicators = 0
        if hasattr(gpu_measurement_model, 'models'):
            for lv_name, model in gpu_measurement_model.models.items():
                n_measurement_indicators += len(model.config.indicators)

        if n_measurement_indicators > 0:
            measurement_weight = 1.0 / n_measurement_indicators

            if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
                iteration_logger.info(
                    f"\n{'='*80}\n"
                    f"ğŸ“Š Gradient ìŠ¤ì¼€ì¼ë§ ì„¤ì • (ì™„ì „ ë³‘ë ¬)\n"
                    f"{'='*80}\n"
                    f"  ì¸¡ì •ëª¨ë¸ ì§€í‘œ ìˆ˜: {n_measurement_indicators}ê°œ\n"
                    f"  ì¸¡ì •ëª¨ë¸ ê°€ì¤‘ì¹˜ (Ï‰): {measurement_weight:.6f}\n"
                    f"  âˆ‡LL_total = âˆ‡LL_choice + {measurement_weight:.6f} Ã— âˆ‡LL_measurement\n"
                    f"{'='*80}"
                )

    # âœ… ë™ì‹œì¶”ì •: ì¸¡ì •ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì œì™¸ (ê³ ì • íŒŒë¼ë¯¸í„°)
    # ì¸¡ì •ëª¨ë¸ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì„¤ì •
    meas_grads = {}
    meas_time = 0.0

    # 4. êµ¬ì¡°ëª¨ë¸ Gradient (ê¸°ì¡´ ë°©ì‹)
    from .gpu_gradient_batch import compute_structural_full_batch_gpu

    struct_start = time.time()
    struct_grads = compute_structural_full_batch_gpu(
        all_ind_data,
        all_lvs_gpu,
        params_dict,
        all_weights_gpu,
        structural_model,
        choice_model,
        gpu_measurement_model,
        lv_names,
        iteration_logger,
        log_level,
        measurement_weight=measurement_weight  # âœ… ìŠ¤ì¼€ì¼ë§ ê°€ì¤‘ì¹˜ ì „ë‹¬
    )
    struct_time = time.time() - struct_start
    
    # 5. ì„ íƒëª¨ë¸ Gradient (ê¸°ì¡´ ë°©ì‹)
    from .gpu_gradient_batch import compute_choice_full_batch_gpu
    
    choice_start = time.time()
    choice_grads = compute_choice_full_batch_gpu(
        all_ind_data,
        all_lvs_gpu,
        params_dict['choice'],
        all_weights_gpu,
        choice_model,
        lv_names,
        iteration_logger,
        log_level
    )
    choice_time = time.time() - choice_start
    
    # 6. ê°œì¸ë³„ gradient ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    all_individual_gradients = []
    
    for ind_idx in range(n_individuals):
        # ì¸¡ì •ëª¨ë¸: {lv_name: {'zeta': array, 'sigma_sq': array}}
        meas_dict = {}
        for lv_name in meas_grads:
            meas_dict[lv_name] = {
                'zeta': meas_grads[lv_name]['zeta'][ind_idx],
                'sigma_sq': meas_grads[lv_name]['sigma_sq'][ind_idx]
            }

        # êµ¬ì¡°ëª¨ë¸: {param_name: scalar}
        struct_dict = {
            key: struct_grads[key][ind_idx].item() if hasattr(struct_grads[key][ind_idx], 'item')
            else struct_grads[key][ind_idx]
            for key in struct_grads
        }

        # ì„ íƒëª¨ë¸: {'intercept': scalar, 'beta': array, ...}
        choice_dict = {}
        for key in choice_grads:
            val = choice_grads[key][ind_idx]
            if key == 'beta':
                choice_dict[key] = val
            elif hasattr(val, 'item'):
                choice_dict[key] = val.item()
            else:
                choice_dict[key] = val
        
        ind_grad_dict = {
            'measurement': meas_dict,
            'structural': struct_dict,
            'choice': choice_dict
        }
        all_individual_gradients.append(ind_grad_dict)
    
    total_time = time.time() - start_time
    
    if iteration_logger and log_level in ['MODERATE', 'DETAILED']:
        iteration_logger.info(
            f"\n{'='*70}\n"
            f"ì™„ì „ ë³‘ë ¬ Gradient ê³„ì‚° ì™„ë£Œ ({total_time:.3f}ì´ˆ)\n"
            f"{'='*70}\n"
            f"  ì‹œê°„ ë¶„ì„:\n"
            f"    - LV ê³„ì‚°:      {lv_time:.3f}ì´ˆ ({lv_time/total_time*100:.1f}%)\n"
            f"    - ì¸¡ì •ëª¨ë¸:     {meas_time:.3f}ì´ˆ ({meas_time/total_time*100:.1f}%)\n"
            f"    - êµ¬ì¡°ëª¨ë¸:     {struct_time:.3f}ì´ˆ ({struct_time/total_time*100:.1f}%)\n"
            f"    - ì„ íƒëª¨ë¸:     {choice_time:.3f}ì´ˆ ({choice_time/total_time*100:.1f}%)\n"
            f"  ì„±ëŠ¥:\n"
            f"    - ê°œì¸ë‹¹ ì‹œê°„:  {total_time / n_individuals * 1000:.2f}ms\n"
            f"    - ì²˜ë¦¬ëŸ‰:       {n_individuals / total_time:.1f} ê°œì¸/ì´ˆ\n"
            f"{'='*70}"
        )
    
    return all_individual_gradients

