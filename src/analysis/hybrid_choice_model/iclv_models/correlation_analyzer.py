"""
í†µí•© ìƒê´€ê´€ê³„ ë¶„ì„ ëª¨ë“ˆ

1ë‹¨ê³„ SEM ë³€ìˆ˜ì™€ 2ë‹¨ê³„ ì„ íƒëª¨ë¸ ë³€ìˆ˜ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ìƒê´€ê´€ê³„ ë¶„ì„

ì£¼ìš” ê¸°ëŠ¥:
1. ì ì¬ë³€ìˆ˜ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ (1ë‹¨ê³„ SEM)
2. ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (1ë‹¨ê³„ SEM)
3. ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (2ë‹¨ê³„)
4. ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (2ë‹¨ê³„)
5. ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (1ë‹¨ê³„-2ë‹¨ê³„ ì—°ê²°)
6. ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (1ë‹¨ê³„-2ë‹¨ê³„ ì—°ê²°)

Author: Sugar Substitute Research Team
Date: 2025-11-16
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import logging
from datetime import datetime
import json

try:
    from semopy import Model
    SEMOPY_AVAILABLE = True
except ImportError:
    SEMOPY_AVAILABLE = False

logger = logging.getLogger(__name__)


class IntegratedCorrelationAnalyzer:
    """
    í†µí•© ìƒê´€ê´€ê³„ ë¶„ì„ê¸°
    
    1ë‹¨ê³„ SEMê³¼ 2ë‹¨ê³„ ì„ íƒëª¨ë¸ì˜ ëª¨ë“  ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” ìƒê´€ê´€ê³„ ë¶„ì„
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(__name__)
        self.results = {}
        
    def analyze_all_correlations(self,
                                 data: pd.DataFrame,
                                 measurement_model,
                                 structural_model,
                                 choice_config,
                                 factor_scores: Optional[Dict[str, np.ndarray]] = None,
                                 save_path: Optional[str] = None) -> Dict[str, Any]:
        """
        ì „ì²´ ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤í–‰
        
        Args:
            data: í†µí•© ë°ì´í„° (SEM ì§€í‘œ + ì„ íƒëª¨ë¸ ë³€ìˆ˜ í¬í•¨)
            measurement_model: ì¸¡ì •ëª¨ë¸ ê°ì²´
            structural_model: êµ¬ì¡°ëª¨ë¸ ê°ì²´
            choice_config: ì„ íƒëª¨ë¸ ì„¤ì •
            factor_scores: ìš”ì¸ì ìˆ˜ (ì„ íƒì‚¬í•­, ì—†ìœ¼ë©´ ê³„ì‚°)
            save_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ
            
        Returns:
            {
                'indicator_correlations': Dict,  # ì§€í‘œ ê°„ ìƒê´€ê´€ê³„
                'latent_correlations': pd.DataFrame,  # ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
                'attribute_correlations': pd.DataFrame,  # ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
                'sociodem_correlations': pd.DataFrame,  # ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
                'lv_attribute_correlations': pd.DataFrame,  # ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„
                'lv_sociodem_correlations': pd.DataFrame,  # ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„
                'full_correlation_matrix': pd.DataFrame,  # ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬
                'summary': Dict  # ìš”ì•½ í†µê³„
            }
        """
        self.logger.info("=== í†µí•© ìƒê´€ê´€ê³„ ë¶„ì„ ì‹œì‘ ===")
        
        results = {}
        
        # 1. ì ì¬ë³€ìˆ˜ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ (1ë‹¨ê³„ SEM)
        self.logger.info("\n[1] ì ì¬ë³€ìˆ˜ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
        results['indicator_correlations'] = self._analyze_indicator_correlations(
            data, measurement_model
        )
        
        # 2. ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (1ë‹¨ê³„ SEM)
        self.logger.info("\n[2] ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
        results['latent_correlations'] = self._analyze_latent_correlations(
            data, measurement_model, factor_scores
        )
        
        # 3. ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (2ë‹¨ê³„)
        self.logger.info("\n[3] ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
        results['attribute_correlations'] = self._analyze_attribute_correlations(
            data, choice_config
        )
        
        # 4. ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ (2ë‹¨ê³„)
        self.logger.info("\n[4] ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
        results['sociodem_correlations'] = self._analyze_sociodem_correlations(
            data, structural_model
        )
        
        # 5. ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
        self.logger.info("\n[5] ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
        results['lv_attribute_correlations'] = self._analyze_lv_attribute_correlations(
            data, measurement_model, choice_config, factor_scores
        )
        
        # 6. ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„
        self.logger.info("\n[6] ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„...")
        results['lv_sociodem_correlations'] = self._analyze_lv_sociodem_correlations(
            data, measurement_model, structural_model, factor_scores
        )
        
        # 7. ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬ ìƒì„±
        self.logger.info("\n[7] ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬ ìƒì„±...")
        results['full_correlation_matrix'] = self._build_full_correlation_matrix(
            data, measurement_model, structural_model, choice_config, factor_scores
        )
        
        # 8. ìš”ì•½ í†µê³„
        results['summary'] = self._generate_summary(results)
        
        # 9. ê²°ê³¼ ì €ì¥
        if save_path:
            self._save_results(results, save_path)
        
        self.results = results
        self.logger.info("\n=== í†µí•© ìƒê´€ê´€ê³„ ë¶„ì„ ì™„ë£Œ ===")

        return results

    def _analyze_indicator_correlations(self, data: pd.DataFrame,
                                        measurement_model) -> Dict[str, pd.DataFrame]:
        """
        ì ì¬ë³€ìˆ˜ë³„ ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„

        Returns:
            Dict[lv_name, correlation_matrix]
        """
        indicator_corrs = {}

        # ê°œì¸ë³„ unique ë°ì´í„° ì¶”ì¶œ
        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'

        for lv_name, config in measurement_model.configs.items():
            indicators = config.indicators

            # ê°œì¸ë³„ ì²« ë²ˆì§¸ í–‰ë§Œ ì„ íƒ
            unique_data = data.groupby(individual_col)[indicators].first().reset_index()

            # ìƒê´€ê´€ê³„ ê³„ì‚°
            corr_matrix = unique_data[indicators].corr()
            indicator_corrs[lv_name] = corr_matrix

            self.logger.info(f"  {lv_name}: {len(indicators)}ê°œ ì§€í‘œ")
            self.logger.info(f"    í‰ê·  ìƒê´€ê³„ìˆ˜: {corr_matrix.values[np.triu_indices_from(corr_matrix.values, k=1)].mean():.3f}")

        return indicator_corrs

    def _analyze_latent_correlations(self, data: pd.DataFrame,
                                     measurement_model,
                                     factor_scores: Optional[Dict[str, np.ndarray]] = None) -> pd.DataFrame:
        """
        ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„

        semopyë¥¼ ì‚¬ìš©í•˜ì—¬ CFA ëª¨ë¸ì—ì„œ ì ì¬ë³€ìˆ˜ ê°„ ê³µë¶„ì‚°/ìƒê´€ê³„ìˆ˜ ì¶”ì¶œ
        """
        if not SEMOPY_AVAILABLE:
            self.logger.warning("semopyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ê°œì¸ë³„ unique ë°ì´í„° ì¶”ì¶œ
        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'

        all_indicators = []
        for config in measurement_model.configs.values():
            all_indicators.extend(config.indicators)

        unique_data = data.groupby(individual_col)[all_indicators].first().reset_index()

        # CFA ëª¨ë¸ ìŠ¤í™ ìƒì„±
        model_spec = self._create_cfa_spec(measurement_model)

        # semopy ëª¨ë¸ ì í•©
        model = Model(model_spec)
        model.fit(unique_data)

        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        params = model.inspect(std_est=True)

        # ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì¶”ì¶œ
        latent_vars = list(measurement_model.configs.keys())
        factor_covs = params[params['op'] == '~~'].copy()

        # ìƒê´€ê³„ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        corr_matrix = pd.DataFrame(
            index=latent_vars,
            columns=latent_vars,
            dtype=float
        )

        # ëŒ€ê°ì„  ìš”ì†Œ (ìê¸° ìì‹  = 1.0)
        for lv in latent_vars:
            corr_matrix.loc[lv, lv] = 1.0

        # ë¹„ëŒ€ê°ì„  ìš”ì†Œ (ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê³„ìˆ˜)
        for _, row in factor_covs.iterrows():
            lval, rval = row['lval'], row['rval']

            if lval != rval and lval in latent_vars and rval in latent_vars:
                corr_value = row['Est. Std']  # í‘œì¤€í™”ëœ ì¶”ì •ê°’ (ìƒê´€ê³„ìˆ˜)
                corr_matrix.loc[lval, rval] = corr_value
                corr_matrix.loc[rval, lval] = corr_value

        self.logger.info(f"  ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„: {len(latent_vars)}ê°œ ì ì¬ë³€ìˆ˜")

        return corr_matrix

    def _analyze_attribute_correlations(self, data: pd.DataFrame,
                                        choice_config) -> pd.DataFrame:
        """
        ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        """
        attributes = choice_config.choice_attributes

        # ì†ì„±ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        available_attrs = [attr for attr in attributes if attr in data.columns]

        if not available_attrs:
            self.logger.warning("ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ìƒê´€ê´€ê³„ ê³„ì‚°
        corr_matrix = data[available_attrs].corr()

        self.logger.info(f"  ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„: {len(available_attrs)}ê°œ ë³€ìˆ˜")

        return corr_matrix

    def _analyze_sociodem_correlations(self, data: pd.DataFrame,
                                       structural_model) -> pd.DataFrame:
        """
        ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        """
        # êµ¬ì¡°ëª¨ë¸ì—ì„œ ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ì¶”ì¶œ
        if hasattr(structural_model, 'covariates'):
            sociodem_vars = structural_model.covariates
        elif hasattr(structural_model, 'sociodemographics'):
            # ë‹¨ì¼ ì ì¬ë³€ìˆ˜ ëª¨ë¸ì˜ ê²½ìš°
            if hasattr(structural_model.configs, 'values'):
                # ë‹¤ì¤‘ ì ì¬ë³€ìˆ˜ ëª¨ë¸
                sociodem_vars = []
                for config in structural_model.configs.values():
                    if hasattr(config, 'sociodemographics'):
                        sociodem_vars.extend(config.sociodemographics)
                sociodem_vars = list(set(sociodem_vars))  # ì¤‘ë³µ ì œê±°
            else:
                sociodem_vars = structural_model.sociodemographics
        else:
            self.logger.warning("êµ¬ì¡°ëª¨ë¸ì—ì„œ ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ê°œì¸ë³„ unique ë°ì´í„° ì¶”ì¶œ
        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'

        # ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        available_vars = [var for var in sociodem_vars if var in data.columns]

        if not available_vars:
            self.logger.warning("ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        unique_data = data.groupby(individual_col)[available_vars].first().reset_index()

        # ìƒê´€ê´€ê³„ ê³„ì‚°
        corr_matrix = unique_data[available_vars].corr()

        self.logger.info(f"  ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„: {len(available_vars)}ê°œ ë³€ìˆ˜")

        return corr_matrix

    def _analyze_lv_attribute_correlations(self, data: pd.DataFrame,
                                           measurement_model,
                                           choice_config,
                                           factor_scores: Optional[Dict[str, np.ndarray]] = None) -> pd.DataFrame:
        """
        ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        """
        # ìš”ì¸ì ìˆ˜ê°€ ì—†ìœ¼ë©´ ê³„ì‚°
        if factor_scores is None:
            factor_scores = self._compute_factor_scores(data, measurement_model)

        # ì ì¬ë³€ìˆ˜ ì´ë¦„
        latent_vars = list(measurement_model.configs.keys())

        # ì†ì„±ë³€ìˆ˜
        attributes = choice_config.choice_attributes
        available_attrs = [attr for attr in attributes if attr in data.columns]

        if not available_attrs:
            self.logger.warning("ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ê°œì¸ë³„ unique ë°ì´í„° ì¶”ì¶œ
        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'
        unique_data = data.groupby(individual_col)[available_attrs].first().reset_index()

        # ìš”ì¸ì ìˆ˜ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        for lv_name, scores in factor_scores.items():
            unique_data[lv_name] = scores

        # ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ê³„ì‚°
        all_vars = latent_vars + available_attrs
        corr_matrix = unique_data[all_vars].corr()

        # ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        lv_attr_corr = corr_matrix.loc[latent_vars, available_attrs]

        self.logger.info(f"  ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„: {len(latent_vars)}Ã—{len(available_attrs)}")

        return lv_attr_corr

    def _analyze_lv_sociodem_correlations(self, data: pd.DataFrame,
                                          measurement_model,
                                          structural_model,
                                          factor_scores: Optional[Dict[str, np.ndarray]] = None) -> pd.DataFrame:
        """
        ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        """
        # ìš”ì¸ì ìˆ˜ê°€ ì—†ìœ¼ë©´ ê³„ì‚°
        if factor_scores is None:
            factor_scores = self._compute_factor_scores(data, measurement_model)

        # ì ì¬ë³€ìˆ˜ ì´ë¦„
        latent_vars = list(measurement_model.configs.keys())

        # ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜
        if hasattr(structural_model, 'covariates'):
            sociodem_vars = structural_model.covariates
        elif hasattr(structural_model, 'sociodemographics'):
            if hasattr(structural_model.configs, 'values'):
                sociodem_vars = []
                for config in structural_model.configs.values():
                    if hasattr(config, 'sociodemographics'):
                        sociodem_vars.extend(config.sociodemographics)
                sociodem_vars = list(set(sociodem_vars))
            else:
                sociodem_vars = structural_model.sociodemographics
        else:
            self.logger.warning("êµ¬ì¡°ëª¨ë¸ì—ì„œ ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        available_vars = [var for var in sociodem_vars if var in data.columns]

        if not available_vars:
            self.logger.warning("ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        # ê°œì¸ë³„ unique ë°ì´í„° ì¶”ì¶œ
        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'
        unique_data = data.groupby(individual_col)[available_vars].first().reset_index()

        # ìš”ì¸ì ìˆ˜ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        for lv_name, scores in factor_scores.items():
            unique_data[lv_name] = scores

        # ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ê³„ì‚°
        all_vars = latent_vars + available_vars
        corr_matrix = unique_data[all_vars].corr()

        # ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        lv_sociodem_corr = corr_matrix.loc[latent_vars, available_vars]

        self.logger.info(f"  ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„: {len(latent_vars)}Ã—{len(available_vars)}")

        return lv_sociodem_corr

    def _build_full_correlation_matrix(self, data: pd.DataFrame,
                                       measurement_model,
                                       structural_model,
                                       choice_config,
                                       factor_scores: Optional[Dict[str, np.ndarray]] = None) -> pd.DataFrame:
        """
        ì „ì²´ ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ í–‰ë ¬ ìƒì„±

        í¬í•¨ ë³€ìˆ˜:
        - ì ì¬ë³€ìˆ˜ (ìš”ì¸ì ìˆ˜)
        - ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜
        - ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜
        """
        # ìš”ì¸ì ìˆ˜ê°€ ì—†ìœ¼ë©´ ê³„ì‚°
        if factor_scores is None:
            factor_scores = self._compute_factor_scores(data, measurement_model)

        # ë³€ìˆ˜ ëª©ë¡ ìˆ˜ì§‘
        latent_vars = list(measurement_model.configs.keys())

        attributes = choice_config.choice_attributes
        available_attrs = [attr for attr in attributes if attr in data.columns]

        if hasattr(structural_model, 'covariates'):
            sociodem_vars = structural_model.covariates
        elif hasattr(structural_model, 'sociodemographics'):
            if hasattr(structural_model.configs, 'values'):
                sociodem_vars = []
                for config in structural_model.configs.values():
                    if hasattr(config, 'sociodemographics'):
                        sociodem_vars.extend(config.sociodemographics)
                sociodem_vars = list(set(sociodem_vars))
            else:
                sociodem_vars = structural_model.sociodemographics
        else:
            sociodem_vars = []

        available_sociodem = [var for var in sociodem_vars if var in data.columns]

        # ê°œì¸ë³„ unique ë°ì´í„° ì¶”ì¶œ
        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'
        all_vars = available_attrs + available_sociodem
        unique_data = data.groupby(individual_col)[all_vars].first().reset_index()

        # ìš”ì¸ì ìˆ˜ ì¶”ê°€
        for lv_name, scores in factor_scores.items():
            unique_data[lv_name] = scores

        # ì „ì²´ ìƒê´€ê´€ê³„ ê³„ì‚°
        all_analysis_vars = latent_vars + available_attrs + available_sociodem
        corr_matrix = unique_data[all_analysis_vars].corr()

        self.logger.info(f"  ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬: {len(all_analysis_vars)}Ã—{len(all_analysis_vars)}")

        return corr_matrix

    def _create_cfa_spec(self, measurement_model) -> str:
        """CFA ëª¨ë¸ ìŠ¤í™ ìƒì„± (semopy í˜•ì‹)"""
        model_lines = []

        for lv_name, config in measurement_model.configs.items():
            indicators = " + ".join(config.indicators)
            model_lines.append(f"{lv_name} =~ {indicators}")

        return "\n".join(model_lines)

    def _compute_factor_scores(self, data: pd.DataFrame, measurement_model) -> Dict[str, np.ndarray]:
        """
        ìš”ì¸ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ í‰ê·  ë°©ì‹)

        ì‹¤ì œë¡œëŠ” SEMEstimatorë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì •í™•í•˜ì§€ë§Œ,
        ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì§€í‘œì˜ í‰ê· ìœ¼ë¡œ ê³„ì‚°
        """
        factor_scores = {}

        individual_col = 'respondent_id' if 'respondent_id' in data.columns else 'id'

        for lv_name, config in measurement_model.configs.items():
            indicators = config.indicators
            unique_data = data.groupby(individual_col)[indicators].first().reset_index()

            # ì§€í‘œì˜ í‰ê· ìœ¼ë¡œ ìš”ì¸ì ìˆ˜ ê³„ì‚°
            factor_scores[lv_name] = unique_data[indicators].mean(axis=1).values

        return factor_scores

    def _generate_summary(self, results: Dict) -> Dict:
        """ìš”ì•½ í†µê³„ ìƒì„±"""
        summary = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'n_latent_variables': 0,
            'n_attributes': 0,
            'n_sociodem_variables': 0,
            'significant_correlations': {}
        }

        # ì ì¬ë³€ìˆ˜ ê°œìˆ˜
        if 'latent_correlations' in results and not results['latent_correlations'].empty:
            summary['n_latent_variables'] = len(results['latent_correlations'])

        # ì†ì„±ë³€ìˆ˜ ê°œìˆ˜
        if 'attribute_correlations' in results and not results['attribute_correlations'].empty:
            summary['n_attributes'] = len(results['attribute_correlations'])

        # ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°œìˆ˜
        if 'sociodem_correlations' in results and not results['sociodem_correlations'].empty:
            summary['n_sociodem_variables'] = len(results['sociodem_correlations'])

        # ìœ ì˜í•œ ìƒê´€ê´€ê³„ (|r| > 0.3)
        if 'full_correlation_matrix' in results and not results['full_correlation_matrix'].empty:
            corr_matrix = results['full_correlation_matrix']
            upper_triangle = np.triu(corr_matrix.values, k=1)

            # ê°•í•œ ìƒê´€ê´€ê³„ (|r| > 0.5)
            strong_corr = np.abs(upper_triangle) > 0.5
            summary['n_strong_correlations'] = int(strong_corr.sum())

            # ì¤‘ê°„ ìƒê´€ê´€ê³„ (0.3 < |r| <= 0.5)
            moderate_corr = (np.abs(upper_triangle) > 0.3) & (np.abs(upper_triangle) <= 0.5)
            summary['n_moderate_correlations'] = int(moderate_corr.sum())

            # ì•½í•œ ìƒê´€ê´€ê³„ (|r| <= 0.3)
            weak_corr = np.abs(upper_triangle) <= 0.3
            summary['n_weak_correlations'] = int(weak_corr.sum())

        return summary

    def _save_results(self, results: Dict, save_path: str):
        """ê²°ê³¼ ì €ì¥"""
        save_dir = Path(save_path)
        save_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 1. ì§€í‘œ ê°„ ìƒê´€ê´€ê³„ ì €ì¥
        if 'indicator_correlations' in results:
            for lv_name, corr_matrix in results['indicator_correlations'].items():
                file_path = save_dir / f"indicator_corr_{lv_name}_{timestamp}.csv"
                corr_matrix.to_csv(file_path, encoding='utf-8-sig')
                self.logger.info(f"ì €ì¥: {file_path}")

        # 2. ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì €ì¥
        if 'latent_correlations' in results and not results['latent_correlations'].empty:
            file_path = save_dir / f"latent_correlations_{timestamp}.csv"
            results['latent_correlations'].to_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ì €ì¥: {file_path}")

        # 3. ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì €ì¥
        if 'attribute_correlations' in results and not results['attribute_correlations'].empty:
            file_path = save_dir / f"attribute_correlations_{timestamp}.csv"
            results['attribute_correlations'].to_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ì €ì¥: {file_path}")

        # 4. ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì €ì¥
        if 'sociodem_correlations' in results and not results['sociodem_correlations'].empty:
            file_path = save_dir / f"sociodem_correlations_{timestamp}.csv"
            results['sociodem_correlations'].to_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ì €ì¥: {file_path}")

        # 5. ì ì¬ë³€ìˆ˜-ì†ì„±ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì €ì¥
        if 'lv_attribute_correlations' in results and not results['lv_attribute_correlations'].empty:
            file_path = save_dir / f"lv_attribute_correlations_{timestamp}.csv"
            results['lv_attribute_correlations'].to_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ì €ì¥: {file_path}")

        # 6. ì ì¬ë³€ìˆ˜-ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì €ì¥
        if 'lv_sociodem_correlations' in results and not results['lv_sociodem_correlations'].empty:
            file_path = save_dir / f"lv_sociodem_correlations_{timestamp}.csv"
            results['lv_sociodem_correlations'].to_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ì €ì¥: {file_path}")

        # 7. ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬ ì €ì¥
        if 'full_correlation_matrix' in results and not results['full_correlation_matrix'].empty:
            file_path = save_dir / f"full_correlation_matrix_{timestamp}.csv"
            results['full_correlation_matrix'].to_csv(file_path, encoding='utf-8-sig')
            self.logger.info(f"ì €ì¥: {file_path}")

        # 8. ìš”ì•½ í†µê³„ ì €ì¥ (JSON)
        if 'summary' in results:
            file_path = save_dir / f"correlation_summary_{timestamp}.json"
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(results['summary'], f, indent=2, ensure_ascii=False)
            self.logger.info(f"ì €ì¥: {file_path}")

        self.logger.info(f"\nëª¨ë“  ê²°ê³¼ê°€ {save_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.results:
            self.logger.warning("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. analyze_all_correlations()ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return

        print("\n" + "="*80)
        print("ğŸ“Š í†µí•© ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*80)

        summary = self.results.get('summary', {})

        print(f"\në¶„ì„ ì‹œê°: {summary.get('timestamp', 'N/A')}")
        print(f"\në³€ìˆ˜ ê°œìˆ˜:")
        print(f"  - ì ì¬ë³€ìˆ˜: {summary.get('n_latent_variables', 0)}ê°œ")
        print(f"  - ì„ íƒëª¨ë¸ ì†ì„±ë³€ìˆ˜: {summary.get('n_attributes', 0)}ê°œ")
        print(f"  - ì‚¬íšŒì¸êµ¬í†µê³„ë³€ìˆ˜: {summary.get('n_sociodem_variables', 0)}ê°œ")

        print(f"\nìƒê´€ê´€ê³„ ê°•ë„ ë¶„í¬:")
        print(f"  - ê°•í•œ ìƒê´€ê´€ê³„ (|r| > 0.5): {summary.get('n_strong_correlations', 0)}ê°œ")
        print(f"  - ì¤‘ê°„ ìƒê´€ê´€ê³„ (0.3 < |r| â‰¤ 0.5): {summary.get('n_moderate_correlations', 0)}ê°œ")
        print(f"  - ì•½í•œ ìƒê´€ê´€ê³„ (|r| â‰¤ 0.3): {summary.get('n_weak_correlations', 0)}ê°œ")

        # ì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì¶œë ¥
        if 'latent_correlations' in self.results and not self.results['latent_correlations'].empty:
            print(f"\nì ì¬ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„:")
            print(self.results['latent_correlations'].round(3))

        print("\n" + "="*80)

