"""
Choice Equations for ICLV Models

ICLV ì„ íƒëª¨ë¸: ì†ì„± + ì ì¬ë³€ìˆ˜ â†’ ì„ íƒ

Based on King (2022) Apollo R code implementation.

Author: Sugar Substitute Research Team
Date: 2025-11-05
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from scipy import stats
from scipy.stats import norm
from scipy.optimize import minimize
from abc import ABC, abstractmethod
import logging
from dataclasses import dataclass

# ChoiceConfig ì •ì˜ (import ì˜¤ë¥˜ ë°©ì§€)
try:
    from .iclv_config import ChoiceConfig
except ImportError:
    from typing import Literal
    
    @dataclass
    class ChoiceConfig:
        """ì„ íƒëª¨ë¸ ì„¤ì •"""
        choice_attributes: List[str]
        choice_type: Literal['binary', 'multinomial', 'ordered'] = 'binary'
        price_variable: str = 'price'
        initial_betas: Optional[Dict[str, float]] = None
        initial_lambda: float = 1.0
        thresholds: Optional[List[float]] = None

logger = logging.getLogger(__name__)


class BaseICLVChoice(ABC):
    """
    ICLV ì„ íƒëª¨ë¸ ë² ì´ìŠ¤ í´ë˜ìŠ¤

    ê³µí†µ ê¸°ëŠ¥:
    - íš¨ìš© ê³„ì‚° (ì¡°ì ˆíš¨ê³¼ ì§€ì›)
    - ì ì¬ë³€ìˆ˜ ì²˜ë¦¬
    - opt-out ëŒ€ì•ˆ ì²˜ë¦¬

    í•˜ìœ„ í´ë˜ìŠ¤ê°€ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ:
    - log_likelihood(): ëª¨ë¸ë³„ í™•ë¥  ê³„ì‚° ë° ë¡œê·¸ìš°ë„
    """

    def __init__(self, config: ChoiceConfig):
        """
        ì´ˆê¸°í™”

        Args:
            config: ì„ íƒëª¨ë¸ ì„¤ì •
        """
        self.config = config
        self.choice_attributes = config.choice_attributes
        self.price_variable = config.price_variable

        # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ì„¤ì •
        self.main_lvs = config.main_lvs if config.main_lvs else []
        self.lv_attribute_interactions = config.lv_attribute_interactions if config.lv_attribute_interactions else []

        self.logger = logging.getLogger(__name__)

        self.logger.info(f"{self.__class__.__name__} ì´ˆê¸°í™”")
        self.logger.info(f"  ì„ íƒ ì†ì„±: {self.choice_attributes}")
        self.logger.info(f"  ê°€ê²© ë³€ìˆ˜: {self.price_variable}")
        self.logger.info(f"  ì£¼íš¨ê³¼ LV: {self.main_lvs if self.main_lvs else 'ì—†ìŒ (Base Model)'}")
        self.logger.info(f"  LV-Attribute ìƒí˜¸ì‘ìš©: {len(self.lv_attribute_interactions)}ê°œ")
        if self.lv_attribute_interactions:
            self.logger.info(f"  ìƒí˜¸ì‘ìš© í•­ëª©: {self.lv_attribute_interactions}")

    def _compute_utilities(self, data: pd.DataFrame, lv, params: Dict) -> np.ndarray:
        """
        íš¨ìš© ê³„ì‚° (ê³µí†µ ë¡œì§)

        âœ… ëŒ€ì•ˆë³„ ASCì™€ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜ ì§€ì›

        ëŒ€ì•ˆë³„ ëª¨ë¸ (Multinomial Logit):
            V_A = ASC_A + Î¸_A_PI * PI + Î¸_A_NK * NK + Î²*X_A
            V_B = ASC_B + Î¸_B_PI * PI + Î¸_B_NK * NK + Î²*X_B
            V_C = 0 (opt-out, reference alternative)

        ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸ (Binary/ê¸°íƒ€):
            V = intercept + Î²*X + Î£(Î»_i * LV_i)

        ì¡°ì ˆíš¨ê³¼ ëª¨ë¸:
            V = intercept + Î²*X + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i)

        ê¸°ë³¸ ëª¨ë¸:
            V = intercept + Î²*X + Î»*LV

        Args:
            data: ì„ íƒ ë°ì´í„°
            lv: ì ì¬ë³€ìˆ˜ ê°’
                - Dict[str, np.ndarray] (ë‹¤ì¤‘ LV ëª¨ë¸)
                - np.ndarray ë˜ëŠ” float (ë‹¨ì¼ LV ëª¨ë¸)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            íš¨ìš© ë²¡í„° (n_obs,)
        """
        beta = params['beta']

        # ì„ íƒ ì†ì„± ì¶”ì¶œ
        X = data[self.choice_attributes].values

        # NaN ì²˜ë¦¬ (opt-out ëŒ€ì•ˆ)
        has_nan = np.isnan(X).any(axis=1)

        # íš¨ìš© ê³„ì‚°
        V = np.zeros(len(data))

        # âœ… ëŒ€ì•ˆë³„ íŒŒë¼ë¯¸í„° ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (Multinomial Logit)
        # Base Model (ì ì¬ë³€ìˆ˜ ì—†ìŒ)ë„ ëŒ€ì•ˆë³„ ASC ì‚¬ìš©
        use_alternative_specific = 'asc_sugar' in params or 'ASC_sugar' in params or 'asc_A' in params or 'ASC_A' in params

        if use_alternative_specific:
            # âœ… ëŒ€ì•ˆë³„ ëª¨ë¸ (Multinomial Logit with ASC)
            # V_alt = ASC_alt + Î£(Î¸_alt_i * LV_i) + Î²*X_alt
            # Base Modelì˜ ê²½ìš°: V_alt = ASC_alt + Î²*X_alt (ì ì¬ë³€ìˆ˜ ì—†ìŒ)

            # âœ… ê° LVë¥¼ ë°°ì—´ë¡œ ë³€í™˜ (ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜)
            lv_arrays = {}
            if isinstance(lv, dict):
                # ê°œì¸ ì¸ë±ìŠ¤ ê³„ì‚° (ê° í–‰ â†’ ê°œì¸)
                # ë°ì´í„° êµ¬ì¡°: ê°œì¸1_ì„ íƒ1_ëŒ€ì•ˆ1, ê°œì¸1_ì„ íƒ1_ëŒ€ì•ˆ2, ê°œì¸1_ì„ íƒ1_ëŒ€ì•ˆ3, ê°œì¸1_ì„ íƒ2_ëŒ€ì•ˆ1, ...
                # ê°œì¸ ìˆ˜ ì¶”ì •: ì²« ë²ˆì§¸ LV ë°°ì—´ì˜ ê¸¸ì´
                first_lv_name = list(lv.keys())[0]
                first_lv_value = lv[first_lv_name]
                if np.isscalar(first_lv_value):
                    n_individuals = 1
                else:
                    n_individuals = len(first_lv_value)

                # ì„ íƒ ìƒí™© ìˆ˜ ê³„ì‚°
                n_choice_situations = len(data) // (n_individuals * self.n_alternatives)

                # ê°œì¸ ì¸ë±ìŠ¤: ê° í–‰ì´ ì–´ëŠ ê°œì¸ì— ì†í•˜ëŠ”ì§€
                # ì˜ˆ: ê°œì¸ 0ì˜ 8ê°œ ì„ íƒ ìƒí™© Ã— 3ê°œ ëŒ€ì•ˆ = 24í–‰ â†’ person_idx = [0]*24
                person_idx = np.repeat(np.arange(n_individuals), n_choice_situations * self.n_alternatives)

                # ì£¼íš¨ê³¼ì— ì‚¬ìš©ë˜ëŠ” ì ì¬ë³€ìˆ˜
                for lv_name in self.main_lvs:
                    if lv_name not in lv:
                        raise KeyError(f"ì ì¬ë³€ìˆ˜ '{lv_name}'ê°€ lv dictì— ì—†ìŠµë‹ˆë‹¤.")

                    lv_value = lv[lv_name]
                    if np.isscalar(lv_value):
                        lv_arrays[lv_name] = np.full(len(data), lv_value)
                    else:
                        # ê°œì¸ ìˆ˜ì¤€ ë°°ì—´ â†’ ì „ì²´ ë°ì´í„° ê¸¸ì´ë¡œ í™•ì¥
                        # person_idxë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í–‰ì— í•´ë‹¹í•˜ëŠ” ê°œì¸ì˜ LV ê°’ í• ë‹¹
                        lv_arrays[lv_name] = lv_value[person_idx]

                # âœ… ìƒí˜¸ì‘ìš©ì— ì‚¬ìš©ë˜ëŠ” ì ì¬ë³€ìˆ˜ (ì£¼íš¨ê³¼ ì—†ì–´ë„ í¬í•¨)
                for interaction in self.lv_attribute_interactions:
                    lv_name = interaction['lv']
                    if lv_name not in lv_arrays and lv_name in lv:
                        lv_value = lv[lv_name]
                        if np.isscalar(lv_value):
                            lv_arrays[lv_name] = np.full(len(data), lv_value)
                        else:
                            # ê°œì¸ ìˆ˜ì¤€ ë°°ì—´ â†’ ì „ì²´ ë°ì´í„° ê¸¸ì´ë¡œ í™•ì¥
                            lv_arrays[lv_name] = lv_value[person_idx]

                # ë””ë²„ê¹…: lv_arrays ë‚´ìš© ë¡œê¹… (ì²« í˜¸ì¶œ ì‹œì—ë§Œ)
                if not hasattr(self, '_lv_arrays_logged'):
                    self.logger.info(f"lv_arrays ìƒì„± ì™„ë£Œ: {list(lv_arrays.keys())}")
                    for lv_name, lv_arr in lv_arrays.items():
                        self.logger.info(f"  {lv_name}: shape={lv_arr.shape if hasattr(lv_arr, 'shape') else 'scalar'}, first 3 values={lv_arr[:3] if hasattr(lv_arr, '__getitem__') else lv_arr}")
                    self._lv_arrays_logged = True

            # âœ… ë²¡í„°í™”ëœ íš¨ìš© ê³„ì‚°
            if 'sugar_content' in data.columns:
                # sugar_content ê¸°ì¤€ ëŒ€ì•ˆ êµ¬ë¶„
                sugar_content_col = data['sugar_content'].values

                # ë§ˆìŠ¤í¬ ìƒì„±
                is_sugar = (sugar_content_col == 'ì•Œë°˜ë‹¹') & ~has_nan
                is_sugar_free = (sugar_content_col == 'ë¬´ì„¤íƒ•') & ~has_nan
                is_opt_out = pd.isna(sugar_content_col) | has_nan

                # ê¸°ë³¸ íš¨ìš©: ASC + Î²*X (ë²¡í„°í™”)
                asc_sugar = params.get('asc_sugar', params.get('ASC_sugar', 0.0))
                asc_sugar_free = params.get('asc_sugar_free', params.get('ASC_sugar_free', 0.0))

                V[is_sugar] = asc_sugar + (X[is_sugar] @ beta)
                V[is_sugar_free] = asc_sugar_free + (X[is_sugar_free] @ beta)
                V[is_opt_out] = 0.0

                # LV ì£¼íš¨ê³¼ ì¶”ê°€ (ë²¡í„°í™”)
                if lv_arrays:
                    for lv_name in self.main_lvs:
                        # ì•Œë°˜ë‹¹ ëŒ€ì•ˆ
                        param_name_sugar = f'theta_sugar_{lv_name}'
                        if param_name_sugar in params:
                            theta = params[param_name_sugar]
                            # lv_arraysëŠ” ì´ë¯¸ ì „ì²´ ë°ì´í„° ê¸¸ì´ë¡œ í™•ì¥ë¨
                            V[is_sugar] += theta * lv_arrays[lv_name][is_sugar]

                        # ë¬´ì„¤íƒ• ëŒ€ì•ˆ
                        param_name_sugar_free = f'theta_sugar_free_{lv_name}'
                        if param_name_sugar_free in params:
                            theta = params[param_name_sugar_free]
                            V[is_sugar_free] += theta * lv_arrays[lv_name][is_sugar_free]

                # LV-Attribute ìƒí˜¸ì‘ìš© ì¶”ê°€ (ë²¡í„°í™”)
                if lv_arrays and self.lv_attribute_interactions:
                    for interaction in self.lv_attribute_interactions:
                        lv_name = interaction['lv']
                        attr_name = interaction['attribute']

                        if lv_name not in lv_arrays or attr_name not in self.choice_attributes:
                            continue

                        attr_idx = self.choice_attributes.index(attr_name)
                        lv_values = lv_arrays[lv_name]  # Shape: (N,)
                        attr_values = X[:, attr_idx]     # Shape: (N,) - 1D slice from 2D array

                        # âœ… ì°¨ì› ê²€ì¦ (ë””ë²„ê¹…ìš©)
                        assert lv_values.ndim == 1, f"lv_values should be 1D, got {lv_values.ndim}D"
                        assert attr_values.ndim == 1, f"attr_values should be 1D, got {attr_values.ndim}D"
                        assert len(lv_values) == len(attr_values), f"Length mismatch: lv_values={len(lv_values)}, attr_values={len(attr_values)}"

                        # ì•Œë°˜ë‹¹ ìƒí˜¸ì‘ìš©
                        param_name_sugar = f'gamma_sugar_{lv_name}_{attr_name}'
                        if param_name_sugar in params:
                            gamma = params[param_name_sugar]
                            interaction_term = gamma * lv_values * attr_values  # Element-wise: (N,) * (N,) = (N,)
                            V[is_sugar] += interaction_term[is_sugar]

                            # ğŸ” ìƒì„¸ ë¡œê¹… (ì²« 5ê°œë§Œ)
                            if not hasattr(self, '_interaction_logged_sugar'):
                                sugar_indices = np.where(is_sugar)[0][:5]
                                for i in sugar_indices:
                                    self.logger.info(f"[ì•Œë°˜ë‹¹ ìƒí˜¸ì‘ìš©] i={i}, gamma={gamma:.4f}, LV={lv_values[i]:.4f}, attr={attr_values[i]:.4f}, term={interaction_term[i]:.4f}, V[{i}]={V[i]:.4f}")
                                self._interaction_logged_sugar = True

                        # ë¬´ì„¤íƒ• ìƒí˜¸ì‘ìš©
                        param_name_sugar_free = f'gamma_sugar_free_{lv_name}_{attr_name}'
                        if param_name_sugar_free in params:
                            gamma = params[param_name_sugar_free]
                            interaction_term = gamma * lv_values * attr_values  # Element-wise: (N,) * (N,) = (N,)
                            V[is_sugar_free] += interaction_term[is_sugar_free]

                            # ğŸ” ìƒì„¸ ë¡œê¹… (ì²« 5ê°œë§Œ)
                            if not hasattr(self, '_interaction_logged_sugar_free'):
                                sugar_free_indices = np.where(is_sugar_free)[0][:5]
                                for i in sugar_free_indices:
                                    self.logger.info(f"[ë¬´ì„¤íƒ• ìƒí˜¸ì‘ìš©] i={i}, gamma={gamma:.4f}, LV={lv_values[i]:.4f}, attr={attr_values[i]:.4f}, term={interaction_term[i]:.4f}, V[{i}]={V[i]:.4f}")
                                self._interaction_logged_sugar_free = True

            else:
                # sugar_content ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ (alternative ê¸°ì¤€) - ë²¡í„°í™”
                alt_idx = np.arange(len(data)) % self.n_alternatives

                is_alt_A = (alt_idx == 0) & ~has_nan
                is_alt_B = (alt_idx == 1) & ~has_nan
                is_opt_out = (alt_idx == 2) | has_nan

                # ê¸°ë³¸ íš¨ìš©: ASC + Î²*X
                asc_A = params.get('asc_A', params.get('ASC_A', 0.0))
                asc_B = params.get('asc_B', params.get('ASC_B', 0.0))

                V[is_alt_A] = asc_A + (X[is_alt_A] @ beta)
                V[is_alt_B] = asc_B + (X[is_alt_B] @ beta)
                V[is_opt_out] = 0.0

                # LV ì£¼íš¨ê³¼ ì¶”ê°€ (ë²¡í„°í™”)
                if lv_arrays:
                    for lv_name in self.main_lvs:
                        # ëŒ€ì•ˆ A
                        param_name_A = f'theta_A_{lv_name}'
                        if param_name_A in params:
                            theta = params[param_name_A]
                            V[is_alt_A] += theta * lv_arrays[lv_name][is_alt_A]

                        # ëŒ€ì•ˆ B
                        param_name_B = f'theta_B_{lv_name}'
                        if param_name_B in params:
                            theta = params[param_name_B]
                            V[is_alt_B] += theta * lv_arrays[lv_name][is_alt_B]

        elif self.all_lvs_as_main and isinstance(lv, dict) and self.main_lvs:
            # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸ (ëŒ€ì•ˆë³„ì´ ì•„ë‹Œ ê²½ìš°)
            # V = intercept + Î²*X + Î£(Î»_i * LV_i)

            # ê° LVë¥¼ ë°°ì—´ë¡œ ë³€í™˜
            lv_arrays = {}
            for lv_name in self.main_lvs:
                if lv_name not in lv:
                    raise KeyError(f"ì ì¬ë³€ìˆ˜ '{lv_name}'ê°€ lv dictì— ì—†ìŠµë‹ˆë‹¤.")

                lv_value = lv[lv_name]
                if np.isscalar(lv_value):
                    lv_arrays[lv_name] = np.full(len(data), lv_value)
                else:
                    lv_arrays[lv_name] = lv_value

            # âœ… ë²¡í„°í™”ëœ íš¨ìš© ê³„ì‚°
            intercept = params.get('intercept', 0.0)

            # ê¸°ë³¸ íš¨ìš©: intercept + Î²*X (ë²¡í„°í™”)
            V[~has_nan] = intercept + (X[~has_nan] @ beta)
            V[has_nan] = 0.0

            # ëª¨ë“  LV ì£¼íš¨ê³¼ ì¶”ê°€ (ë²¡í„°í™”)
            for lv_name in self.main_lvs:
                param_name = f'lambda_{lv_name}'
                if param_name in params:
                    lambda_lv = params[param_name]
                    V[~has_nan] += lambda_lv * lv_arrays[lv_name][~has_nan]

            # âœ… LV-Attribute ìƒí˜¸ì‘ìš© ì¶”ê°€ (ë²¡í„°í™”)
            if self.lv_attribute_interactions:
                for interaction in self.lv_attribute_interactions:
                    lv_name = interaction['lv']
                    attr_name = interaction['attribute']

                    # íŒŒë¼ë¯¸í„° ì´ë¦„: gamma_PI_price, gamma_PI_health_label, gamma_NK_health_label
                    param_name = f'gamma_{lv_name}_{attr_name}'

                    if param_name in params and attr_name in self.choice_attributes:
                        gamma = params[param_name]
                        attr_idx = self.choice_attributes.index(attr_name)

                        # ìƒí˜¸ì‘ìš©í•­ ì¶”ê°€: Î³ * LV * Attribute (ë²¡í„°í™”)
                        lv_values = lv_arrays[lv_name]  # Shape: (N,)
                        attr_values = X[:, attr_idx]     # Shape: (N,)

                        # âœ… ì°¨ì› ê²€ì¦
                        assert lv_values.ndim == 1, f"lv_values should be 1D, got {lv_values.ndim}D"
                        assert attr_values.ndim == 1, f"attr_values should be 1D, got {attr_values.ndim}D"

                        # Element-wise multiplication: (N,) * (N,) = (N,)
                        V[~has_nan] += gamma * lv_values[~has_nan] * attr_values[~has_nan]

        elif self.moderation_enabled and isinstance(lv, dict):
            # ì¡°ì ˆíš¨ê³¼ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
            intercept = params.get('intercept', 0.0)
            lambda_main = params.get('lambda_main', params.get('lambda', 1.0))

            # ì£¼ LV ì¶”ì¶œ
            lv_main = lv[self.main_lv]
            if np.isscalar(lv_main):
                lv_main_array = np.full(len(data), lv_main)
            else:
                lv_main_array = lv_main

            # ì¡°ì ˆ LV ì¶”ì¶œ
            moderator_arrays = {}
            for mod_lv in self.moderator_lvs:
                lv_mod = lv[mod_lv]
                if np.isscalar(lv_mod):
                    moderator_arrays[mod_lv] = np.full(len(data), lv_mod)
                else:
                    moderator_arrays[mod_lv] = lv_mod

            # âœ… ë²¡í„°í™”ëœ íš¨ìš© ê³„ì‚°: V = intercept + Î²*X + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i)
            # ê¸°ë³¸ íš¨ìš©
            V[~has_nan] = intercept + (X[~has_nan] @ beta) + lambda_main * lv_main_array[~has_nan]
            V[has_nan] = 0.0

            # ì¡°ì ˆíš¨ê³¼ ì¶”ê°€ (ë²¡í„°í™”)
            for mod_lv in self.moderator_lvs:
                param_name = f'lambda_mod_{mod_lv}'
                if param_name in params:
                    lambda_mod = params[param_name]
                    interaction = lv_main_array * moderator_arrays[mod_lv]
                    V[~has_nan] += lambda_mod * interaction[~has_nan]

        else:
            # ê¸°ë³¸ ëª¨ë¸ (ë‹¨ì¼ LV, í•˜ìœ„ í˜¸í™˜)
            intercept = params.get('intercept', 0.0)
            lambda_lv = params.get('lambda', params.get('lambda_main', 1.0))

            # ì ì¬ë³€ìˆ˜ ì²˜ë¦¬ (ìŠ¤ì¹¼ë¼ ë˜ëŠ” ë°°ì—´)
            if isinstance(lv, dict):
                # dictì¸ ê²½ìš° main_lv ì‚¬ìš©
                lv_value = lv[self.main_lv]
            else:
                lv_value = lv

            if np.isscalar(lv_value):
                lv_array = np.full(len(data), lv_value)
            else:
                lv_array = lv_value

            # âœ… ë²¡í„°í™”ëœ íš¨ìš© ê³„ì‚°: V = intercept + Î²*X + Î»*LV
            V[~has_nan] = intercept + (X[~has_nan] @ beta) + lambda_lv * lv_array[~has_nan]
            V[has_nan] = 0.0

        return V

    @abstractmethod
    def log_likelihood(self, data: pd.DataFrame, lv, params: Dict) -> float:
        """
        ì„ íƒëª¨ë¸ ë¡œê·¸ìš°ë„ (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)

        Args:
            data: ì„ íƒ ë°ì´í„°
            lv: ì ì¬ë³€ìˆ˜ ê°’
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            ë¡œê·¸ìš°ë„ ê°’
        """
        pass


class BinaryProbitChoice(BaseICLVChoice):
    """
    Binary Probit ì„ íƒëª¨ë¸ (ICLVìš©)

    âœ… ë””í´íŠ¸: ëª¨ë“  LV ì£¼íš¨ê³¼

    ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸:
        V = intercept + Î²*X + Î£(Î»_i * LV_i)
        P(Yes) = Î¦(V)

    ê¸°ë³¸ ëª¨ë¸:
        V = intercept + Î²*X + Î»*LV
        P(Yes) = Î¦(V)

    ì¡°ì ˆíš¨ê³¼ ëª¨ë¸ (ë””í´íŠ¸):
        V = intercept + Î²*X + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i)
        P(Yes) = Î¦(V)

    ì—¬ê¸°ì„œ:
        - V: íš¨ìš© (Utility)
        - X: ì„ íƒ ì†ì„± (Choice attributes, e.g., price, quality)
        - Î²: ì†ì„± ê³„ìˆ˜ (Attribute coefficients)
        - Î»_main: ì£¼íš¨ê³¼ ê³„ìˆ˜ (Main effect coefficient)
        - Î»_mod_i: ì¡°ì ˆíš¨ê³¼ ê³„ìˆ˜ (Moderation effect coefficients)
        - LV_main: ì£¼ ì ì¬ë³€ìˆ˜ (Main latent variable, e.g., purchase_intention)
        - LV_mod_i: ì¡°ì ˆ ì ì¬ë³€ìˆ˜ (Moderator latent variables, e.g., perceived_price, nutrition_knowledge)
        - Î¦: í‘œì¤€ì •ê·œ ëˆ„ì ë¶„í¬í•¨ìˆ˜

    King (2022) Apollo R ì½”ë“œ ê¸°ë°˜:
        op_settings = list(
            outcomeOrdered = Q6ResearchResponse,
            V = intercept + b_bid*Q6Bid + lambda*LV,
            tau = list(-100, 0),
            componentName = "choice",
            coding = c(-1, 0, 1)
        )
        P[['choice']] = apollo_op(op_settings, functionality)

    Usage:
        >>> config = ChoiceConfig(
        ...     choice_attributes=['price', 'quality'],
        ...     choice_type='binary',
        ...     price_variable='price',
        ...     moderation_enabled=True,
        ...     moderator_lvs=['perceived_price', 'nutrition_knowledge'],
        ...     main_lv='purchase_intention'
        ... )
        >>> model = BinaryProbitChoice(config)
        >>>
        >>> # Simultaneous ì¶”ì •ìš©
        >>> ll = model.log_likelihood(data, lv_dict, params)
        >>>
        >>> # ì˜ˆì¸¡ìš©
        >>> probs = model.predict_probabilities(data, lv_dict, params)
    """

    def __init__(self, config: ChoiceConfig):
        """
        ì´ˆê¸°í™”

        Args:
            config: ì„ íƒëª¨ë¸ ì„¤ì •
        """
        # ë² ì´ìŠ¤ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(config)
    
    def log_likelihood(self, data: pd.DataFrame, lv,
                      params: Dict) -> float:
        """
        Binary Probit ë¡œê·¸ìš°ë„

        âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›

        ê¸°ë³¸ ëª¨ë¸:
            V = intercept + Î²*X + Î»*LV
            P(Yes) = Î¦(V)

        ì¡°ì ˆíš¨ê³¼ ëª¨ë¸ (ë””í´íŠ¸):
            V = intercept + Î²*X + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i)
            P(Yes) = Î¦(V)

        Args:
            data: ì„ íƒ ë°ì´í„° (n_obs, n_vars)
                  'choice' ì—´ í•„ìˆ˜ (0 or 1)
            lv: ì ì¬ë³€ìˆ˜ ê°’
                - ê¸°ë³¸ ëª¨ë¸: (n_obs,) ë˜ëŠ” ìŠ¤ì¹¼ë¼
                - ì¡°ì ˆíš¨ê³¼ ëª¨ë¸: Dict[str, np.ndarray] ë˜ëŠ” Dict[str, float]
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            ë¡œê·¸ìš°ë„ ê°’ (ìŠ¤ì¹¼ë¼)
        """
        # ì„ íƒ ê²°ê³¼ (0 or 1)
        if 'choice' in data.columns:
            choice = data['choice'].values
        elif 'Choice' in data.columns:
            choice = data['Choice'].values
        else:
            raise ValueError("ë°ì´í„°ì— 'choice' ë˜ëŠ” 'Choice' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

        # âœ… ë² ì´ìŠ¤ í´ë˜ìŠ¤ì˜ íš¨ìš© ê³„ì‚° ì‚¬ìš©
        V = self._compute_utilities(data, lv, params)

        # í™•ë¥  ê³„ì‚°: P(Yes) = Î¦(V)
        prob_yes = norm.cdf(V)

        # ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•´ í´ë¦¬í•‘
        prob_yes = np.clip(prob_yes, 1e-10, 1 - 1e-10)

        # ë¡œê·¸ìš°ë„: log L = Î£ [choice * log(Î¦(V)) + (1-choice) * log(1-Î¦(V))]
        ll = np.sum(
            choice * np.log(prob_yes) +
            (1 - choice) * np.log(1 - prob_yes)
        )

        return ll
    
    def predict_probabilities(self, data: pd.DataFrame, lv,
                             params: Dict) -> np.ndarray:
        """
        ì„ íƒ í™•ë¥  ì˜ˆì¸¡

        âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›

        ê¸°ë³¸ ëª¨ë¸:
            P(Yes) = Î¦(intercept + Î²*X + Î»*LV)

        ì¡°ì ˆíš¨ê³¼ ëª¨ë¸:
            P(Yes) = Î¦(intercept + Î²*X + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i))

        Args:
            data: ì„ íƒ ë°ì´í„°
            lv: ì ì¬ë³€ìˆ˜ ê°’ (ìŠ¤ì¹¼ë¼/ë°°ì—´ ë˜ëŠ” ë”•ì…”ë„ˆë¦¬)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            ì„ íƒ í™•ë¥  (n_obs,)

        Example:
            >>> probs = model.predict_probabilities(data, lv_dict, params)
        """
        intercept = params['intercept']
        beta = params['beta']

        # ì„ íƒ ì†ì„± ì¶”ì¶œ
        X = data[self.choice_attributes].values

        # íš¨ìš© ê³„ì‚°
        if self.moderation_enabled and isinstance(lv, dict):
            # âœ… ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
            lambda_main = params.get('lambda_main', params.get('lambda', 1.0))

            # ì£¼ LV ì¶”ì¶œ
            lv_main = lv[self.main_lv]
            if np.isscalar(lv_main):
                lv_main_array = np.full(len(data), lv_main)
            else:
                lv_main_array = lv_main

            # ì¡°ì ˆ LV ì¶”ì¶œ
            moderator_arrays = {}
            for mod_lv in self.moderator_lvs:
                lv_mod = lv[mod_lv]
                if np.isscalar(lv_mod):
                    moderator_arrays[mod_lv] = np.full(len(data), lv_mod)
                else:
                    moderator_arrays[mod_lv] = lv_mod

            # ê¸°ë³¸ íš¨ìš©
            V = intercept + X @ beta + lambda_main * lv_main_array

            # ì¡°ì ˆíš¨ê³¼ ì¶”ê°€
            for mod_lv in self.moderator_lvs:
                param_name = f'lambda_mod_{mod_lv}'
                if param_name in params:
                    lambda_mod = params[param_name]
                    interaction = lv_main_array * moderator_arrays[mod_lv]
                    V += lambda_mod * interaction

        else:
            # ê¸°ë³¸ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
            lambda_lv = params.get('lambda', params.get('lambda_main', 1.0))

            # ì ì¬ë³€ìˆ˜ ì²˜ë¦¬
            if isinstance(lv, dict):
                lv_value = lv[self.main_lv]
            else:
                lv_value = lv

            if np.isscalar(lv_value):
                lv_array = np.full(len(data), lv_value)
            else:
                lv_array = lv_value

            # íš¨ìš© ê³„ì‚°
            V = intercept + X @ beta + lambda_lv * lv_array

        # í™•ë¥  ê³„ì‚°
        prob_yes = norm.cdf(V)

        return prob_yes
    
    def predict(self, data: pd.DataFrame, lv: np.ndarray,
               params: Dict, threshold: float = 0.5) -> np.ndarray:
        """
        ì„ íƒ ì˜ˆì¸¡
        
        Args:
            data: ì„ íƒ ë°ì´í„°
            lv: ì ì¬ë³€ìˆ˜ ê°’
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            threshold: ì„ íƒ ì„ê³„ê°’ (ê¸°ë³¸: 0.5)
        
        Returns:
            ì˜ˆì¸¡ëœ ì„ íƒ (n_obs,) - 0 or 1
        
        Example:
            >>> predictions = model.predict(data, lv, params)
        """
        probs = self.predict_probabilities(data, lv, params)
        predictions = (probs >= threshold).astype(int)
        
        return predictions
    
    def get_initial_params(self, data: pd.DataFrame) -> Dict:
        """
        ì´ˆê¸° íŒŒë¼ë¯¸í„° ìƒì„±

        âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ì§€ì›
        âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›
        âœ… ê°€ê²© ìŠ¤ì¼€ì¼ ìë™ ì¡°ì •

        Args:
            data: ì„ íƒ ë°ì´í„°

        Returns:
            ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸:
                {
                    'intercept': float,
                    'beta': np.ndarray,
                    'lambda_health_concern': float,
                    'lambda_perceived_benefit': float,
                    'lambda_perceived_price': float,
                    'lambda_nutrition_knowledge': float,
                    'lambda_purchase_intention': float
                }

            ì¡°ì ˆíš¨ê³¼ ëª¨ë¸:
                {
                    'intercept': float,
                    'beta': np.ndarray,
                    'lambda_main': float,
                    'lambda_mod_perceived_price': float,
                    'lambda_mod_nutrition_knowledge': float
                }

            ê¸°ë³¸ ëª¨ë¸:
                {'intercept': float, 'beta': np.ndarray, 'lambda': float}

        Example:
            >>> params = model.get_initial_params(data)
        """
        n_attributes = len(self.choice_attributes)

        # ê¸°ë³¸ ì´ˆê¸°ê°’
        params = {
            'intercept': 0.0,
            'beta': np.zeros(n_attributes)
        }

        # ê°€ê²© ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ìŒìˆ˜ë¡œ ì´ˆê¸°í™” (ìŠ¤ì¼€ì¼ ìë™ ì¡°ì •)
        if self.price_variable in self.choice_attributes:
            price_idx = self.choice_attributes.index(self.price_variable)

            # ê°€ê²© ë°ì´í„° í™•ì¸
            if self.price_variable in data.columns:
                price_data = data[self.price_variable].dropna()
                if len(price_data) > 0:
                    price_mean = price_data.mean()
                    price_std = price_data.std()

                    # ê°€ê²© ìŠ¤ì¼€ì¼ì— ë”°ë¼ ì´ˆê¸°ê°’ ì¡°ì •
                    # ëª©í‘œ: íš¨ìš©ì´ -5 ~ 5 ë²”ìœ„ê°€ ë˜ë„ë¡
                    if price_mean > 100:  # ì›ë³¸ ê°€ê²© ìŠ¤ì¼€ì¼ (ì˜ˆ: 2000~3000)
                        params['beta'][price_idx] = -0.001
                        self.logger.info(f"ê°€ê²© ìŠ¤ì¼€ì¼ ê°ì§€: í‰ê· ={price_mean:.1f}, ì´ˆê¸° beta_price=-0.001")
                    elif price_mean > 1:  # 1000ìœ¼ë¡œ ë‚˜ëˆˆ ìŠ¤ì¼€ì¼ (ì˜ˆ: 2.0~3.0)
                        params['beta'][price_idx] = -1.0
                        self.logger.info(f"ê°€ê²© ìŠ¤ì¼€ì¼ ê°ì§€: í‰ê· ={price_mean:.1f}, ì´ˆê¸° beta_price=-1.0")
                    else:  # í‘œì¤€í™”ëœ ìŠ¤ì¼€ì¼ (ì˜ˆ: -1~1)
                        params['beta'][price_idx] = -0.5
                        self.logger.info(f"ê°€ê²© ìŠ¤ì¼€ì¼ ê°ì§€: í‰ê· ={price_mean:.1f}, ì´ˆê¸° beta_price=-0.5")
                else:
                    params['beta'][price_idx] = -0.001
                    self.logger.warning(f"ê°€ê²© ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ê°’ -0.001 ì‚¬ìš©")
            else:
                params['beta'][price_idx] = -0.001
                self.logger.warning(f"ê°€ê²© ë³€ìˆ˜ '{self.price_variable}' ì—†ìŒ, ê¸°ë³¸ê°’ -0.001 ì‚¬ìš©")

        # âœ… ìœ ì—°í•œ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜: ì ì¬ë³€ìˆ˜ ê³„ìˆ˜ ì´ˆê¸°í™”
        if self.main_lvs:
            # ì£¼íš¨ê³¼ ëª¨ë¸: lambda_{lv_name}
            for lv_name in self.main_lvs:
                params[f'lambda_{lv_name}'] = 1.0
        else:
            # ê¸°ë³¸ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
            params['lambda'] = 1.0

        # âœ… LV-Attribute ìƒí˜¸ì‘ìš© ì´ˆê¸°ê°’
        if self.lv_attribute_interactions:
            for interaction in self.lv_attribute_interactions:
                lv_name = interaction['lv']
                attr_name = interaction['attribute']
                params[f'gamma_{lv_name}_{attr_name}'] = 0.5

        self.logger.info(f"ì´ˆê¸° íŒŒë¼ë¯¸í„°: {params}")

        return params
    
    def calculate_wtp(self, params: Dict, attribute: str) -> float:
        """
        WTP (Willingness-to-Pay) ê³„ì‚°
        
        WTP = -Î²_attribute / Î²_price
        
        Args:
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
            attribute: WTPë¥¼ ê³„ì‚°í•  ì†ì„±
        
        Returns:
            WTP ê°’
        
        Example:
            >>> wtp = model.calculate_wtp(params, 'quality')
        """
        beta = params['beta']
        
        # ê°€ê²© ê³„ìˆ˜
        price_idx = self.choice_attributes.index(self.price_variable)
        beta_price = beta[price_idx]
        
        # ì†ì„± ê³„ìˆ˜
        attr_idx = self.choice_attributes.index(attribute)
        beta_attr = beta[attr_idx]
        
        # WTP = -Î²_attr / Î²_price
        wtp = -beta_attr / beta_price
        
        return wtp


def estimate_choice_model(data: pd.DataFrame, latent_var: np.ndarray,
                         choice_attributes: List[str],
                         price_variable: str = 'price',
                         **kwargs) -> Dict:
    """
    ì„ íƒëª¨ë¸ ì¶”ì • í—¬í¼ í•¨ìˆ˜
    
    Args:
        data: ì„ íƒ ë°ì´í„°
        latent_var: ì ì¬ë³€ìˆ˜ ê°’
        choice_attributes: ì„ íƒ ì†ì„± ë¦¬ìŠ¤íŠ¸
        price_variable: ê°€ê²© ë³€ìˆ˜ëª…
        **kwargs: ì¶”ê°€ ì„¤ì •
    
    Returns:
        ì¶”ì • ê²°ê³¼
    
    Example:
        >>> results = estimate_choice_model(
        ...     data,
        ...     latent_var,
        ...     choice_attributes=['price', 'quality'],
        ...     price_variable='price'
        ... )
    """
    config = ChoiceConfig(
        choice_attributes=choice_attributes,
        choice_type='binary',
        price_variable=price_variable,
        **kwargs
    )

    model = BinaryProbitChoice(config)

    # ê°„ë‹¨í•œ ì¶”ì • (ë¡œê·¸ìš°ë„ ìµœëŒ€í™”)
    initial_params = model.get_initial_params(data)

    def negative_log_likelihood(params_array):
        params = {
            'intercept': params_array[0],
            'beta': params_array[1:1+len(choice_attributes)],
            'lambda': params_array[-1]
        }
        return -model.log_likelihood(data, latent_var, params)

    # ì´ˆê¸°ê°’ ë°°ì—´
    x0 = np.concatenate([
        [initial_params['intercept']],
        initial_params['beta'],
        [initial_params['lambda']]
    ])

    # ìµœì í™”
    result = minimize(negative_log_likelihood, x0, method='BFGS')

    # ê²°ê³¼ ì •ë¦¬
    estimated_params = {
        'intercept': result.x[0],
        'beta': result.x[1:1+len(choice_attributes)],
        'lambda': result.x[-1],
        'log_likelihood': -result.fun,
        'success': result.success
    }

    return estimated_params


class MultinomialLogitChoice(BaseICLVChoice):
    """
    Multinomial Logit ì„ íƒëª¨ë¸ (ICLVìš©)

    âœ… BinaryProbitChoiceì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
    âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›
    âœ… GPU ë°°ì¹˜ ì²˜ë¦¬ í˜¸í™˜

    ëª¨ë¸:
        V_j = intercept + Î²*X_j + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i)
        P(j) = exp(V_j) / Î£_k exp(V_k)

    ì—¬ê¸°ì„œ:
        - j: ëŒ€ì•ˆ ì¸ë±ìŠ¤ (ì œí’ˆA, ì œí’ˆB, êµ¬ë§¤ì•ˆí•¨)
        - V_j: ëŒ€ì•ˆ jì˜ íš¨ìš©
        - P(j): ëŒ€ì•ˆ jì˜ ì„ íƒ í™•ë¥ 

    ë°ì´í„° êµ¬ì¡°:
        - ê° ì„ íƒ ìƒí™©ì€ 3ê°œ í–‰ (ì œí’ˆA, ì œí’ˆB, êµ¬ë§¤ì•ˆí•¨)
        - choice ì»¬ëŸ¼: ì„ íƒëœ ëŒ€ì•ˆì€ 1, ë‚˜ë¨¸ì§€ëŠ” 0
        - opt-out ëŒ€ì•ˆ: ì†ì„±ì´ NaN â†’ íš¨ìš© = 0 (ê¸°ì¤€ ëŒ€ì•ˆ)

    Usage:
        >>> config = ChoiceConfig(
        ...     choice_attributes=['sugar_free', 'health_label', 'price'],
        ...     choice_type='multinomial',
        ...     moderation_enabled=True,
        ...     moderator_lvs=['perceived_price', 'nutrition_knowledge'],
        ...     main_lv='purchase_intention'
        ... )
        >>> model = MultinomialLogitChoice(config)
        >>> ll = model.log_likelihood(data, lv_dict, params)
    """

    def __init__(self, config: ChoiceConfig):
        """
        ì´ˆê¸°í™”

        Args:
            config: ì„ íƒëª¨ë¸ ì„¤ì •
        """
        # ë² ì´ìŠ¤ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        super().__init__(config)

        # MNL íŠ¹í™” ì„¤ì •
        self.n_alternatives = 3  # ì œí’ˆA, ì œí’ˆB, êµ¬ë§¤ì•ˆí•¨

        self.logger.info(f"  ëŒ€ì•ˆ ìˆ˜: {self.n_alternatives}")

    def log_likelihood(self, data: pd.DataFrame, lv, params: Dict) -> float:
        """
        Multinomial Logit ë¡œê·¸ìš°ë„

        âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›

        ëª¨ë¸:
            V_j = intercept + Î²*X_j + Î»_main*LV_main + Î£(Î»_mod_i * LV_main * LV_mod_i)
            P(j) = exp(V_j) / Î£_k exp(V_k)

        Args:
            data: ì„ íƒ ë°ì´í„°
                  ê° ì„ íƒ ìƒí™©ì€ n_alternativesê°œ í–‰
                  'choice' ì—´: ì„ íƒëœ ëŒ€ì•ˆì€ 1, ë‚˜ë¨¸ì§€ëŠ” 0
            lv: ì ì¬ë³€ìˆ˜ ê°’
                - Dict[str, np.ndarray] (ì¡°ì ˆíš¨ê³¼ ëª¨ë¸)
                - np.ndarray ë˜ëŠ” float (ê¸°ë³¸ ëª¨ë¸)
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            ë¡œê·¸ìš°ë„ ê°’ (ìŠ¤ì¹¼ë¼)
        """
        # ì„ íƒ ê²°ê³¼ (0 or 1)
        if 'choice' in data.columns:
            choice = data['choice'].values
        elif 'Choice' in data.columns:
            choice = data['Choice'].values
        else:
            raise ValueError("ë°ì´í„°ì— 'choice' ë˜ëŠ” 'Choice' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

        # âœ… ë² ì´ìŠ¤ í´ë˜ìŠ¤ì˜ íš¨ìš© ê³„ì‚° ì‚¬ìš©
        V = self._compute_utilities(data, lv, params)

        # ì„ íƒ ìƒí™©ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ Softmax ê³„ì‚°
        n_rows = len(data)
        n_choice_situations = n_rows // self.n_alternatives

        total_ll = 0.0

        for i in range(n_choice_situations):
            start_idx = i * self.n_alternatives
            end_idx = start_idx + self.n_alternatives

            # ì´ ì„ íƒ ìƒí™©ì˜ íš¨ìš©ë“¤
            V_situation = V[start_idx:end_idx]  # (n_alternatives,)

            # Softmax í™•ë¥  ê³„ì‚° (ìˆ˜ì¹˜ ì•ˆì •ì„±)
            V_max = np.max(V_situation)
            exp_V = np.exp(V_situation - V_max)
            prob = exp_V / np.sum(exp_V)

            # ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•´ í´ë¦¬í•‘
            prob = np.clip(prob, 1e-10, 1 - 1e-10)

            # ì„ íƒëœ ëŒ€ì•ˆ ì°¾ê¸°
            choices = choice[start_idx:end_idx]
            chosen_idx = np.argmax(choices)

            # ë¡œê·¸ìš°ë„ ëˆ„ì 
            total_ll += np.log(prob[chosen_idx])

        return total_ll

    def predict_probabilities(self, data: pd.DataFrame, lv, params: Dict) -> np.ndarray:
        """
        ì„ íƒ í™•ë¥  ì˜ˆì¸¡

        Args:
            data: ì„ íƒ ë°ì´í„°
            lv: ì ì¬ë³€ìˆ˜ ê°’
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            ì„ íƒ í™•ë¥  ë°°ì—´ (n_obs,)
        """
        # íš¨ìš© ê³„ì‚°
        V = self._compute_utilities(data, lv, params)

        # ì„ íƒ ìƒí™©ë³„ë¡œ Softmax ê³„ì‚°
        n_rows = len(data)
        n_choice_situations = n_rows // self.n_alternatives

        probabilities = np.zeros(n_rows)

        for i in range(n_choice_situations):
            start_idx = i * self.n_alternatives
            end_idx = start_idx + self.n_alternatives

            # ì´ ì„ íƒ ìƒí™©ì˜ íš¨ìš©ë“¤
            V_situation = V[start_idx:end_idx]

            # Softmax í™•ë¥ 
            V_max = np.max(V_situation)
            exp_V = np.exp(V_situation - V_max)
            prob = exp_V / np.sum(exp_V)

            # í™•ë¥  ì €ì¥
            probabilities[start_idx:end_idx] = prob

        return probabilities

    def fit(self, data: pd.DataFrame, factor_scores: Dict[str, np.ndarray]) -> Dict[str, Any]:
        """
        ì„ íƒëª¨ë¸ ì¶”ì • (ìˆœì°¨ì¶”ì • Step 2)

        âœ… ìš”ì¸ì ìˆ˜ë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ ì‚¬ìš©
        âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›

        íš¨ìš©í•¨ìˆ˜:
            V = intercept + Î²*X + Î»_main*PI + Î»_mod_PP*(PIÃ—PP) + Î»_mod_NK*(PIÃ—NK)

        ì—¬ê¸°ì„œ:
            - X: ì„ íƒ ì†ì„± (sugar_free, health_label, price)
            - PI: êµ¬ë§¤ì˜ë„ ìš”ì¸ì ìˆ˜ (ì£¼íš¨ê³¼)
            - PP: ì§€ê°ëœ ê°€ê²© ìš”ì¸ì ìˆ˜ (ì¡°ì ˆíš¨ê³¼)
            - NK: ì˜ì–‘ì§€ì‹ ìš”ì¸ì ìˆ˜ (ì¡°ì ˆíš¨ê³¼)

        Args:
            data: ì„ íƒ ë°ì´í„°
                  ê° ì„ íƒ ìƒí™©ì€ 3ê°œ í–‰ (ì œí’ˆA, ì œí’ˆB, êµ¬ë§¤ì•ˆí•¨)
                  'choice' ì—´: ì„ íƒëœ ëŒ€ì•ˆì€ 1, ë‚˜ë¨¸ì§€ëŠ” 0
            factor_scores: SEMì—ì„œ ì¶”ì¶œí•œ ìš”ì¸ì ìˆ˜
                {
                    'purchase_intention': np.ndarray (n_individuals,),
                    'perceived_price': np.ndarray (n_individuals,),
                    'nutrition_knowledge': np.ndarray (n_individuals,)
                }

        Returns:
            {
                'params': ì¶”ì •ëœ íŒŒë¼ë¯¸í„°,
                'log_likelihood': ë¡œê·¸ìš°ë„,
                'aic': AIC,
                'bic': BIC,
                'success': ì„±ê³µ ì—¬ë¶€,
                'message': ìµœì í™” ë©”ì‹œì§€,
                'n_iterations': ë°˜ë³µ íšŸìˆ˜
            }

        Example:
            >>> config = ChoiceConfig(
            ...     choice_attributes=['sugar_free', 'health_label', 'price'],
            ...     moderation_enabled=True,
            ...     moderator_lvs=['perceived_price', 'nutrition_knowledge'],
            ...     main_lv='purchase_intention'
            ... )
            >>> model = MultinomialLogitChoice(config)
            >>> results = model.fit(choice_data, factor_scores)
        """
        self.logger.info("=" * 70)
        self.logger.info("ì„ íƒëª¨ë¸ ì¶”ì • ì‹œì‘ (MultinomialLogitChoice)")
        self.logger.info("=" * 70)

        # 1. ë°ì´í„° ê²€ì¦
        if 'choice' not in data.columns and 'Choice' not in data.columns:
            raise ValueError("ë°ì´í„°ì— 'choice' ë˜ëŠ” 'Choice' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")

        # 2. ìš”ì¸ì ìˆ˜ë¥¼ ê°œì¸ë³„ë¡œ ë³µì œ (ê° ì„ íƒ ìƒí™©ë§ˆë‹¤ n_alternativesê°œ í–‰)
        # ì„ íƒ ë°ì´í„°ëŠ” (n_individuals * n_choice_sets * n_alternatives) í–‰
        # ìš”ì¸ì ìˆ˜ëŠ” (n_individuals,) ë°°ì—´
        # ê° ê°œì¸ì˜ ëª¨ë“  ì„ íƒ ìƒí™©ì— ë™ì¼í•œ ìš”ì¸ì ìˆ˜ ì‚¬ìš©

        n_rows = len(data)

        # âœ… ìš”ì¸ì ìˆ˜ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ì ì¬ë³€ìˆ˜ íš¨ê³¼ ì—†ìŒ)
        if not factor_scores:
            self.logger.info("ìš”ì¸ì ìˆ˜ê°€ ë¹„ì–´ìˆìŒ (ì ì¬ë³€ìˆ˜ íš¨ê³¼ ì—†ì´ ì„ íƒëª¨ë¸ë§Œ ì¶”ì •)")
            lv_expanded = {}
        else:
            n_individuals = len(next(iter(factor_scores.values())))

            self.logger.info(f"ìš”ì¸ì ìˆ˜ í™•ì¥:")
            self.logger.info(f"  ì „ì²´ ë°ì´í„° í–‰ ìˆ˜: {n_rows}")
            self.logger.info(f"  ê°œì¸ ìˆ˜: {n_individuals}")

            # âœ… í™•ì¥ ì „ ìš”ì¸ì ìˆ˜ ë¡œê¹…
            self._log_factor_scores(factor_scores, stage="ì„ íƒëª¨ë¸_í™•ì¥_ì „")

            # respondent_id ê¸°ì¤€ìœ¼ë¡œ ìš”ì¸ì ìˆ˜ ë§¤í•‘ (ë¶€íŠ¸ìŠ¤íŠ¸ë© ì•ˆì „)
            if 'respondent_id' in data.columns:
                # ê°œì¸ ID ì¶”ì¶œ
                unique_ids = data['respondent_id'].unique()

                # ìš”ì¸ì ìˆ˜ë¥¼ ID ìˆœì„œëŒ€ë¡œ ë§¤í•‘
                lv_expanded = {}
                for lv_name, scores in factor_scores.items():
                    # ê° í–‰ì˜ respondent_idì— í•´ë‹¹í•˜ëŠ” ìš”ì¸ì ìˆ˜ í• ë‹¹
                    id_to_score = {unique_ids[i]: scores[i] for i in range(len(unique_ids))}
                    expanded = np.array([id_to_score[rid] for rid in data['respondent_id']])
                    lv_expanded[lv_name] = expanded
                    self.logger.info(f"  {lv_name}: {scores.shape} â†’ {expanded.shape}")
            else:
                # respondent_idê°€ ì—†ëŠ” ê²½ìš° (í•˜ìœ„ í˜¸í™˜)
                rows_per_individual = n_rows // n_individuals
                self.logger.info(f"  ê°œì¸ë‹¹ í–‰ ìˆ˜: {rows_per_individual}")

                lv_expanded = {}
                for lv_name, scores in factor_scores.items():
                    expanded = np.repeat(scores, rows_per_individual)
                    lv_expanded[lv_name] = expanded
                    self.logger.info(f"  {lv_name}: {scores.shape} â†’ {expanded.shape}")

            # âœ… í™•ì¥ í›„ ìš”ì¸ì ìˆ˜ ë¡œê¹…
            self._log_factor_scores(lv_expanded, stage="ì„ íƒëª¨ë¸_í™•ì¥_í›„")

        # 3. ì´ˆê¸° íŒŒë¼ë¯¸í„° ìƒì„±
        initial_params = self.get_initial_params(data)
        self.logger.info(f"ì´ˆê¸° íŒŒë¼ë¯¸í„°: {initial_params}")

        # 4. íŒŒë¼ë¯¸í„°ë¥¼ ë°°ì—´ë¡œ ë³€í™˜ (ìµœì í™”ìš©)
        param_names, x0 = self._params_to_array(initial_params)
        self.logger.info(f"ìµœì í™” íŒŒë¼ë¯¸í„° ê°œìˆ˜: {len(x0)}")

        # 5. ëª©ì í•¨ìˆ˜ ì •ì˜ (ìŒì˜ ë¡œê·¸ìš°ë„) + ë°˜ë³µ ë¡œê¹…
        iteration_count = [0]  # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ í´ë¡œì €ì—ì„œ ìˆ˜ì • ê°€ëŠ¥í•˜ê²Œ

        def negative_log_likelihood(params_array):
            params = self._array_to_params(param_names, params_array)
            ll = self.log_likelihood(data, lv_expanded, params)
            nll = -ll

            # ë°˜ë³µ ë¡œê¹… (10íšŒë§ˆë‹¤)
            iteration_count[0] += 1
            if iteration_count[0] % 10 == 0 or iteration_count[0] == 1:
                print(f"  ë°˜ë³µ {iteration_count[0]:3d}: NLL = {nll:12.4f}, LL = {ll:12.4f}")
                self.logger.info(f"  ë°˜ë³µ {iteration_count[0]:3d}: NLL = {nll:12.4f}, LL = {ll:12.4f}")

                # ğŸ” gamma íŒŒë¼ë¯¸í„° ì¶”ì  (ìƒí˜¸ì‘ìš© í•­ì´ ìˆëŠ” ê²½ìš°)
                if hasattr(self, 'lv_attribute_interactions') and self.lv_attribute_interactions:
                    gamma_params = {k: v for k, v in params.items() if k.startswith('gamma_')}
                    if gamma_params:
                        gamma_str = ', '.join([f"{k}={v:.4f}" for k, v in gamma_params.items()])
                        self.logger.info(f"    ğŸ” Gamma: {gamma_str}")

            return nll

        # 6. ìµœì í™” ì‹¤í–‰
        print(f"\n[ì„ íƒëª¨ë¸ ìµœì í™” ì‹œì‘] method=L-BFGS-B")
        self.logger.info("ìµœì í™” ì‹œì‘ (method=L-BFGS-B)...")

        initial_nll = negative_log_likelihood(x0)
        print(f"  ì´ˆê¸° NLL: {initial_nll:.4f}")
        self.logger.info(f"  ì´ˆê¸° NLL: {initial_nll:.4f}")

        # ë°˜ë³µ ì¹´ìš´í„° ì´ˆê¸°í™”
        iteration_count[0] = 0

        result = minimize(
            negative_log_likelihood,
            x0,
            method='L-BFGS-B',
            options={'maxiter': 1000, 'disp': False}  # disp=Falseë¡œ ë³€ê²½ (ìš°ë¦¬ê°€ ì§ì ‘ ë¡œê¹…)
        )

        # ìµœì í™” ì™„ë£Œ ë¡œê¹…
        print(f"\n[ì„ íƒëª¨ë¸ ìµœì í™” ì™„ë£Œ]")
        print(f"  ì´ ë°˜ë³µ íšŸìˆ˜: {result.nit}")
        print(f"  í•¨ìˆ˜ í‰ê°€ íšŸìˆ˜: {result.nfev}")
        print(f"  ìµœì¢… LL: {-result.fun:.4f}")
        print(f"  ìˆ˜ë ´ ì—¬ë¶€: {result.success}")
        print(f"  ë©”ì‹œì§€: {result.message}")

        self.logger.info(f"ìµœì í™” ì™„ë£Œ:")
        self.logger.info(f"  ì´ ë°˜ë³µ íšŸìˆ˜: {result.nit}")
        self.logger.info(f"  í•¨ìˆ˜ í‰ê°€ íšŸìˆ˜: {result.nfev}")
        self.logger.info(f"  ìµœì¢… LL: {-result.fun:.4f}")
        self.logger.info(f"  ìˆ˜ë ´ ì—¬ë¶€: {result.success}")
        self.logger.info(f"  ë©”ì‹œì§€: {result.message}")

        # 7. ê²°ê³¼ ì •ë¦¬
        estimated_params = self._array_to_params(param_names, result.x)
        log_likelihood = -result.fun
        n_params = len(result.x)
        n_choice_situations = n_rows // self.n_alternatives
        n_obs = n_choice_situations

        aic = 2 * n_params - 2 * log_likelihood
        bic = n_params * np.log(n_obs) - 2 * log_likelihood

        results = {
            'params': estimated_params,
            'log_likelihood': log_likelihood,
            'aic': aic,
            'bic': bic,
            'n_params': n_params,
            'n_obs': n_obs,
            'success': result.success,
            'message': result.message,
            'n_iterations': result.nit
        }

        # 8. í‘œì¤€ì˜¤ì°¨ ë° p-value ê³„ì‚° (ë™ì‹œì¶”ì • ëª¨ë“ˆê³¼ ë™ì¼í•œ ë°©ì‹)
        try:
            if hasattr(result, 'hess_inv'):
                hess_inv = result.hess_inv
                if hasattr(hess_inv, 'todense'):
                    hess_inv = hess_inv.todense()

                # Hessian ì—­í–‰ë ¬ ì €ì¥
                results['hessian_inv'] = np.array(hess_inv)

                # ëŒ€ê° ì›ì†Œ ì¶”ì¶œ (ë¶„ì‚°)
                variances = np.diag(hess_inv)

                # ìŒìˆ˜ ë¶„ì‚° ì²˜ë¦¬ (ìˆ˜ì¹˜ ì˜¤ë¥˜)
                variances = np.maximum(variances, 1e-10)

                # í‘œì¤€ì˜¤ì°¨
                se = np.sqrt(variances)
                results['standard_errors'] = se

                # t-í†µê³„ëŸ‰
                results['t_statistics'] = result.x / se

                # p-ê°’ (ì–‘ì¸¡ ê²€ì •, ëŒ€í‘œë³¸ì´ë¯€ë¡œ ì •ê·œë¶„í¬ ì‚¬ìš©)
                from scipy.stats import norm
                results['p_values'] = 2 * (1 - norm.cdf(np.abs(results['t_statistics'])))

                # íŒŒë¼ë¯¸í„°ë³„ë¡œ êµ¬ì¡°í™”
                results['parameter_statistics'] = self._structure_statistics(
                    param_names, result.x, se, results['t_statistics'], results['p_values']
                )

                self.logger.info("í‘œì¤€ì˜¤ì°¨ ë° p-value ê³„ì‚° ì™„ë£Œ")

            else:
                self.logger.warning("Hessian ì •ë³´ê°€ ì—†ì–´ í‘œì¤€ì˜¤ì°¨ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                results['hessian_inv'] = None
                results['standard_errors'] = None
                results['t_statistics'] = None
                results['p_values'] = None
                results['parameter_statistics'] = None

        except Exception as e:
            self.logger.warning(f"í‘œì¤€ì˜¤ì°¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            results['hessian_inv'] = None
            results['standard_errors'] = None
            results['t_statistics'] = None
            results['p_values'] = None
            results['parameter_statistics'] = None

        self.logger.info("=" * 70)
        self.logger.info("ì„ íƒëª¨ë¸ ì¶”ì • ì™„ë£Œ")
        self.logger.info(f"  ë¡œê·¸ìš°ë„: {log_likelihood:.2f}")
        self.logger.info(f"  AIC: {aic:.2f}")
        self.logger.info(f"  BIC: {bic:.2f}")
        self.logger.info(f"  ì„±ê³µ: {result.success}")
        self.logger.info("=" * 70)

        return results

    def get_initial_params(self, data: pd.DataFrame) -> Dict:
        """
        ì´ˆê¸° íŒŒë¼ë¯¸í„° ìƒì„±

        âœ… ëŒ€ì•ˆë³„ ASCì™€ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜ ì§€ì›
        âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ì§€ì›
        âœ… ì¡°ì ˆíš¨ê³¼ ì§€ì›

        Args:
            data: ì„ íƒ ë°ì´í„°

        Returns:
            ëŒ€ì•ˆë³„ ëª¨ë¸ (Multinomial Logit):
                {
                    'asc_A': float,
                    'asc_B': float,
                    'beta': np.ndarray,
                    'theta_A_purchase_intention': float,
                    'theta_A_nutrition_knowledge': float,
                    'theta_B_purchase_intention': float,
                    'theta_B_nutrition_knowledge': float
                }

            ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸:
                {
                    'intercept': float,
                    'beta': np.ndarray,
                    'lambda_health_concern': float,
                    'lambda_perceived_benefit': float,
                    'lambda_perceived_price': float,
                    'lambda_nutrition_knowledge': float,
                    'lambda_purchase_intention': float
                }

            ì¡°ì ˆíš¨ê³¼ ëª¨ë¸:
                {
                    'intercept': float,
                    'beta': np.ndarray,
                    'lambda_main': float,
                    'lambda_mod_perceived_price': float,
                    'lambda_mod_nutrition_knowledge': float
                }

            ê¸°ë³¸ ëª¨ë¸:
                {'intercept': float, 'beta': np.ndarray, 'lambda': float}

        Example:
            >>> params = model.get_initial_params(data)
        """
        n_attributes = len(self.choice_attributes)

        # ê¸°ë³¸ ì´ˆê¸°ê°’
        params = {
            'beta': np.zeros(n_attributes)
        }

        # ê°€ê²© ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ìŒìˆ˜ë¡œ ì´ˆê¸°í™” (ìŠ¤ì¼€ì¼ ìë™ ì¡°ì •)
        if self.price_variable in self.choice_attributes:
            price_idx = self.choice_attributes.index(self.price_variable)

            # ê°€ê²© ë°ì´í„° í™•ì¸
            if self.price_variable in data.columns:
                price_data = data[self.price_variable].dropna()
                if len(price_data) > 0:
                    price_mean = price_data.mean()

                    # ê°€ê²© ìŠ¤ì¼€ì¼ì— ë”°ë¼ ì´ˆê¸°ê°’ ì¡°ì •
                    if price_mean > 100:  # ì›ë³¸ ê°€ê²© ìŠ¤ì¼€ì¼ (ì˜ˆ: 2000~3000)
                        params['beta'][price_idx] = -0.001
                        self.logger.info(f"ê°€ê²© ìŠ¤ì¼€ì¼ ê°ì§€: í‰ê· ={price_mean:.1f}, ì´ˆê¸° beta_price=-0.001")
                    elif price_mean > 1:  # 1000ìœ¼ë¡œ ë‚˜ëˆˆ ìŠ¤ì¼€ì¼ (ì˜ˆ: 2.0~3.0)
                        params['beta'][price_idx] = -1.0
                        self.logger.info(f"ê°€ê²© ìŠ¤ì¼€ì¼ ê°ì§€: í‰ê· ={price_mean:.1f}, ì´ˆê¸° beta_price=-1.0")
                    else:  # í‘œì¤€í™”ëœ ìŠ¤ì¼€ì¼ (ì˜ˆ: -1~1)
                        params['beta'][price_idx] = -0.5
                        self.logger.info(f"ê°€ê²© ìŠ¤ì¼€ì¼ ê°ì§€: í‰ê· ={price_mean:.1f}, ì´ˆê¸° beta_price=-0.5")
                else:
                    params['beta'][price_idx] = -0.001
                    self.logger.warning(f"ê°€ê²© ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ê°’ -0.001 ì‚¬ìš©")
            else:
                params['beta'][price_idx] = -0.001
                self.logger.warning(f"ê°€ê²© ë³€ìˆ˜ '{self.price_variable}' ì—†ìŒ, ê¸°ë³¸ê°’ -0.001 ì‚¬ìš©")

        # âœ… ëŒ€ì•ˆë³„ ëª¨ë¸ (Multinomial Logit with alternative-specific constants)
        # n_alternativesê°€ 3ì´ë©´ ëŒ€ì•ˆë³„ ëª¨ë¸ ì‚¬ìš©
        if hasattr(self, 'n_alternatives') and self.n_alternatives == 3:
            # âœ… sugar_content ê¸°ì¤€ìœ¼ë¡œ ASC ì´ˆê¸°í™”
            if 'sugar_content' in data.columns:
                # ASC (opt-outì€ referenceì´ë¯€ë¡œ 0, ë‚˜ë¨¸ì§€ëŠ” ì¶”ì •)
                params['asc_sugar'] = 0.5  # ì¼ë°˜ë‹¹ (ì´ˆê¸°ê°’ 0.5)
                params['asc_sugar_free'] = 0.5  # ë¬´ì„¤íƒ• (ì´ˆê¸°ê°’ 0.5)

                # ëŒ€ì•ˆë³„ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
                # all_lvs_as_main ì†ì„±ì´ ìˆìœ¼ë©´ ì²´í¬, ì—†ìœ¼ë©´ main_lvsë§Œ ì²´í¬
                use_main_lvs = getattr(self, 'all_lvs_as_main', False) or (self.main_lvs is not None and len(self.main_lvs) > 0)
                if use_main_lvs and self.main_lvs is not None:
                    for lv_name in self.main_lvs:
                        params[f'theta_sugar_{lv_name}'] = 0.5
                        params[f'theta_sugar_free_{lv_name}'] = 0.5

                # âœ… LV-Attribute ìƒí˜¸ì‘ìš© ì´ˆê¸°ê°’ (ëŒ€ì•ˆë³„) - ì£¼íš¨ê³¼ ì—†ì´ë„ ê°€ëŠ¥
                if hasattr(self, 'lv_attribute_interactions') and self.lv_attribute_interactions:
                    self.logger.info(f"ğŸ” LV-Attribute ìƒí˜¸ì‘ìš© ì´ˆê¸°í™” ì‹œì‘: {len(self.lv_attribute_interactions)}ê°œ")
                    for interaction in self.lv_attribute_interactions:
                        lv_name = interaction['lv']
                        attr_name = interaction['attribute']
                        param_sugar = f'gamma_sugar_{lv_name}_{attr_name}'
                        param_sugar_free = f'gamma_sugar_free_{lv_name}_{attr_name}'
                        params[param_sugar] = 0.1  # 0ì´ ì•„ë‹Œ ì‘ì€ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
                        params[param_sugar_free] = 0.1
                        self.logger.info(f"  - {param_sugar} = 0.1")
                        self.logger.info(f"  - {param_sugar_free} = 0.1")
            else:
                # sugar_content ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ (alternative ê¸°ì¤€)
                params['asc_A'] = 0.5
                params['asc_B'] = 0.5

                # ëŒ€ì•ˆë³„ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
                if self.all_lvs_as_main and self.main_lvs is not None:
                    for lv_name in self.main_lvs:
                        params[f'theta_A_{lv_name}'] = 0.5
                        params[f'theta_B_{lv_name}'] = 0.5

        # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ëª¨ë¸ (Binary/ê¸°íƒ€)
        elif self.all_lvs_as_main and self.main_lvs is not None:
            params['intercept'] = 0.0
            for lv_name in self.main_lvs:
                params[f'lambda_{lv_name}'] = 1.0

        # âœ… ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
        elif self.moderation_enabled:
            params['intercept'] = 0.0
            params['lambda_main'] = 1.0

            # ì¡°ì ˆíš¨ê³¼ ì´ˆê¸°ê°’
            for mod_lv in self.moderator_lvs:
                param_name = f'lambda_mod_{mod_lv}'
                # ê°€ê²©ì€ ë¶€ì  ì¡°ì ˆ, ì§€ì‹ì€ ì •ì  ì¡°ì ˆ ê°€ì •
                if 'price' in mod_lv.lower():
                    params[param_name] = -0.3
                elif 'knowledge' in mod_lv.lower():
                    params[param_name] = 0.2
                else:
                    params[param_name] = 0.0

        # âœ… ê¸°ë³¸ ëª¨ë¸ (í•˜ìœ„ í˜¸í™˜)
        else:
            params['intercept'] = 0.0
            params['lambda'] = 1.0

        self.logger.info(f"ì´ˆê¸° íŒŒë¼ë¯¸í„°: {params}")

        return params

    def _params_to_array(self, params: Dict) -> Tuple[List[str], np.ndarray]:
        """
        íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ë¥¼ ë°°ì—´ë¡œ ë³€í™˜ (ìµœì í™”ìš©)

        âœ… ëŒ€ì•ˆë³„ ASCì™€ theta ì§€ì›
        âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ì§€ì›

        Args:
            params: íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            (param_names, param_array)
        """
        param_names = []
        param_values = []

        # âœ… ëŒ€ì•ˆë³„ ëª¨ë¸: ASC (sugar_content ê¸°ì¤€ ë˜ëŠ” alternative ê¸°ì¤€)
        if 'asc_sugar' in params or 'ASC_sugar' in params:
            # sugar_content ê¸°ì¤€
            param_names.append('asc_sugar')
            param_values.append(params.get('asc_sugar', params.get('ASC_sugar', 0.0)))
            param_names.append('asc_sugar_free')
            param_values.append(params.get('asc_sugar_free', params.get('ASC_sugar_free', 0.0)))
        elif 'asc_A' in params or 'ASC_A' in params:
            # alternative ê¸°ì¤€ (í•˜ìœ„ í˜¸í™˜)
            param_names.append('asc_A')
            param_values.append(params.get('asc_A', params.get('ASC_A', 0.0)))
            param_names.append('asc_B')
            param_values.append(params.get('asc_B', params.get('ASC_B', 0.0)))

        # intercept (ëŒ€ì•ˆë³„ ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°)
        elif 'intercept' in params:
            param_names.append('intercept')
            param_values.append(params['intercept'])

        # beta
        for i, attr in enumerate(self.choice_attributes):
            param_names.append(f'beta_{attr}')
            param_values.append(params['beta'][i])

        # âœ… ëŒ€ì•ˆë³„ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜: theta_sugar_*, theta_sugar_free_* ë˜ëŠ” theta_A_*, theta_B_*
        if 'asc_sugar' in params or 'ASC_sugar' in params:
            # sugar_content ê¸°ì¤€
            if self.all_lvs_as_main and self.main_lvs is not None:
                for lv_name in self.main_lvs:
                    param_name_sugar = f'theta_sugar_{lv_name}'
                    param_name_sugar_free = f'theta_sugar_free_{lv_name}'
                    if param_name_sugar in params:
                        param_names.append(param_name_sugar)
                        param_values.append(params[param_name_sugar])
                    if param_name_sugar_free in params:
                        param_names.append(param_name_sugar_free)
                        param_values.append(params[param_name_sugar_free])
        elif 'asc_A' in params or 'ASC_A' in params:
            # alternative ê¸°ì¤€ (í•˜ìœ„ í˜¸í™˜)
            if self.all_lvs_as_main and self.main_lvs is not None:
                for lv_name in self.main_lvs:
                    param_name_A = f'theta_A_{lv_name}'
                    param_name_B = f'theta_B_{lv_name}'
                    if param_name_A in params:
                        param_names.append(param_name_A)
                        param_values.append(params[param_name_A])
                    if param_name_B in params:
                        param_names.append(param_name_B)
                        param_values.append(params[param_name_B])

        # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ lambda íŒŒë¼ë¯¸í„° (ëŒ€ì•ˆë³„ ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°)
        elif self.all_lvs_as_main and self.main_lvs is not None:
            for lv_name in self.main_lvs:
                param_name = f'lambda_{lv_name}'
                if param_name in params:
                    param_names.append(param_name)
                    param_values.append(params[param_name])
        elif 'lambda_main' in params:
            # ì¡°ì ˆíš¨ê³¼ ëª¨ë¸
            param_names.append('lambda_main')
            param_values.append(params['lambda_main'])
        elif 'lambda' in params:
            # ê¸°ë³¸ ëª¨ë¸
            param_names.append('lambda')
            param_values.append(params['lambda'])

        # lambda_mod_*
        if self.moderation_enabled:
            for mod_lv in self.moderator_lvs:
                param_name = f'lambda_mod_{mod_lv}'
                if param_name in params:
                    param_names.append(param_name)
                    param_values.append(params[param_name])

        # âœ… gamma (LV-Attribute ìƒí˜¸ì‘ìš©, ëŒ€ì•ˆë³„)
        if hasattr(self, 'lv_attribute_interactions') and self.lv_attribute_interactions:
            for interaction in self.lv_attribute_interactions:
                lv_name = interaction['lv']
                attr_name = interaction['attribute']
                # sugarì™€ sugar_free ëŒ€ì•ˆë³„ë¡œ ì¶”ê°€
                param_name_sugar = f'gamma_sugar_{lv_name}_{attr_name}'
                param_name_sugar_free = f'gamma_sugar_free_{lv_name}_{attr_name}'
                if param_name_sugar in params:
                    param_names.append(param_name_sugar)
                    param_values.append(params[param_name_sugar])
                    # ğŸ” ë¡œê¹…
                    if not hasattr(self, '_gamma_to_array_logged'):
                        self.logger.info(f"ğŸ” [_params_to_array] {param_name_sugar} = {params[param_name_sugar]:.4f} ì¶”ê°€ë¨")
                if param_name_sugar_free in params:
                    param_names.append(param_name_sugar_free)
                    param_values.append(params[param_name_sugar_free])
                    # ğŸ” ë¡œê¹…
                    if not hasattr(self, '_gamma_to_array_logged'):
                        self.logger.info(f"ğŸ” [_params_to_array] {param_name_sugar_free} = {params[param_name_sugar_free]:.4f} ì¶”ê°€ë¨")

            # ë¡œê¹… í”Œë˜ê·¸
            if not hasattr(self, '_gamma_to_array_logged'):
                self._gamma_to_array_logged = True

        return param_names, np.array(param_values)

    def _array_to_params(self, param_names: List[str], param_array: np.ndarray) -> Dict:
        """
        ë°°ì—´ì„ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

        âœ… ëŒ€ì•ˆë³„ ASCì™€ theta ì§€ì›
        âœ… ëª¨ë“  LV ì£¼íš¨ê³¼ ì§€ì›

        Args:
            param_names: íŒŒë¼ë¯¸í„° ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            param_array: íŒŒë¼ë¯¸í„° ê°’ ë°°ì—´

        Returns:
            íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬
        """
        params = {}

        # beta ìˆ˜ì§‘ìš©
        beta_values = []

        for name, value in zip(param_names, param_array):
            if name == 'intercept':
                params['intercept'] = value
            elif name in ['asc_sugar', 'ASC_sugar', 'asc_sugar_free', 'ASC_sugar_free',
                         'asc_A', 'ASC_A', 'asc_B', 'ASC_B']:
                # âœ… ëŒ€ì•ˆë³„ ASC (sugar_content ê¸°ì¤€ ë˜ëŠ” alternative ê¸°ì¤€)
                params[name] = value
            elif name.startswith('beta_'):
                beta_values.append(value)
            elif name.startswith('theta_sugar_') or name.startswith('theta_sugar_free_') or \
                 name.startswith('theta_A_') or name.startswith('theta_B_'):
                # âœ… ëŒ€ì•ˆë³„ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
                params[name] = value
            elif name == 'lambda_main':
                params['lambda_main'] = value
            elif name == 'lambda':
                params['lambda'] = value
            elif name.startswith('lambda_mod_'):
                params[name] = value
            elif name.startswith('lambda_'):
                # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼: lambda_{lv_name}
                params[name] = value
            elif name.startswith('gamma_'):
                # âœ… LV-Attribute ìƒí˜¸ì‘ìš©: gamma_{lv_name}_{attr_name}
                params[name] = value
                # ğŸ” ë¡œê¹…
                if not hasattr(self, '_gamma_from_array_logged'):
                    self.logger.info(f"ğŸ” [_array_to_params] {name} = {value:.4f} ë³µì›ë¨")

        # ë¡œê¹… í”Œë˜ê·¸
        if not hasattr(self, '_gamma_from_array_logged'):
            self._gamma_from_array_logged = True

        # beta ë°°ì—´ë¡œ ë³€í™˜
        if beta_values:
            params['beta'] = np.array(beta_values)

        return params

    def _structure_statistics(self, param_names: List[str],
                             estimates: np.ndarray,
                             std_errors: np.ndarray,
                             t_stats: np.ndarray,
                             p_values: np.ndarray) -> Dict:
        """
        íŒŒë¼ë¯¸í„°ë³„ í†µê³„ëŸ‰ì„ êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

        âœ… ëŒ€ì•ˆë³„ ASCì™€ theta ì§€ì›

        Args:
            param_names: íŒŒë¼ë¯¸í„° ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            estimates: ì¶”ì •ê°’ ë°°ì—´
            std_errors: í‘œì¤€ì˜¤ì°¨ ë°°ì—´
            t_stats: t-í†µê³„ëŸ‰ ë°°ì—´
            p_values: p-value ë°°ì—´

        Returns:
            êµ¬ì¡°í™”ëœ í†µê³„ëŸ‰ ë”•ì…”ë„ˆë¦¬
            {
                'asc_A': {'estimate': ..., 'se': ..., 't': ..., 'p': ...},
                'asc_B': {'estimate': ..., 'se': ..., 't': ..., 'p': ...},
                'beta': {
                    'sugar_free': {'estimate': ..., 'se': ..., 't': ..., 'p': ...},
                    'health_label': {...},
                    'price': {...}
                },
                'theta_A_purchase_intention': {...},
                'theta_A_nutrition_knowledge': {...},
                'theta_B_purchase_intention': {...},
                'theta_B_nutrition_knowledge': {...}
            }
        """
        stats = {}

        for i, name in enumerate(param_names):
            stat_dict = {
                'estimate': estimates[i],
                'se': std_errors[i],
                't': t_stats[i],
                'p': p_values[i]
            }

            if name == 'intercept':
                stats['intercept'] = stat_dict
            elif name in ['asc_sugar', 'ASC_sugar', 'asc_sugar_free', 'ASC_sugar_free',
                         'asc_A', 'ASC_A', 'asc_B', 'ASC_B']:
                # âœ… ëŒ€ì•ˆë³„ ASC (sugar_content ê¸°ì¤€ ë˜ëŠ” alternative ê¸°ì¤€)
                stats[name] = stat_dict
            elif name.startswith('beta_'):
                # beta íŒŒë¼ë¯¸í„°ëŠ” ì†ì„±ë³„ë¡œ ê·¸ë£¹í™”
                if 'beta' not in stats:
                    stats['beta'] = {}
                attr_name = name.replace('beta_', '')
                stats['beta'][attr_name] = stat_dict
            elif name.startswith('theta_sugar_') or name.startswith('theta_sugar_free_') or \
                 name.startswith('theta_A_') or name.startswith('theta_B_'):
                # âœ… ëŒ€ì•ˆë³„ ì ì¬ë³€ìˆ˜ ê³„ìˆ˜
                stats[name] = stat_dict
            elif name == 'lambda_main':
                stats['lambda_main'] = stat_dict
            elif name == 'lambda':
                stats['lambda'] = stat_dict
            elif name.startswith('lambda_mod_'):
                stats[name] = stat_dict
            elif name.startswith('lambda_'):
                # âœ… ëª¨ë“  LV ì£¼íš¨ê³¼: lambda_{lv_name}
                stats[name] = stat_dict
            elif name.startswith('gamma_'):
                # âœ… LV-Attribute ìƒí˜¸ì‘ìš©: gamma_{lv_name}_{attr_name}
                stats[name] = stat_dict

        return stats

    def _log_factor_scores(self, factor_scores: Dict[str, np.ndarray], stage: str = ""):
        """
        ìš”ì¸ì ìˆ˜ ìƒì„¸ ë¡œê¹… ë° íŒŒì¼ ì €ì¥

        Args:
            factor_scores: ìš”ì¸ì ìˆ˜ ë”•ì…”ë„ˆë¦¬
            stage: ë¡œê¹… ë‹¨ê³„ ì„¤ëª…
        """
        from pathlib import Path

        self.logger.info("=" * 70)
        self.logger.info(f"ìš”ì¸ì ìˆ˜ ìƒì„¸ ì •ë³´ [{stage}]")
        self.logger.info("=" * 70)

        # ê¸°ë³¸ í†µê³„
        for lv_name, scores in factor_scores.items():
            self.logger.info(f"\n{lv_name}:")
            self.logger.info(f"  Shape: {scores.shape}")
            self.logger.info(f"  Mean: {np.mean(scores):.4f}")
            self.logger.info(f"  Std: {np.std(scores):.4f}")
            self.logger.info(f"  Min: {np.min(scores):.4f}")
            self.logger.info(f"  Max: {np.max(scores):.4f}")
            self.logger.info(f"  First 5: {scores[:5]}")

            # NaN/Inf ì²´í¬
            n_nan = np.sum(np.isnan(scores))
            n_inf = np.sum(np.isinf(scores))
            if n_nan > 0 or n_inf > 0:
                self.logger.warning(f"  âš ï¸ NaN: {n_nan}, Inf: {n_inf}")

        # ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥
        self.logger.info("\níŒŒì¼ ì €ì¥ ì‹œì‘...")
        try:
            from datetime import datetime
            import os

            # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
            current_dir = Path(os.getcwd())
            log_dir = current_dir / "logs" / "factor_scores"
            self.logger.info(f"í˜„ì¬ ë””ë ‰í† ë¦¬: {current_dir}")
            self.logger.info(f"ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
            log_dir.mkdir(parents=True, exist_ok=True)

            # íƒ€ì„ìŠ¤íƒ¬í”„
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # ë‹¨ê³„ë³„ íŒŒì¼ëª…
            stage_clean = stage.replace(" ", "_").replace("[", "").replace("]", "")
            log_file = log_dir / f"factor_scores_{stage_clean}_{timestamp}.csv"
            self.logger.info(f"ì €ì¥ íŒŒì¼: {log_file}")

            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            df = pd.DataFrame(factor_scores)
            self.logger.info(f"DataFrame ìƒì„± ì™„ë£Œ: {df.shape}")
            df.to_csv(str(log_file), index=False)
            self.logger.info(f"CSV ì €ì¥ ì™„ë£Œ")

            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if log_file.exists():
                self.logger.info(f"íŒŒì¼ ì¡´ì¬ í™•ì¸: {log_file.exists()}, í¬ê¸°: {log_file.stat().st_size} bytes")
            else:
                self.logger.warning(f"íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

            self.logger.info(f"\nâœ… ìš”ì¸ì ìˆ˜ ì €ì¥: {log_file}")
        except Exception as e:
            import traceback
            self.logger.error(f"\nâŒ ìš”ì¸ì ìˆ˜ ì €ì¥ ì‹¤íŒ¨: {e}")
            self.logger.error(f"Traceback: {traceback.format_exc()}")

        self.logger.info("=" * 70)

