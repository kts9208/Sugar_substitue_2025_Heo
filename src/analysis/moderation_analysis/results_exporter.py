"""
Moderation Analysis Results Exporter Module

ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ê²°ê³¼ë¥¼ CSV, JSON, ìš”ì•½ë³´ê³ ì„œ í˜•íƒœë¡œ ì €ì¥í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import json
from typing import Dict, List, Optional, Tuple, Union, Any
from pathlib import Path
from datetime import datetime
import logging

from .config import ModerationAnalysisConfig

logger = logging.getLogger(__name__)


class ModerationResultsExporter:
    """ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ê²°ê³¼ ì €ì¥ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Optional[ModerationAnalysisConfig] = None):
        """
        ê²°ê³¼ ì €ì¥ê¸° ì´ˆê¸°í™”
        
        Args:
            config (Optional[ModerationAnalysisConfig]): ë¶„ì„ ì„¤ì •
        """
        from .config import DEFAULT_CONFIG
        self.config = config or DEFAULT_CONFIG
        self.results_dir = Path(self.config.results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        logger.info(f"ê²°ê³¼ ì €ì¥ê¸° ì´ˆê¸°í™”: {self.results_dir}")
    
    def export_comprehensive_results(self, results: Dict[str, Any],
                                   analysis_name: Optional[str] = None) -> Dict[str, Path]:
        """
        í¬ê´„ì  ê²°ê³¼ ì €ì¥ (CSV, JSON, ë³´ê³ ì„œ)
        
        Args:
            results (Dict[str, Any]): ë¶„ì„ ê²°ê³¼
            analysis_name (Optional[str]): ë¶„ì„ëª… (íŒŒì¼ëª…ì— ì‚¬ìš©)
            
        Returns:
            Dict[str, Path]: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        logger.info("í¬ê´„ì  ê²°ê³¼ ì €ì¥ ì‹œì‘")
        
        # ë¶„ì„ëª… ì„¤ì •
        if analysis_name is None:
            vars_info = results.get('variables', {})
            analysis_name = f"{vars_info.get('independent', 'X')}_x_{vars_info.get('moderator', 'Z')}_to_{vars_info.get('dependent', 'Y')}"
        
        saved_files = {}
        
        try:
            # 1. CSV íŒŒì¼ë“¤ ì €ì¥
            if self.config.save_csv:
                csv_files = self._save_csv_results(results, analysis_name)
                saved_files.update(csv_files)
            
            # 2. JSON íŒŒì¼ ì €ì¥
            if self.config.save_json:
                json_file = self._save_json_results(results, analysis_name)
                saved_files['json'] = json_file
            
            # 3. ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
            if self.config.save_report:
                report_file = self._save_summary_report(results, analysis_name)
                saved_files['report'] = report_file
            
            logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {len(saved_files)}ê°œ íŒŒì¼")
            return saved_files
            
        except Exception as e:
            logger.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def _save_csv_results(self, results: Dict[str, Any], analysis_name: str) -> Dict[str, Path]:
        """CSV ê²°ê³¼ íŒŒì¼ë“¤ ì €ì¥"""
        csv_files = {}
        
        # 1. íšŒê·€ê³„ìˆ˜ í…Œì´ë¸”
        coefficients_df = self._create_coefficients_table(results.get('coefficients', {}))
        if not coefficients_df.empty:
            coeff_file = self.results_dir / f"{analysis_name}_coefficients_{self.timestamp}.csv"
            coefficients_df.to_csv(coeff_file, index=True, encoding='utf-8-sig')
            csv_files['coefficients'] = coeff_file
        
        # 2. ë‹¨ìˆœê¸°ìš¸ê¸° ë¶„ì„ ê²°ê³¼
        simple_slopes_df = self._create_simple_slopes_table(results.get('simple_slopes', {}))
        if not simple_slopes_df.empty:
            slopes_file = self.results_dir / f"{analysis_name}_simple_slopes_{self.timestamp}.csv"
            simple_slopes_df.to_csv(slopes_file, index=True, encoding='utf-8-sig')
            csv_files['simple_slopes'] = slopes_file
        
        # 3. ì¡°ê±´ë¶€ íš¨ê³¼ ê²°ê³¼
        conditional_df = self._create_conditional_effects_table(results.get('conditional_effects', {}))
        if not conditional_df.empty:
            conditional_file = self.results_dir / f"{analysis_name}_conditional_effects_{self.timestamp}.csv"
            conditional_df.to_csv(conditional_file, index=True, encoding='utf-8-sig')
            csv_files['conditional_effects'] = conditional_file
        
        # 4. ì í•©ë„ ì§€ìˆ˜
        fit_indices_df = self._create_fit_indices_table(results.get('fit_indices', {}))
        if not fit_indices_df.empty:
            fit_file = self.results_dir / f"{analysis_name}_fit_indices_{self.timestamp}.csv"
            fit_indices_df.to_csv(fit_file, index=True, encoding='utf-8-sig')
            csv_files['fit_indices'] = fit_file
        
        return csv_files
    
    def _create_coefficients_table(self, coefficients: Dict[str, Any]) -> pd.DataFrame:
        """íšŒê·€ê³„ìˆ˜ í…Œì´ë¸” ìƒì„±"""
        if not coefficients:
            return pd.DataFrame()
        
        coeff_data = []
        for var_name, coeff_info in coefficients.items():
            coeff_data.append({
                'Variable': var_name,
                'Estimate': coeff_info.get('estimate', np.nan),
                'Std_Error': coeff_info.get('std_error', np.nan),
                'Z_Value': coeff_info.get('z_value', np.nan),
                'P_Value': coeff_info.get('p_value', np.nan),
                'Std_Estimate': coeff_info.get('std_estimate', np.nan),
                'Significant': coeff_info.get('significant', False)
            })
        
        return pd.DataFrame(coeff_data).set_index('Variable')
    
    def _create_simple_slopes_table(self, simple_slopes: Dict[str, Any]) -> pd.DataFrame:
        """ë‹¨ìˆœê¸°ìš¸ê¸° í…Œì´ë¸” ìƒì„±"""
        if not simple_slopes:
            return pd.DataFrame()
        
        slopes_data = []
        for level, slope_info in simple_slopes.items():
            slopes_data.append({
                'Moderator_Level': level,
                'Moderator_Value': slope_info.get('moderator_value', np.nan),
                'Simple_Slope': slope_info.get('simple_slope', np.nan),
                'Std_Error': slope_info.get('std_error', np.nan),
                'T_Value': slope_info.get('t_value', np.nan),
                'P_Value': slope_info.get('p_value', np.nan),
                'Significant': slope_info.get('significant', False)
            })
        
        return pd.DataFrame(slopes_data).set_index('Moderator_Level')
    
    def _create_conditional_effects_table(self, conditional_effects: Dict[str, Any]) -> pd.DataFrame:
        """ì¡°ê±´ë¶€ íš¨ê³¼ í…Œì´ë¸” ìƒì„±"""
        if not conditional_effects:
            return pd.DataFrame()
        
        conditional_data = []
        for percentile, effect_info in conditional_effects.items():
            conditional_data.append({
                'Percentile': percentile,
                'Moderator_Value': effect_info.get('moderator_value', np.nan),
                'Conditional_Effect': effect_info.get('simple_slope', np.nan),
                'Std_Error': effect_info.get('std_error', np.nan),
                'T_Value': effect_info.get('t_value', np.nan),
                'P_Value': effect_info.get('p_value', np.nan),
                'Significant': effect_info.get('significant', False)
            })
        
        return pd.DataFrame(conditional_data).set_index('Percentile')
    
    def _create_fit_indices_table(self, fit_indices: Dict[str, float]) -> pd.DataFrame:
        """ì í•©ë„ ì§€ìˆ˜ í…Œì´ë¸” ìƒì„±"""
        if not fit_indices:
            return pd.DataFrame()
        
        fit_data = []
        for index_name, value in fit_indices.items():
            # ì í•©ë„ í•´ì„
            interpretation = self._interpret_fit_index(index_name, value)
            
            fit_data.append({
                'Fit_Index': index_name,
                'Value': value,
                'Interpretation': interpretation
            })
        
        return pd.DataFrame(fit_data).set_index('Fit_Index')
    
    def _interpret_fit_index(self, index_name: str, value: float) -> str:
        """ì í•©ë„ ì§€ìˆ˜ í•´ì„"""
        if index_name in ['CFI', 'TLI']:
            if value >= 0.95:
                return 'Excellent'
            elif value >= 0.90:
                return 'Good'
            else:
                return 'Poor'
        elif index_name == 'RMSEA':
            if value <= 0.05:
                return 'Excellent'
            elif value <= 0.08:
                return 'Good'
            else:
                return 'Poor'
        elif index_name == 'SRMR':
            if value <= 0.05:
                return 'Excellent'
            elif value <= 0.08:
                return 'Good'
            else:
                return 'Poor'
        else:
            return 'N/A'
    
    def _save_json_results(self, results: Dict[str, Any], analysis_name: str) -> Path:
        """JSON ê²°ê³¼ íŒŒì¼ ì €ì¥"""
        json_file = self.results_dir / f"{analysis_name}_full_results_{self.timestamp}.json"
        
        # JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜
        json_results = self._convert_to_json_serializable(results)
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        
        return json_file
    
    def _convert_to_json_serializable(self, obj: Any) -> Any:
        """JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        if isinstance(obj, dict):
            return {key: self._convert_to_json_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_to_json_serializable(item) for item in obj]
        elif isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        else:
            return obj
    
    def _save_summary_report(self, results: Dict[str, Any], analysis_name: str) -> Path:
        """ìš”ì•½ ë³´ê³ ì„œ ì €ì¥"""
        report_file = self.results_dir / f"{analysis_name}_summary_report_{self.timestamp}.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(self._generate_summary_report(results, analysis_name))
        
        return report_file
    
    def _generate_summary_report(self, results: Dict[str, Any], analysis_name: str) -> str:
        """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        report_lines = []
        
        # í—¤ë”
        report_lines.append("=" * 80)
        report_lines.append("ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ìš”ì•½ ë³´ê³ ì„œ")
        report_lines.append("=" * 80)
        report_lines.append(f"ë¶„ì„ëª…: {analysis_name}")
        report_lines.append(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # ë³€ìˆ˜ ì •ë³´
        variables = results.get('variables', {})
        report_lines.append("ğŸ“‹ ë¶„ì„ ë³€ìˆ˜")
        report_lines.append("-" * 40)
        report_lines.append(f"ë…ë¦½ë³€ìˆ˜: {variables.get('independent', 'N/A')}")
        report_lines.append(f"ì¢…ì†ë³€ìˆ˜: {variables.get('dependent', 'N/A')}")
        report_lines.append(f"ì¡°ì ˆë³€ìˆ˜: {variables.get('moderator', 'N/A')}")
        report_lines.append(f"ìƒí˜¸ì‘ìš©í•­: {variables.get('interaction', 'N/A')}")
        report_lines.append("")
        
        # ëª¨ë¸ ì •ë³´
        model_info = results.get('model_info', {})
        report_lines.append("ğŸ“Š ëª¨ë¸ ì •ë³´")
        report_lines.append("-" * 40)
        report_lines.append(f"ê´€ì¸¡ì¹˜ ìˆ˜: {model_info.get('n_observations', 'N/A')}")
        report_lines.append(f"ëª¨ìˆ˜ ìˆ˜: {model_info.get('n_parameters', 'N/A')}")
        report_lines.append("")
        
        # ì¡°ì ˆíš¨ê³¼ ê²€ì • ê²°ê³¼
        moderation_test = results.get('moderation_test', {})
        report_lines.append("ğŸ¯ ì¡°ì ˆíš¨ê³¼ ê²€ì • ê²°ê³¼")
        report_lines.append("-" * 40)
        interaction_coeff = moderation_test.get('interaction_coefficient', 'N/A')
        std_error = moderation_test.get('std_error', 'N/A')
        z_value = moderation_test.get('z_value', 'N/A')
        p_value = moderation_test.get('p_value', 'N/A')

        report_lines.append(f"ìƒí˜¸ì‘ìš© ê³„ìˆ˜: {interaction_coeff:.4f}" if isinstance(interaction_coeff, (int, float)) else f"ìƒí˜¸ì‘ìš© ê³„ìˆ˜: {interaction_coeff}")
        report_lines.append(f"í‘œì¤€ì˜¤ì°¨: {std_error:.4f}" if isinstance(std_error, (int, float)) else f"í‘œì¤€ì˜¤ì°¨: {std_error}")
        report_lines.append(f"Zê°’: {z_value:.4f}" if isinstance(z_value, (int, float)) else f"Zê°’: {z_value}")
        report_lines.append(f"Pê°’: {p_value:.4f}" if isinstance(p_value, (int, float)) else f"Pê°’: {p_value}")
        report_lines.append(f"ìœ ì˜ì„±: {'ìœ ì˜í•¨' if moderation_test.get('significant', False) else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
        report_lines.append(f"í•´ì„: {moderation_test.get('interpretation', 'N/A')}")
        report_lines.append("")
        
        # ë‹¨ìˆœê¸°ìš¸ê¸° ë¶„ì„
        simple_slopes = results.get('simple_slopes', {})
        if simple_slopes:
            report_lines.append("ğŸ“ˆ ë‹¨ìˆœê¸°ìš¸ê¸° ë¶„ì„")
            report_lines.append("-" * 40)
            for level, slope_info in simple_slopes.items():
                report_lines.append(f"{level.upper()}:")

                moderator_value = slope_info.get('moderator_value', 'N/A')
                simple_slope = slope_info.get('simple_slope', 'N/A')
                p_value = slope_info.get('p_value', 'N/A')

                report_lines.append(f"  ì¡°ì ˆë³€ìˆ˜ ê°’: {moderator_value:.4f}" if isinstance(moderator_value, (int, float)) else f"  ì¡°ì ˆë³€ìˆ˜ ê°’: {moderator_value}")
                report_lines.append(f"  ë‹¨ìˆœê¸°ìš¸ê¸°: {simple_slope:.4f}" if isinstance(simple_slope, (int, float)) else f"  ë‹¨ìˆœê¸°ìš¸ê¸°: {simple_slope}")
                report_lines.append(f"  Pê°’: {p_value:.4f}" if isinstance(p_value, (int, float)) else f"  Pê°’: {p_value}")
                report_lines.append(f"  ìœ ì˜ì„±: {'ìœ ì˜í•¨' if slope_info.get('significant', False) else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
                report_lines.append("")
        
        # ì í•©ë„ ì§€ìˆ˜
        fit_indices = results.get('fit_indices', {})
        if fit_indices:
            report_lines.append("ğŸ“ ëª¨ë¸ ì í•©ë„")
            report_lines.append("-" * 40)
            for index_name, value in fit_indices.items():
                interpretation = self._interpret_fit_index(index_name, value)
                if isinstance(value, (int, float)):
                    report_lines.append(f"{index_name}: {value:.4f} ({interpretation})")
                else:
                    report_lines.append(f"{index_name}: {value} ({interpretation})")
            report_lines.append("")
        
        # ê²°ë¡ 
        report_lines.append("ğŸ’¡ ë¶„ì„ ê²°ë¡ ")
        report_lines.append("-" * 40)
        if moderation_test.get('significant', False):
            report_lines.append("âœ… ì¡°ì ˆíš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤.")
            report_lines.append(f"   {moderation_test.get('interpretation', '')}")
        else:
            report_lines.append("âŒ ì¡°ì ˆíš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        return "\n".join(report_lines)

    def save_comprehensive_results(self, comprehensive_results: Dict[str, Any],
                                 analysis_name: str = "comprehensive_analysis") -> Dict[str, Path]:
        """ì¢…í•© ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        return save_comprehensive_moderation_results(comprehensive_results, analysis_name, self.config)


# í¸ì˜ í•¨ìˆ˜ë“¤
def export_moderation_results(results: Dict[str, Any], analysis_name: Optional[str] = None,
                            config: Optional[ModerationAnalysisConfig] = None) -> Dict[str, Path]:
    """ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ê²°ê³¼ ì €ì¥ í¸ì˜ í•¨ìˆ˜"""
    exporter = ModerationResultsExporter(config)
    return exporter.export_comprehensive_results(results, analysis_name)


def create_moderation_report(results: Dict[str, Any], analysis_name: str,
                           config: Optional[ModerationAnalysisConfig] = None) -> Path:
    """ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ë³´ê³ ì„œ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    exporter = ModerationResultsExporter(config)
    return exporter._save_summary_report(results, analysis_name)


def save_comprehensive_moderation_results(comprehensive_results: Dict[str, Any],
                                        analysis_name: str = "comprehensive_analysis",
                                        config: Optional[ModerationAnalysisConfig] = None) -> Dict[str, Path]:
    """ì¢…í•© ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ê²°ê³¼ ì €ì¥ í¸ì˜ í•¨ìˆ˜"""
    exporter = ModerationResultsExporter(config)

    saved_files = {}

    try:
        # CSV ì €ì¥
        if 'detailed_results' in comprehensive_results:
            df = pd.DataFrame(comprehensive_results['detailed_results'])
            csv_path = exporter.results_dir / f"{analysis_name}_{exporter.timestamp}.csv"
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            saved_files['csv_file'] = csv_path

        # JSON ì €ì¥ (JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜)
        json_data = {}
        for key, value in comprehensive_results.items():
            if key == 'detailed_results':
                # DataFrameì„ dictë¡œ ë³€í™˜
                json_data[key] = pd.DataFrame(value).to_dict('records') if value else []
            else:
                json_data[key] = value

        json_path = exporter.results_dir / f"{analysis_name}_{exporter.timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2, default=str)
        saved_files['json_file'] = json_path

        # ìš”ì•½ ë³´ê³ ì„œ ì €ì¥
        report_path = exporter.results_dir / f"{analysis_name}_summary_{exporter.timestamp}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("5ê°œ ìš”ì¸ ê°„ ì¡°ì ˆíš¨ê³¼ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ\n")
            f.write("=" * 80 + "\n")
            f.write(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # ìš”ì•½ ì •ë³´
            if 'summary' in comprehensive_results:
                summary = comprehensive_results['summary']
                f.write("ğŸ“Š ë¶„ì„ ìš”ì•½\n")
                f.write("-" * 40 + "\n")
                f.write(f"ì´ ë¶„ì„ ì¡°í•©: {summary.get('total_combinations', 0)}ê°œ\n")
                f.write(f"ì„±ê³µí•œ ë¶„ì„: {summary.get('successful_analyses', 0)}ê°œ ({summary.get('success_rate', 0):.1f}%)\n")
                f.write(f"ìœ ì˜í•œ ì¡°ì ˆíš¨ê³¼: {summary.get('significant_effects', 0)}ê°œ ({summary.get('significance_rate', 0):.1f}%)\n\n")

                if summary.get('significant_effects', 0) == 0:
                    f.write("ğŸ’¡ ìœ ì˜í•œ ì¡°ì ˆíš¨ê³¼ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n\n")

            # ìš”ì¸ë³„ ë¶„ì„ ê²°ê³¼
            if 'variables' in comprehensive_results and 'detailed_results' in comprehensive_results:
                variables = comprehensive_results['variables']
                detailed_results = comprehensive_results['detailed_results']

                f.write("ğŸ“‹ ìš”ì¸ë³„ ë¶„ì„ ê²°ê³¼\n")
                f.write("-" * 40 + "\n\n")

                for var in variables:
                    # í•´ë‹¹ ë³€ìˆ˜ê°€ ì¢…ì†ë³€ìˆ˜ì¸ ê²½ìš°ë“¤ ì°¾ê¸°
                    var_results = [r for r in detailed_results if r.get('dependent') == var]
                    significant_count = len([r for r in var_results if r.get('significant', False)])

                    f.write(f"{var} (ì¢…ì†ë³€ìˆ˜):\n")
                    f.write(f"  ì´ ë¶„ì„: {len(var_results)}ê°œ\n")
                    f.write(f"  ìœ ì˜í•œ ì¡°ì ˆíš¨ê³¼: {significant_count}ê°œ\n\n")

        saved_files['report_file'] = report_path

        logger.info(f"ì¢…í•© ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {len(saved_files)}ê°œ íŒŒì¼")
        return saved_files

    except Exception as e:
        logger.error(f"ì¢…í•© ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return saved_files
